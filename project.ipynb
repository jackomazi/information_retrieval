{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information retrieval project\n",
    "\n",
    "Goal is to create an IR model that can perform both boolean (AND, OR and NOT), wildcard and phrase queries.\n",
    "\n",
    "Perform normalization and stemming.\n",
    "\n",
    "Spelling correction.\n",
    "\n",
    "Evaluate the system on test queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents():\n",
    "    f = open(\"archive/CISI.ALL\")\n",
    "    merged = \" \"\n",
    "    i = 0\n",
    "    for a_line in f.readlines ():\n",
    "            if a_line.startswith (\".\"):\n",
    "                i += 1\n",
    "                merged += \"\\n\" + a_line.strip ()\n",
    "            else:\n",
    "                i += 1\n",
    "                merged += \" \" + a_line.strip ()\n",
    "        # updates the merged variable using a for-loop\n",
    "    documents = {}\n",
    "    content = \"\"\n",
    "    doc_id = \"\"\n",
    "    # each entry in the dictioanry contains key = doc_id and value = content\n",
    "\n",
    "    for line in merged.split (\"\\n\"):\n",
    "        #print(a_line)\n",
    "        if line.startswith (\".I\"):\n",
    "            doc_id = line.split (\" \") [1].strip()\n",
    "        elif line.startswith (\".X\"):\n",
    "            documents[doc_id] = content\n",
    "            content = \"\"\n",
    "            doc_id = \"\"\n",
    "        else:\n",
    "            content += line.strip ()[3:] + \" \"\n",
    "            #Extract after . a letter and a space\n",
    "    f.close ()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_queries():\n",
    "    f = open(\"archive/CISI.QRY\")\n",
    "\n",
    "    merged = \"\"\n",
    "\n",
    "    for line in f.readlines ():\n",
    "        if line.startswith (\".\"):\n",
    "            merged += \"\\n\" + line.strip ()\n",
    "        else:\n",
    "            merged += \" \" + line.strip ()\n",
    "    \n",
    "    queries = {}\n",
    "\n",
    "    content = \"\"\n",
    "    qry_id = \"\"\n",
    "\n",
    "    for line in merged.split (\"\\n\"):\n",
    "        if line.startswith(\".I\"):\n",
    "            if not content == \"\":\n",
    "                queries [qry_id] = content\n",
    "                content = \"\"\n",
    "                qry_id = \"\"\n",
    "            # add an enrty to the dictionary when you encounter an .I identifier\n",
    "            qry_id = line.split(\" \")[1].strip ()\n",
    "        # otherwise, keep adding content to the content variable\n",
    "        elif line.startswith (\".W\") or line.startswith (\".T\"):\n",
    "            content += line.strip ()[3:] + \" \"\n",
    "    queries [qry_id] = content\n",
    "    f.close ()\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_relevance():\n",
    "    f = open(\"archive/CISI.REL\")\n",
    "    mappings = {}\n",
    "    \n",
    "    for line in f.readlines ():\n",
    "        voc = line.strip ().split ()\n",
    "        key = voc[0].strip ()\n",
    "        current_value = voc[1].strip()\n",
    "        value = []\n",
    "        # update the entry in the mappings dictionary with the current value\n",
    "        if key in mappings.keys ():\n",
    "            value = mappings.get (key)\n",
    "        value.append (current_value)\n",
    "        mappings [key] = value\n",
    "    f.close ()\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      " 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"
     ]
    }
   ],
   "source": [
    "documents = read_documents()\n",
    "print(len(documents))\n",
    "print(documents[\"1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles? \n"
     ]
    }
   ],
   "source": [
    "queries = read_queries()\n",
    "print(len(queries))\n",
    "print(queries[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
     ]
    }
   ],
   "source": [
    "relevance = read_relevance()\n",
    "print(len(relevance))\n",
    "print(relevance[\"1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(text):\n",
    "    terms = {}\n",
    "    ps = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_list = [ps.stem(word) for word in word_tokenize(text.lower()) if not word in string.punctuation and word not in stop_words]\n",
    "    #print(word_list)\n",
    "    for word in word_list:\n",
    "        terms[word] = terms.get(word, 0) + 1\n",
    "    return terms\n",
    "\n",
    "doc_terms = {}\n",
    "qry_terms = {}\n",
    "for doc_id in documents.keys ():\n",
    "    text = documents.get (doc_id)\n",
    "    #print(word_tokenize(text.lower()))\n",
    "    doc_terms[doc_id] = get_terms(documents.get(doc_id))\n",
    "\n",
    "for qry_id in queries.keys ():\n",
    "    # populate the term frequency dictionaries for all documents and all queries\n",
    "    qry_terms [qry_id] = get_terms (queries.get (qry_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "{'note': 1, 'pseudo-mathemat': 1, 'relev': 6, 'taub': 1, 'm.': 1, 'recent': 1, 'number': 1, 'articl': 1, 'book': 1, 'report': 2, 'deal': 1, 'inform': 2, 'system': 5, 'i.e.': 1, 'document': 2, 'retriev': 1, 'advanc': 1, 'doctrin': 2, 'evalu': 1, 'term': 6, 'degre': 1, 'percentag': 1, 'provid': 2, 'although': 1, 'seem': 1, 'littl': 1, 'agreement': 2, 'mean': 3, 'doubt': 1, 'quantifi': 1, 'nevertheless': 1, 'grow': 1, 'fix': 1, 'formal': 1, 'relationship': 1, 'exist': 1, 'recal': 2, 'perform': 1, 'thu': 1, 'find': 1, 'literatur': 1, 'frankli': 1, 'subject': 2, 'notion': 1, 'individu': 1, 'user': 2, 'equat': 2, 'curv': 1, 'mathemat': 4, 'formul': 1, 'presum': 1, 'numer': 1, 'measur': 1, 'characterist': 1, 'phenomenon': 1, 'shift': 1, 'back': 1, 'forth': 1, 'admittedli': 1, 'non-mathemat': 1, 'given': 1, 'valu': 1, 'definit': 1, 'ancient': 1, 'parallel': 1, 'discuss': 1, 'probabl': 1, 'one': 1, 'cours': 1, 'legisl': 1, 'depend': 1, 'alic': 1, 'point': 1, '``': 1, 'master': 1, \"''\": 1, 'hand': 1, 'use': 1, 'singl': 1, 'cover': 1, 'two': 1, 'distinct': 1, 'especi': 1, 'usag': 1, 'design': 1, 'secur': 1, 'accept': 1, 'attribut': 1, 'valid': 1, 'repres': 1, 'seriou': 1, 'situat': 1, 'mere': 1, 'careless': 1, 'ambigu': 1}\n",
      "95\n",
      "112\n",
      "{'problem': 1, 'concern': 1, 'make': 1, 'descript': 1, 'titl': 3, 'difficulti': 1, 'involv': 1, 'automat': 1, 'retriev': 1, 'articl': 2, 'approxim': 1, 'usual': 1, 'relev': 1, 'content': 1}\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print (len (doc_terms))  # number of documents\n",
    "print (doc_terms.get (\"28\"))  # terms in document 1\n",
    "print (len (doc_terms.get(\"28\")))  # number of terms in document 1\n",
    "print (len (qry_terms)) # number of queries\n",
    "print (qry_terms.get(\"1\")) # terms in query 1\n",
    "print (len (qry_terms.get(\"1\"))) # number of terms in query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "{'18': 1, 'edit': 4, 'of': 7, 'the': 10, 'dewey': 3, 'decim': 2, 'classif': 2, 'comaromi': 1, 'j.p.': 1, 'present': 1, 'studi': 1, 'is': 2, 'a': 2, 'histori': 2, 'first': 2, 'ddc': 2, 'wa': 1, 'publish': 1, 'in': 4, '1876': 1, 'eighteenth': 1, '1971': 1, 'and': 3, 'futur': 1, 'will': 1, 'continu': 1, 'to': 2, 'appear': 1, 'as': 1, 'need': 1, 'spite': 1, \"'s\": 1, 'long': 1, 'healthi': 1, 'life': 1, 'howev': 1, 'it': 1, 'full': 1, 'stori': 1, 'ha': 2, 'never': 1, 'been': 2, 'told': 1, 'there': 1, 'have': 1, 'biographi': 1, 'that': 2, 'briefli': 1, 'describ': 1, 'hi': 1, 'system': 1, 'but': 1, 'thi': 2, 'attempt': 1, 'provid': 1, 'detail': 1, 'work': 1, 'more': 1, 'than': 1, 'ani': 1, 'other': 1, 'spur': 1, 'growth': 1, 'librarianship': 1, 'countri': 1, 'abroad': 1}\n",
      "66\n",
      "112\n",
      "{'what': 3, 'problem': 1, 'and': 1, 'concern': 1, 'are': 2, 'there': 1, 'in': 2, 'make': 1, 'up': 1, 'descript': 1, 'titl': 3, 'difficulti': 1, 'involv': 1, 'automat': 1, 'retriev': 1, 'articl': 2, 'from': 1, 'approxim': 1, 'is': 1, 'the': 2, 'usual': 1, 'relev': 1, 'of': 2, 'content': 1, 'to': 1, 'their': 1}\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print (len (doc_terms))  # number of documents\n",
    "print (doc_terms.get (\"1\"))  # terms in document 1\n",
    "print (len (doc_terms.get(\"1\")))  # number of terms in document 1\n",
    "print (len (qry_terms)) # number of queries\n",
    "print (qry_terms.get(\"1\")) # terms in query 1\n",
    "print (len (qry_terms.get(\"1\"))) # number of terms in query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    query_set = set(query)\n",
    "    doc_set = set(document)\n",
    "    #print(query_set)\n",
    "    #print(doc_set)\n",
    "    return len(query_set & doc_set) / len(query_set | doc_set)\n",
    "\n",
    "jacc = {}\n",
    "for doc_id in doc_terms.keys ():\n",
    "    # save in a dict the jaccard result for each document\n",
    "    jacc[doc_id] = jaccard_similarity(qry_terms.get(\"1\"), doc_terms.get(doc_id))\n",
    "\n",
    "\n",
    "    #print (jaccard_similarity (qry_terms.get (\"1\"), doc_terms.get (doc_id)))\n",
    "\n",
    "#print(jaccard_similarity(qry_terms.get(\"1\"), doc_terms.get(\"1\")))  # Output vicino a 1 indica alta rilevanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1323', 0.0975609756097561)\n",
      "('769', 0.0847457627118644)\n",
      "('1364', 0.08333333333333333)\n",
      "('1163', 0.07894736842105263)\n",
      "('518', 0.0784313725490196)\n",
      "('882', 0.07692307692307693)\n",
      "('993', 0.07692307692307693)\n",
      "('1294', 0.07407407407407407)\n",
      "('1307', 0.06896551724137931)\n",
      "('451', 0.06818181818181818)\n"
     ]
    }
   ],
   "source": [
    "# print the top 10 documents with the highest Jaccard similarity\n",
    "sorted_jacc = sorted(jacc.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print(sorted_jacc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08235294117647059\n",
      "0.1\n",
      "0.08536585365853659\n",
      "0.05747126436781609\n",
      "0.06299212598425197\n",
      "0.059602649006622516\n",
      "0.08641975308641975\n",
      "0.07586206896551724\n",
      "0.05785123966942149\n",
      "0.07407407407407407\n",
      "0.10975609756097561\n",
      "0.06153846153846154\n",
      "0.07228915662650602\n",
      "0.06722689075630252\n",
      "0.08108108108108109\n",
      "0.06832298136645963\n",
      "0.05439330543933055\n",
      "0.0761904761904762\n",
      "0.051470588235294115\n",
      "0.06363636363636363\n",
      "0.057971014492753624\n",
      "0.07317073170731707\n",
      "0.08333333333333333\n",
      "0.1388888888888889\n",
      "0.08163265306122448\n",
      "0.10975609756097561\n",
      "0.0425531914893617\n",
      "0.08609271523178808\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 30):\n",
    "    print(jaccard_similarity(qry_terms.get(\"1\"), doc_terms.get(str(i))))  # Output vicino a 1 indica alta rilevanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INVERTED INDEX\n",
    "def normalize(text):\n",
    "    no_punctuation = re.sub(r'[^\\w^\\s*-]','',text) # remove punctuation\n",
    "    downcase = no_punctuation.lower() # lowercase\n",
    "    return downcase\n",
    "\n",
    "def tokenize(content):\n",
    "    text = normalize(content)\n",
    "    return list(text.split()) # return a list of tokens\n",
    "\n",
    "def Lstemm(content):\n",
    "    ps = LancasterStemmer() # stemmer\n",
    "    text = tokenize(content) # tokenize\n",
    "    return list(set([ps.stem(word) for word in text]))\n",
    "def Pstemm(content):\n",
    "    ps = PorterStemmer() # stemmer\n",
    "    text = tokenize(content) # tokenize\n",
    "    return list(set([ps.stem(word) for word in text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverted index\n",
    "def create_inverted_index_no_norm(documents):\n",
    "    inverted_index = {}\n",
    "    for doc_id, content in documents.items():\n",
    "        for token in content.split():\n",
    "            if token in inverted_index.keys():\n",
    "                if doc_id not in inverted_index[token]:\n",
    "                    inverted_index[token].append(doc_id)\n",
    "            else:\n",
    "                inverted_index[token] = [doc_id]\n",
    "        #if (int(doc_id) % 100 == 0):\n",
    "        #    print(\"ID: \" + str(doc_id))\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverted index\n",
    "def create_inverted_index_P(documents):\n",
    "    inverted_index = {}\n",
    "    for doc_id, content in documents.items():\n",
    "        #print(content)\n",
    "        for token in Pstemm(content):\n",
    "            if token in inverted_index.keys():\n",
    "                if doc_id not in inverted_index[token]:\n",
    "                    inverted_index[token].append(doc_id)\n",
    "            else:\n",
    "                inverted_index[token] = [doc_id]\n",
    "        #if (int(doc_id) % 100 == 0):\n",
    "        #    print(\"ID: \" + str(doc_id))\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverted index\n",
    "def create_inverted_index_L(documents):\n",
    "    inverted_index = {}\n",
    "    for doc_id, content in documents.items():\n",
    "        #print(content)\n",
    "        for token in Lstemm(content):\n",
    "            if token in inverted_index.keys():\n",
    "                if doc_id not in inverted_index[token]:\n",
    "                    inverted_index[token].append(doc_id)\n",
    "            else:\n",
    "                inverted_index[token] = [doc_id]\n",
    "        #if (int(doc_id) % 100 == 0):\n",
    "        #    print(\"ID: \" + str(doc_id))\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len no norm: 21967\n",
      "Len L: 7556\n",
      "Len P: 8554\n"
     ]
    }
   ],
   "source": [
    "inv_index_no_norm = create_inverted_index_no_norm(documents)\n",
    "\n",
    "inv_index_L = create_inverted_index_L(documents)\n",
    "\n",
    "inv_index_P = create_inverted_index_P(documents)\n",
    "\n",
    "print(f\"Len no norm: {len(inv_index_no_norm)}\")\n",
    "print(f\"Len L: {len(inv_index_L)}\")\n",
    "print(f\"Len P: {len(inv_index_P)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_inverted_index(inverted_index):\n",
    "    ordered_inverted_index = {}\n",
    "    for key in sorted(inverted_index.keys()):\n",
    "        ordered_inverted_index[key] = inverted_index[key]\n",
    "    return ordered_inverted_index\n",
    "\n",
    "ordered = order_inverted_index(inv_index_no_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '16',\n",
       " '42',\n",
       " '176',\n",
       " '233',\n",
       " '275',\n",
       " '282',\n",
       " '290',\n",
       " '328',\n",
       " '341',\n",
       " '345',\n",
       " '363',\n",
       " '379',\n",
       " '404',\n",
       " '405',\n",
       " '417',\n",
       " '428',\n",
       " '455',\n",
       " '476',\n",
       " '478',\n",
       " '479',\n",
       " '486',\n",
       " '559',\n",
       " '577',\n",
       " '610',\n",
       " '669',\n",
       " '694',\n",
       " '701',\n",
       " '722',\n",
       " '769',\n",
       " '791',\n",
       " '797',\n",
       " '798',\n",
       " '838',\n",
       " '857',\n",
       " '862',\n",
       " '945',\n",
       " '954',\n",
       " '958',\n",
       " '1029',\n",
       " '1075',\n",
       " '1180',\n",
       " '1204',\n",
       " '1217',\n",
       " '1237',\n",
       " '1380',\n",
       " '1395',\n",
       " '1398',\n",
       " '1415',\n",
       " '1423']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_index_P.get(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOOLEAN QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemm(book):\n",
    "    ps = PorterStemmer() # stemmer\n",
    "    text = tokenize(book) # tokenize\n",
    "    return list(set([ps.stem(word) for word in text])) \n",
    "\n",
    "def build_ngram_inverted_index(documents, n): # function take in input the documents and the n-gram size\n",
    "    inverted_index = {}\n",
    "    print(\"Building ngram inverted index...\")\n",
    "    for doc_id, doc in enumerate(documents): # for each document\n",
    "        for token in stemm(doc): # for each token in the document\n",
    "            wild_token = \"$\" + token + \"$\" # add initial and final symbol\n",
    "            for i in range(len(wild_token) - n + 1): # for each ngram in the token\n",
    "                ngram = wild_token[i:i+n]  # extract the n-gram\n",
    "                if ngram not in inverted_index:\n",
    "                    inverted_index[ngram] = [] # if the ngram is not in the inverted index we add it\n",
    "                if token not in inverted_index[ngram]:\n",
    "                    inverted_index[ngram].append(token) # if the token is not in the inverted index we add it to the list of tokens for that ngram    \n",
    "        if (doc_id % 1000 == 0):\n",
    "                print(\"ID: \" + str(doc_id))\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ngram inverted index...\n",
      "ID: 0\n",
      "ID: 1000\n"
     ]
    }
   ],
   "source": [
    "n_gram_inv_index = build_ngram_inverted_index(documents.values(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPELLING CORRECTION using Jaccard similarity\n",
    "def ngrams(word, n):\n",
    "    return [word[i:i+n] for i in range(len(word)-n+1)]\n",
    "\n",
    "def spelling_correction(word, index):    \n",
    "    # Get the list of k-grams for the input word\n",
    "    word_ngrams = ngrams(\"$\" + word + \"$\", 3)\n",
    "    # Build a set of all words that have any of these k-grams\n",
    "    words_with_kgrams = set()\n",
    "    for ngram in word_ngrams:\n",
    "        try: # check if What are the benefits of appl* or banana?ngram is in inverted index, if not, pass\n",
    "            words_with_kgrams.update(index[ngram]) \n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    # Compute the Jaccard similarity coefficient for each candidate word,\n",
    "    # and take the one that maximizes it\n",
    "    scores = []\n",
    "    for w in words_with_kgrams: # for each word in the set of words with k-grams\n",
    "        w_ngrams = ngrams(\"$\" + w + \"$\", 3) # get the list of k-grams for the word\n",
    "        scores.append((w, len(set(word_ngrams).intersection(w_ngrams)) / len(set(word_ngrams).union(w_ngrams)))) # compute the Jaccard similarity coefficient and append it to the list of scores  \n",
    "    return max(scores, key=lambda x: x[1])[0] # return the word with the highest Jaccard similarity coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: NOT class AND gam\n",
      "Matching Documents: {291, 205}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_query(query):\n",
    "    \"\"\"\n",
    "    Splits the query into tokens (terms, operators, and parentheses).\n",
    "    Operators are normalized to uppercase.\n",
    "    Terms are lowercased and stemmed using the Porter Stemmer.\n",
    "    \"\"\"\n",
    "    # This regex captures words, parentheses, and Boolean operators.\n",
    "    tokens = re.findall(r'\\(|\\)|\\bAND\\b|\\bOR\\b|\\bNOT\\b|\\w+', query, flags=re.IGNORECASE)\n",
    "    normalized_tokens = []\n",
    "    for token in tokens:\n",
    "        # Check if token is an operator\n",
    "        if token.upper() in {\"AND\", \"OR\", \"NOT\"}:\n",
    "            normalized_tokens.append(token.upper())\n",
    "        elif token in {\"(\", \")\"}:\n",
    "            normalized_tokens.append(token)\n",
    "        else:\n",
    "            # For terms, lowercase and apply stemming\n",
    "            token = stemmer.stem(token.lower())\n",
    "            if token not in inv_index_P.keys():\n",
    "                token = spelling_correction(token, n_gram_inv_index)\n",
    "            normalized_tokens.append(token)\n",
    "\n",
    "    return normalized_tokens\n",
    "\n",
    "def shunting_yard(tokens):\n",
    "    \"\"\"\n",
    "    Converts infix expression tokens to postfix (RPN) using the Shunting-yard algorithm.\n",
    "    Operator precedence: NOT > AND > OR.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    op_stack = []\n",
    "    precedence = {\"NOT\": 3, \"AND\": 2, \"OR\": 1}\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in {\"AND\", \"OR\", \"NOT\"}:\n",
    "            # Pop operators with higher or equal precedence\n",
    "            while (op_stack and op_stack[-1] != \"(\" and \n",
    "                   op_stack[-1] in precedence and \n",
    "                   precedence[op_stack[-1]] >= precedence[token]):\n",
    "                output.append(op_stack.pop())\n",
    "            op_stack.append(token)\n",
    "        elif token == \"(\":\n",
    "            op_stack.append(token)\n",
    "        elif token == \")\":\n",
    "            # Pop until an '(' is encountered\n",
    "            while op_stack and op_stack[-1] != \"(\":\n",
    "                output.append(op_stack.pop())\n",
    "            if op_stack and op_stack[-1] == \"(\":\n",
    "                op_stack.pop()  # Remove the '('\n",
    "            else:\n",
    "                raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        else:\n",
    "            output.append(token)\n",
    "    \n",
    "    while op_stack:\n",
    "        op = op_stack.pop()\n",
    "        if op in {\"(\", \")\"}:\n",
    "            raise ValueError(\"Mismatched parentheses in query.\")\n",
    "        output.append(op)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def evaluate_postfix(postfix_tokens, inverted_index, universal_set):\n",
    "    \"\"\"\n",
    "    Evaluates the Boolean query given in postfix notation.\n",
    "    Returns a set of document IDs matching the query.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    for token in postfix_tokens:\n",
    "        if token in {\"AND\", \"OR\", \"NOT\"}:\n",
    "            if token == \"NOT\":\n",
    "                if not stack:\n",
    "                    raise ValueError(\"Insufficient operands for NOT operator.\")\n",
    "                operand = stack.pop()\n",
    "                result = universal_set - operand\n",
    "                stack.append(result)\n",
    "            else:\n",
    "                if len(stack) < 2:\n",
    "                    raise ValueError(f\"Insufficient operands for {token} operator.\")\n",
    "                right = stack.pop()\n",
    "                left = stack.pop()\n",
    "                if token == \"AND\":\n",
    "                    result = left & right  # Intersection\n",
    "                elif token == \"OR\":\n",
    "                    result = left | right  # Union\n",
    "                stack.append(result)\n",
    "        else:\n",
    "\n",
    "            posting = inverted_index.get(token, set())\n",
    "            stack.append(posting)\n",
    "    \n",
    "    if len(stack) != 1:\n",
    "        raise ValueError(f\"Error in evaluation: stack should have exactly one element, but got {stack}\")\n",
    "    \n",
    "    return stack[0]\n",
    "\n",
    "def evaluate_boolean_query(query, inverted_index, universal_set):\n",
    "    \"\"\"\n",
    "    Processes a Boolean query:\n",
    "      1. Tokenizes the query (with stemming).\n",
    "      2. Converts it to postfix notation.\n",
    "      3. Evaluates the postfix expression.\n",
    "    Returns a set of document IDs that satisfy the query.\n",
    "    \"\"\"\n",
    "    tokens = tokenize_query(query)\n",
    "    postfix = shunting_yard(tokens)\n",
    "    result = evaluate_postfix(postfix, inverted_index, universal_set)\n",
    "    return result \n",
    "\n",
    "universal_set = set(range(1, 1461))\n",
    "\n",
    "\n",
    "queries = [\n",
    "    \"NOT class AND gam\"\n",
    "]\n",
    "converted_index = {term: set(map(int, doc_ids)) for term, doc_ids in inv_index_P.items()}\n",
    "\n",
    "for query in queries:\n",
    "    try:\n",
    "        result = evaluate_boolean_query(query, converted_index, universal_set)\n",
    "        print(f\"Query: {query}\\nMatching Documents: {result}\\n\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Query: {query}\\nError: {ve}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '5', '6', '8', '10', '11', '14', '16', '17', '18', '19', '20', '21', '22', '24', '25', '26', '28', '29', '30', '31', '34', '37', '38', '40', '42', '43', '44', '46', '47', '48', '49', '51', '52', '56', '58', '60', '61', '62', '63', '64', '65', '66', '67', '68', '70', '71', '72', '74', '76', '77', '78', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '92', '93', '94', '96', '97', '98', '99', '100', '101', '102', '103', '104', '108', '109', '110', '113', '114', '115', '116', '117', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '147', '148', '150', '151', '153', '154', '155', '156', '158', '159', '160', '161', '163', '165', '166', '168', '173', '174', '175', '176', '177', '180', '182', '185', '186', '187', '188', '189', '190', '191', '192', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '207', '208', '209', '211', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '224', '226', '227', '228', '229', '230', '232', '233', '234', '236', '237', '238', '239', '240', '241', '242', '244', '247', '249', '250', '251', '252', '253', '254', '257', '258', '259', '260', '261', '263', '264', '265', '267', '270', '271', '272', '273', '274', '275', '276', '278', '282', '284', '285', '286', '287', '288', '289', '290', '291', '292', '294', '295', '296', '297', '299', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '314', '315', '317', '318', '319', '320', '321', '323', '324', '326', '327', '328', '329', '331', '332', '333', '334', '335', '336', '337', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '356', '357', '358', '359', '361', '363', '364', '367', '368', '369', '370', '371', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '385', '386', '387', '388', '389', '390', '391', '392', '396', '397', '398', '399', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '428', '429', '430', '431', '432', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '464', '466', '467', '469', '470', '471', '472', '474', '475', '476', '477', '478', '480', '481', '482', '483', '484', '485', '486', '487', '489', '490', '492', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '511', '512', '514', '515', '516', '517', '519', '520', '521', '522', '523', '525', '526', '527', '528', '529', '530', '532', '534', '535', '536', '538', '542', '543', '544', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '557', '558', '559', '560', '561', '562', '564', '566', '567', '568', '569', '570', '571', '572', '574', '575', '576', '577', '579', '580', '581', '582', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '605', '606', '607', '608', '610', '611', '612', '614', '615', '616', '617', '620', '621', '624', '625', '627', '628', '630', '631', '632', '634', '635', '636', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '673', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '692', '693', '694', '697', '698', '700', '702', '703', '705', '706', '707', '709', '710', '714', '715', '716', '719', '720', '721', '722', '723', '724', '725', '730', '731', '733', '734', '735', '737', '738', '741', '742', '745', '746', '747', '748', '750', '751', '752', '754', '756', '758', '759', '760', '762', '764', '766', '767', '768', '770', '771', '772', '773', '776', '777', '778', '779', '781', '784', '785', '786', '789', '790', '791', '793', '794', '795', '796', '797', '798', '800', '801', '802', '803', '805', '806', '808', '809', '810', '811', '812', '813', '815', '816', '818', '819', '820', '821', '823', '824', '825', '826', '829', '830', '831', '832', '833', '835', '836', '837', '838', '839', '840', '841', '842', '843', '846', '847', '848', '849', '850', '852', '856', '860', '862', '863', '865', '870', '872', '873', '874', '875', '879', '881', '882', '884', '885', '887', '889', '891', '892', '894', '895', '896', '897', '898', '899', '902', '904', '905', '906', '908', '909', '910', '911', '912', '916', '917', '919', '920', '921', '925', '926', '928', '929', '930', '932', '933', '934', '935', '938', '939', '941', '945', '947', '948', '949', '950', '951', '952', '953', '954', '956', '957', '959', '960', '961', '962', '963', '964', '965', '966', '967', '968', '969', '970', '975', '976', '977', '978', '979', '980', '982', '983', '984', '985', '987', '991', '993', '995', '997', '1001', '1003', '1005', '1006', '1007', '1008', '1010', '1011', '1012', '1014', '1015', '1016', '1018', '1019', '1020', '1021', '1023', '1024', '1025', '1026', '1027', '1030', '1032', '1033', '1034', '1035', '1036', '1037', '1038', '1039', '1040', '1041', '1043', '1044', '1046', '1047', '1048', '1049', '1050', '1051', '1053', '1054', '1056', '1057', '1062', '1063', '1064', '1065', '1066', '1067', '1070', '1073', '1074', '1075', '1078', '1079', '1080', '1081', '1082', '1084', '1089', '1090', '1091', '1093', '1094', '1096', '1098', '1100', '1101', '1102', '1103', '1104', '1105', '1109', '1110', '1111', '1114', '1115', '1116', '1117', '1118', '1119', '1120', '1123', '1124', '1126', '1127', '1128', '1129', '1130', '1131', '1132', '1134', '1135', '1136', '1140', '1141', '1143', '1144', '1145', '1147', '1148', '1150', '1151', '1153', '1154', '1157', '1158', '1159', '1160', '1161', '1162', '1163', '1164', '1166', '1167', '1168', '1169', '1170', '1171', '1172', '1173', '1174', '1175', '1176', '1177', '1179', '1180', '1181', '1182', '1183', '1184', '1185', '1186', '1187', '1188', '1189', '1190', '1191', '1193', '1197', '1198', '1199', '1201', '1202', '1204', '1207', '1209', '1210', '1211', '1212', '1213', '1214', '1215', '1216', '1218', '1219', '1221', '1222', '1223', '1225', '1226', '1227', '1228', '1229', '1232', '1233', '1234', '1235', '1236', '1237', '1238', '1240', '1241', '1243', '1244', '1245', '1246', '1247', '1248', '1249', '1250', '1251', '1252', '1253', '1254', '1255', '1256', '1257', '1258', '1259', '1260', '1261', '1262', '1265', '1266', '1271', '1272', '1273', '1275', '1276', '1277', '1278', '1279', '1284', '1285', '1286', '1291', '1292', '1294', '1303', '1304', '1305', '1309', '1311', '1314', '1315', '1316', '1317', '1318', '1321', '1322', '1325', '1328', '1329', '1330', '1331', '1332', '1333', '1335', '1337', '1339', '1340', '1341', '1342', '1343', '1346', '1347', '1348', '1349', '1354', '1357', '1358', '1359', '1360', '1361', '1362', '1363', '1364', '1365', '1367', '1368', '1369', '1371', '1372', '1374', '1377', '1379', '1380', '1381', '1382', '1384', '1385', '1386', '1387', '1388', '1389', '1390', '1391', '1392', '1393', '1394', '1395', '1396', '1402', '1403', '1404', '1405', '1407', '1408', '1411', '1412', '1413', '1414', '1415', '1416', '1417', '1418', '1419', '1420', '1421', '1424', '1425', '1426', '1427', '1429', '1430', '1432', '1433', '1436', '1438', '1439', '1440', '1441', '1442', '1443', '1444', '1445', '1447', '1448', '1449', '1450', '1451', '1452', '1453', '1455', '1457', '1458', '1460']\n"
     ]
    }
   ],
   "source": [
    "if \"is\" in inv_index_P.keys():\n",
    "    print(inv_index_P.get(\"is\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Note on the Pseudo-Mathematics of Relevance Taube, M. Recently a number of articles, books, and reports dealing with information systems, i.e., document retrieval systems, have advanced the doctrine that such systems are to be evaluated in terms of the degree or percentage of relevancy they provide. Although there seems to be little agreement on what relevance means, and some doubt that it is quantifiable, there is, nevertheless, a growing agreement that a fixed and formal relationship exists between the relevance and the recall performance of any system.  Thus, we will find in the literature both a frankly subjective notion of relevance as reported by individual users, and equations, curves, and mathematical formulations which presumably provide numerical measures of the recall and relevance characteristics of information systems.  This phenomenon of shifting back and forth from an admittedly subjective and non-mathematical term to equations in which the same term is given a mathematical value or a mathematical definition has its ancient parallel in discussions of probability.  One cannot, of course, legislate the meaning of a term.  It all depends, as Alice pointed out, on \"who is master,\" the user or the term.  On the other hand, the use of a single term in the same document to cover two or more distinct meanings, especially when such a usage is designed to secure the acceptance of a doctrine by attributing to it mathematical validity which it does not have, represents a more serious situation than merely careless ambiguity. '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[\"28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_terms[\"28\"][\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28',\n",
       " '35',\n",
       " '42',\n",
       " '43',\n",
       " '47',\n",
       " '58',\n",
       " '61',\n",
       " '65',\n",
       " '70',\n",
       " '74',\n",
       " '84',\n",
       " '86',\n",
       " '89',\n",
       " '135',\n",
       " '151',\n",
       " '156',\n",
       " '165',\n",
       " '174',\n",
       " '186',\n",
       " '194',\n",
       " '202',\n",
       " '303',\n",
       " '319',\n",
       " '368',\n",
       " '379',\n",
       " '384',\n",
       " '386',\n",
       " '398',\n",
       " '399',\n",
       " '426',\n",
       " '444',\n",
       " '445',\n",
       " '447',\n",
       " '449',\n",
       " '456',\n",
       " '466',\n",
       " '481',\n",
       " '486',\n",
       " '487',\n",
       " '489',\n",
       " '492',\n",
       " '503',\n",
       " '506',\n",
       " '510',\n",
       " '516',\n",
       " '518',\n",
       " '519',\n",
       " '523',\n",
       " '530',\n",
       " '532',\n",
       " '553',\n",
       " '554',\n",
       " '556',\n",
       " '557',\n",
       " '562',\n",
       " '566',\n",
       " '568',\n",
       " '576',\n",
       " '603',\n",
       " '623',\n",
       " '633',\n",
       " '652',\n",
       " '659',\n",
       " '660',\n",
       " '666',\n",
       " '713',\n",
       " '733',\n",
       " '738',\n",
       " '740',\n",
       " '747',\n",
       " '754',\n",
       " '759',\n",
       " '762',\n",
       " '770',\n",
       " '773',\n",
       " '785',\n",
       " '786',\n",
       " '792',\n",
       " '797',\n",
       " '801',\n",
       " '806',\n",
       " '807',\n",
       " '810',\n",
       " '813',\n",
       " '820',\n",
       " '825',\n",
       " '826',\n",
       " '832',\n",
       " '845',\n",
       " '894',\n",
       " '934',\n",
       " '935',\n",
       " '956',\n",
       " '965',\n",
       " '966',\n",
       " '1005',\n",
       " '1038',\n",
       " '1054',\n",
       " '1091',\n",
       " '1114',\n",
       " '1119',\n",
       " '1120',\n",
       " '1124',\n",
       " '1127',\n",
       " '1138',\n",
       " '1139',\n",
       " '1146',\n",
       " '1188',\n",
       " '1195',\n",
       " '1212',\n",
       " '1213',\n",
       " '1217',\n",
       " '1230',\n",
       " '1281',\n",
       " '1339',\n",
       " '1365',\n",
       " '1398',\n",
       " '1415',\n",
       " '1427',\n",
       " '1443']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_index_P[\"relev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the inverted index\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(inverted_index, stop_words):\n",
    "    return {term: doc_ids for term, doc_ids in inverted_index.items() if term not in stop_words}\n",
    "\n",
    "inv_index_no_stopwords = remove_stopwords(inv_index_P, stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'what': 3,\n",
       "  'problem': 1,\n",
       "  'and': 1,\n",
       "  'concern': 1,\n",
       "  'are': 2,\n",
       "  'there': 1,\n",
       "  'in': 2,\n",
       "  'make': 1,\n",
       "  'up': 1,\n",
       "  'descript': 1,\n",
       "  'titl': 3,\n",
       "  'difficulti': 1,\n",
       "  'involv': 1,\n",
       "  'automat': 1,\n",
       "  'retriev': 1,\n",
       "  'articl': 2,\n",
       "  'from': 1,\n",
       "  'approxim': 1,\n",
       "  'is': 1,\n",
       "  'the': 2,\n",
       "  'usual': 1,\n",
       "  'relev': 1,\n",
       "  'of': 2,\n",
       "  'content': 1,\n",
       "  'to': 1,\n",
       "  'their': 1},\n",
       " '2': {'how': 1,\n",
       "  'can': 1,\n",
       "  'actual': 1,\n",
       "  'pertin': 1,\n",
       "  'data': 1,\n",
       "  'as': 1,\n",
       "  'oppos': 1,\n",
       "  'to': 2,\n",
       "  'refer': 1,\n",
       "  'or': 1,\n",
       "  'entir': 1,\n",
       "  'articl': 1,\n",
       "  'themselv': 1,\n",
       "  'be': 1,\n",
       "  'retriev': 1,\n",
       "  'automat': 1,\n",
       "  'in': 1,\n",
       "  'respons': 1,\n",
       "  'inform': 1,\n",
       "  'request': 1},\n",
       " '3': {'what': 1,\n",
       "  'is': 1,\n",
       "  'inform': 1,\n",
       "  'scienc': 1,\n",
       "  'give': 1,\n",
       "  'definit': 1,\n",
       "  'where': 1,\n",
       "  'possibl': 1},\n",
       " '4': {'imag': 1,\n",
       "  'recognit': 1,\n",
       "  'and': 1,\n",
       "  'ani': 1,\n",
       "  'other': 1,\n",
       "  'method': 1,\n",
       "  'of': 1,\n",
       "  'automat': 1,\n",
       "  'transform': 1,\n",
       "  'print': 1,\n",
       "  'text': 1,\n",
       "  'into': 1,\n",
       "  'computer-readi': 1,\n",
       "  'form': 1},\n",
       " '5': {'what': 2,\n",
       "  'special': 1,\n",
       "  'train': 1,\n",
       "  'will': 1,\n",
       "  'ordinari': 1,\n",
       "  'research': 1,\n",
       "  'and': 2,\n",
       "  'businessmen': 1,\n",
       "  'need': 1,\n",
       "  'for': 1,\n",
       "  'proper': 1,\n",
       "  'inform': 2,\n",
       "  'manag': 1,\n",
       "  'unobstruct': 1,\n",
       "  'use': 1,\n",
       "  'of': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 1,\n",
       "  'problem': 1,\n",
       "  'are': 1,\n",
       "  'they': 1,\n",
       "  'like': 1,\n",
       "  'to': 1,\n",
       "  'encount': 1},\n",
       " '6': {'what': 1,\n",
       "  'possibl': 1,\n",
       "  'are': 1,\n",
       "  'there': 1,\n",
       "  'for': 1,\n",
       "  'verbal': 1,\n",
       "  'commun': 2,\n",
       "  'between': 1,\n",
       "  'comput': 1,\n",
       "  'and': 1,\n",
       "  'human': 1,\n",
       "  'that': 1,\n",
       "  'is': 1,\n",
       "  'via': 1,\n",
       "  'the': 1,\n",
       "  'spoken': 1,\n",
       "  'word': 1},\n",
       " '7': {'describ': 1,\n",
       "  'present': 1,\n",
       "  'work': 1,\n",
       "  'and': 3,\n",
       "  'plan': 1,\n",
       "  'system': 1,\n",
       "  'for': 2,\n",
       "  'publish': 1,\n",
       "  'print': 1,\n",
       "  'origin': 1,\n",
       "  'paper': 1,\n",
       "  'by': 1,\n",
       "  'comput': 1,\n",
       "  'then': 1,\n",
       "  'save': 1,\n",
       "  'the': 1,\n",
       "  'byproduct': 1,\n",
       "  'articl': 1,\n",
       "  'code': 1,\n",
       "  'in': 2,\n",
       "  'data-process': 1,\n",
       "  'form': 1,\n",
       "  'further': 1,\n",
       "  'use': 1,\n",
       "  'retriev': 1},\n",
       " '8': {'describ': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'and': 1,\n",
       "  'index': 1,\n",
       "  'in': 2,\n",
       "  'other': 1,\n",
       "  'languag': 1,\n",
       "  'what': 1,\n",
       "  'bear': 1,\n",
       "  'doe': 1,\n",
       "  'it': 1,\n",
       "  'have': 1,\n",
       "  'on': 1,\n",
       "  'the': 1,\n",
       "  'scienc': 1,\n",
       "  'gener': 1},\n",
       " '9': {'what': 1,\n",
       "  'possibl': 1,\n",
       "  'are': 1,\n",
       "  'there': 1,\n",
       "  'for': 2,\n",
       "  'automat': 1,\n",
       "  'grammat': 1,\n",
       "  'and': 1,\n",
       "  'contextu': 1,\n",
       "  'analysi': 1,\n",
       "  'of': 1,\n",
       "  'articl': 1,\n",
       "  'inclus': 1,\n",
       "  'in': 1,\n",
       "  'an': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 1},\n",
       " '10': {'the': 1,\n",
       "  'use': 1,\n",
       "  'of': 1,\n",
       "  'abstract': 1,\n",
       "  'mathemat': 1,\n",
       "  'in': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'e.g': 1,\n",
       "  'group': 1,\n",
       "  'theori': 1},\n",
       " '11': {'what': 1,\n",
       "  'is': 1,\n",
       "  'the': 1,\n",
       "  'need': 1,\n",
       "  'for': 1,\n",
       "  'inform': 1,\n",
       "  'consolid': 1,\n",
       "  'evalu': 1,\n",
       "  'and': 1,\n",
       "  'retriev': 1,\n",
       "  'in': 1,\n",
       "  'scientif': 1,\n",
       "  'research': 1},\n",
       " '12': {'give': 1,\n",
       "  'method': 1,\n",
       "  'for': 1,\n",
       "  'high': 1,\n",
       "  'speed': 1,\n",
       "  'public': 1,\n",
       "  'print': 1,\n",
       "  'and': 1,\n",
       "  'distribut': 1,\n",
       "  'of': 1,\n",
       "  'scientif': 1,\n",
       "  'journal': 1},\n",
       " '13': {'what': 1,\n",
       "  'criteria': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'develop': 1,\n",
       "  'for': 1,\n",
       "  'the': 1,\n",
       "  'object': 1,\n",
       "  'evalu': 1,\n",
       "  'of': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'and': 1,\n",
       "  'dissemin': 1,\n",
       "  'system': 1},\n",
       " '14': {'what': 1,\n",
       "  'futur': 1,\n",
       "  'is': 1,\n",
       "  'there': 1,\n",
       "  'for': 1,\n",
       "  'automat': 1,\n",
       "  'medic': 1,\n",
       "  'diagnosi': 1},\n",
       " '15': {'how': 1,\n",
       "  'much': 1,\n",
       "  'do': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'and': 2,\n",
       "  'dissemin': 1,\n",
       "  'system': 1,\n",
       "  'as': 2,\n",
       "  'well': 1,\n",
       "  'autom': 1,\n",
       "  'librari': 1,\n",
       "  'cost': 1,\n",
       "  'are': 1,\n",
       "  'they': 1,\n",
       "  'worth': 1,\n",
       "  'it': 1,\n",
       "  'to': 2,\n",
       "  'the': 1,\n",
       "  'research': 1,\n",
       "  'industri': 1},\n",
       " '16': {'what': 2,\n",
       "  'system': 1,\n",
       "  'incorpor': 1,\n",
       "  'multiprogram': 1,\n",
       "  'or': 1,\n",
       "  'remot': 1,\n",
       "  'station': 1,\n",
       "  'in': 2,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'will': 1,\n",
       "  'be': 1,\n",
       "  'the': 2,\n",
       "  'extent': 1,\n",
       "  'of': 1,\n",
       "  'their': 1,\n",
       "  'use': 1,\n",
       "  'futur': 1},\n",
       " '17': {'mean': 1,\n",
       "  'of': 1,\n",
       "  'obtain': 1,\n",
       "  'larg': 1,\n",
       "  'volum': 1,\n",
       "  'high': 1,\n",
       "  'speed': 1,\n",
       "  'custom': 1,\n",
       "  'usabl': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'output': 1},\n",
       " '18': {'what': 1,\n",
       "  'method': 1,\n",
       "  'are': 1,\n",
       "  'there': 1,\n",
       "  'for': 2,\n",
       "  'encod': 1,\n",
       "  'automat': 2,\n",
       "  'match': 1,\n",
       "  'and': 1,\n",
       "  'draw': 1,\n",
       "  'structur': 2,\n",
       "  'extend': 1,\n",
       "  'in': 1,\n",
       "  'two': 1,\n",
       "  'dimens': 1,\n",
       "  'like': 1,\n",
       "  'the': 1,\n",
       "  'formula': 1,\n",
       "  'chemic': 1,\n",
       "  'compound': 1},\n",
       " '19': {'techniqu': 1,\n",
       "  'of': 1,\n",
       "  'machin': 2,\n",
       "  'match': 2,\n",
       "  'and': 2,\n",
       "  'search': 1,\n",
       "  'system': 1,\n",
       "  'code': 1,\n",
       "  'method': 1},\n",
       " '20': {'test': 1, 'autom': 1, 'inform': 1, 'system': 1},\n",
       " '21': {'the': 2,\n",
       "  'need': 1,\n",
       "  'to': 1,\n",
       "  'provid': 1,\n",
       "  'personnel': 1,\n",
       "  'for': 1,\n",
       "  'inform': 1,\n",
       "  'field': 1},\n",
       " '22': {'autom': 1, 'inform': 1, 'in': 1, 'the': 1, 'medic': 1, 'field': 1},\n",
       " '23': {'amount': 1,\n",
       "  'of': 2,\n",
       "  'use': 1,\n",
       "  'book': 1,\n",
       "  'in': 1,\n",
       "  'librari': 1,\n",
       "  'relat': 1,\n",
       "  'to': 1,\n",
       "  'need': 1,\n",
       "  'for': 1,\n",
       "  'autom': 1,\n",
       "  'inform': 1,\n",
       "  'system': 1},\n",
       " '24': {'educ': 1,\n",
       "  'and': 1,\n",
       "  'train': 3,\n",
       "  'requir': 1,\n",
       "  'for': 3,\n",
       "  'personnel': 1,\n",
       "  'in': 1,\n",
       "  'the': 1,\n",
       "  'inform': 1,\n",
       "  'field': 1,\n",
       "  'possibl': 1,\n",
       "  'thi': 2,\n",
       "  'need': 1,\n",
       "  'program': 1,\n",
       "  'provid': 1},\n",
       " '25': {'intern': 1,\n",
       "  'system': 1,\n",
       "  'for': 1,\n",
       "  'exchang': 1,\n",
       "  'and': 1,\n",
       "  'dissemin': 1,\n",
       "  'of': 1,\n",
       "  'inform': 1},\n",
       " '26': {'cost': 2,\n",
       "  'and': 1,\n",
       "  'determin': 1,\n",
       "  'of': 2,\n",
       "  'associ': 1,\n",
       "  'with': 1,\n",
       "  'system': 1,\n",
       "  'autom': 1,\n",
       "  'inform': 1},\n",
       " '27': {'computer': 2, 'inform': 1, 'retriev': 1, 'system': 2, 'index': 1},\n",
       " '28': {'computer': 1,\n",
       "  'inform': 1,\n",
       "  'system': 1,\n",
       "  'in': 1,\n",
       "  'field': 1,\n",
       "  'relat': 1,\n",
       "  'to': 1,\n",
       "  'chemistri': 1},\n",
       " '29': {'specif': 1,\n",
       "  'advantag': 1,\n",
       "  'of': 1,\n",
       "  'computer': 1,\n",
       "  'index': 1,\n",
       "  'system': 1},\n",
       " '30': {'inform': 1,\n",
       "  'dissemin': 1,\n",
       "  'by': 1,\n",
       "  'journal': 1,\n",
       "  'and': 1,\n",
       "  'period': 1},\n",
       " '31': {'inform': 1, 'system': 1, 'in': 1, 'the': 1, 'physic': 1, 'scienc': 1},\n",
       " '32': {'attempt': 1,\n",
       "  'at': 1,\n",
       "  'computer': 1,\n",
       "  'and': 3,\n",
       "  'mechan': 1,\n",
       "  'system': 2,\n",
       "  'for': 1,\n",
       "  'gener': 2,\n",
       "  'librari': 1,\n",
       "  'problem': 1,\n",
       "  'method': 1,\n",
       "  'of': 1,\n",
       "  'autom': 1,\n",
       "  'author': 1,\n",
       "  'titl': 1,\n",
       "  'index': 1},\n",
       " '33': {'retriev': 1,\n",
       "  'system': 1,\n",
       "  'which': 1,\n",
       "  'provid': 1,\n",
       "  'for': 1,\n",
       "  'the': 2,\n",
       "  'autom': 1,\n",
       "  'transmiss': 1,\n",
       "  'of': 1,\n",
       "  'inform': 1,\n",
       "  'to': 1,\n",
       "  'user': 1,\n",
       "  'from': 1,\n",
       "  'a': 1,\n",
       "  'distanc': 1},\n",
       " '34': {'method': 1,\n",
       "  'of': 1,\n",
       "  'code': 1,\n",
       "  'use': 1,\n",
       "  'in': 1,\n",
       "  'computer': 1,\n",
       "  'index': 1,\n",
       "  'system': 1},\n",
       " '35': {'govern': 1,\n",
       "  'support': 1,\n",
       "  'agenc': 1,\n",
       "  'and': 1,\n",
       "  'project': 1,\n",
       "  'deal': 1,\n",
       "  'with': 1,\n",
       "  'inform': 1,\n",
       "  'dissemin': 1},\n",
       " '36': {'what': 1,\n",
       "  'are': 1,\n",
       "  'some': 1,\n",
       "  'of': 5,\n",
       "  'the': 1,\n",
       "  'theori': 1,\n",
       "  'and': 1,\n",
       "  'practic': 1,\n",
       "  'in': 3,\n",
       "  'comput': 1,\n",
       "  'translat': 3,\n",
       "  'text': 1,\n",
       "  'from': 1,\n",
       "  'one': 1,\n",
       "  'nation': 1,\n",
       "  'languag': 2,\n",
       "  'to': 1,\n",
       "  'anoth': 1,\n",
       "  'how': 1,\n",
       "  'can': 1,\n",
       "  'machin': 1,\n",
       "  'compet': 1,\n",
       "  'with': 1,\n",
       "  'tradit': 1,\n",
       "  'method': 1,\n",
       "  'comprehend': 1,\n",
       "  'nuanc': 1,\n",
       "  'mean': 1,\n",
       "  'differ': 1,\n",
       "  'structur': 1},\n",
       " '37': {'what': 1,\n",
       "  'list': 3,\n",
       "  'of': 4,\n",
       "  'word': 2,\n",
       "  'use': 2,\n",
       "  'for': 3,\n",
       "  'index': 1,\n",
       "  'or': 2,\n",
       "  'classifi': 1,\n",
       "  'materi': 2,\n",
       "  'are': 5,\n",
       "  'avail': 1,\n",
       "  'want': 2,\n",
       "  'term': 1,\n",
       "  'that': 3,\n",
       "  'descript': 1,\n",
       "  'vocabulari': 1,\n",
       "  'particular': 1,\n",
       "  'field': 1,\n",
       "  'schedul': 1,\n",
       "  'relat': 1,\n",
       "  'to': 2,\n",
       "  'each': 1,\n",
       "  'other': 1,\n",
       "  'in': 1,\n",
       "  'meaning': 1,\n",
       "  'scheme': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'test': 1,\n",
       "  'at': 1,\n",
       "  'least': 1,\n",
       "  'some': 1,\n",
       "  'extent': 1,\n",
       "  'and': 2,\n",
       "  'found': 1,\n",
       "  'organ': 1,\n",
       "  'retriev': 1,\n",
       "  'it': 1},\n",
       " '38': {'how': 1,\n",
       "  'can': 1,\n",
       "  'access': 1,\n",
       "  'word': 3,\n",
       "  'in': 3,\n",
       "  'an': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 2,\n",
       "  'be': 3,\n",
       "  'kept': 1,\n",
       "  'up': 1,\n",
       "  'to': 2,\n",
       "  'date': 1,\n",
       "  'mean': 1,\n",
       "  'and': 3,\n",
       "  'usag': 1,\n",
       "  'often': 1,\n",
       "  'chang': 1,\n",
       "  'list': 1,\n",
       "  'must': 1,\n",
       "  'dynam': 1,\n",
       "  'current': 1,\n",
       "  'what': 1,\n",
       "  'definit': 1,\n",
       "  'of': 2,\n",
       "  'the': 1,\n",
       "  'problem': 1,\n",
       "  'progress': 1,\n",
       "  'toward': 1,\n",
       "  'solut': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'made': 1,\n",
       "  'provid': 1,\n",
       "  'necessari': 1,\n",
       "  'flexibl': 1,\n",
       "  'subject': 1,\n",
       "  'head': 1,\n",
       "  'index': 1,\n",
       "  'or': 1,\n",
       "  'other': 1,\n",
       "  'symbol': 1,\n",
       "  'use': 1,\n",
       "  'for': 1,\n",
       "  'get': 1,\n",
       "  'at': 1,\n",
       "  'store': 1,\n",
       "  'data': 1},\n",
       " '39': {'the': 5,\n",
       "  'progress': 1,\n",
       "  'of': 6,\n",
       "  'inform': 2,\n",
       "  'retriev': 1,\n",
       "  'present': 1,\n",
       "  'problem': 1,\n",
       "  'maladjust': 1,\n",
       "  'and': 7,\n",
       "  'disloc': 1,\n",
       "  'personnel': 1,\n",
       "  'train': 1,\n",
       "  'retrain': 1,\n",
       "  'peopl': 1,\n",
       "  'to': 4,\n",
       "  'use': 2,\n",
       "  'new': 1,\n",
       "  'equip': 1,\n",
       "  'is': 1,\n",
       "  'import': 1,\n",
       "  'at': 1,\n",
       "  'all': 1,\n",
       "  'level': 1,\n",
       "  'librarian': 1,\n",
       "  'assist': 1,\n",
       "  'technician': 1,\n",
       "  'student': 1,\n",
       "  'research': 1,\n",
       "  'even': 1,\n",
       "  'execut': 1,\n",
       "  'will': 1,\n",
       "  'need': 1,\n",
       "  'educ': 1,\n",
       "  'learn': 2,\n",
       "  'purpos': 1,\n",
       "  'valu': 1,\n",
       "  'system': 1,\n",
       "  'hardwar': 1,\n",
       "  'what': 1,\n",
       "  'program': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'develop': 1,\n",
       "  'chang': 1,\n",
       "  'attitud': 1,\n",
       "  'skill': 1,\n",
       "  'tradit': 1,\n",
       "  'worker': 1,\n",
       "  'help': 1,\n",
       "  'them': 1,\n",
       "  'newer': 1,\n",
       "  'techniqu': 1},\n",
       " '40': {'what': 3,\n",
       "  'is': 1,\n",
       "  'the': 3,\n",
       "  'statu': 1,\n",
       "  'of': 4,\n",
       "  'machin': 1,\n",
       "  'translat': 1,\n",
       "  'progress': 1,\n",
       "  'ha': 1,\n",
       "  'been': 2,\n",
       "  'made': 1,\n",
       "  'in': 1,\n",
       "  'use': 1,\n",
       "  'comput': 1,\n",
       "  'to': 4,\n",
       "  'transfer': 1,\n",
       "  'from': 1,\n",
       "  'one': 1,\n",
       "  'languag': 1,\n",
       "  'anoth': 1,\n",
       "  'with': 1,\n",
       "  'some': 1,\n",
       "  'degre': 1,\n",
       "  'autom': 1,\n",
       "  'problem': 1,\n",
       "  'and': 2,\n",
       "  'stumbl': 1,\n",
       "  'block': 1,\n",
       "  'have': 1,\n",
       "  'found': 1,\n",
       "  'are': 1,\n",
       "  'they': 1,\n",
       "  'consid': 1,\n",
       "  'be': 1,\n",
       "  'insurmount': 1,\n",
       "  'limit': 1,\n",
       "  'or': 1,\n",
       "  'onli': 1,\n",
       "  'challeng': 1,\n",
       "  'field': 1,\n",
       "  'document': 1,\n",
       "  'on': 1,\n",
       "  'an': 1,\n",
       "  'intern': 1,\n",
       "  'scale': 1},\n",
       " '41': {'is': 3,\n",
       "  'alphabet': 3,\n",
       "  'order': 3,\n",
       "  'of': 5,\n",
       "  'materi': 2,\n",
       "  'consid': 1,\n",
       "  'to': 3,\n",
       "  'be': 1,\n",
       "  'a': 3,\n",
       "  'use': 1,\n",
       "  'tool': 1,\n",
       "  'in': 2,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'what': 1,\n",
       "  'studi': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'done': 1,\n",
       "  'compar': 1,\n",
       "  'the': 1,\n",
       "  'effect': 1,\n",
       "  'with': 1,\n",
       "  'other': 1,\n",
       "  'organ': 1,\n",
       "  'scheme': 1,\n",
       "  'there': 2,\n",
       "  'gener': 1,\n",
       "  'accept': 1,\n",
       "  'form': 2,\n",
       "  'arrang': 1,\n",
       "  'and': 1,\n",
       "  'an': 1,\n",
       "  'easi': 1,\n",
       "  'way': 1,\n",
       "  'achiev': 1,\n",
       "  'thi': 1,\n",
       "  'without': 1,\n",
       "  'go': 1,\n",
       "  'great': 1,\n",
       "  'amount': 1,\n",
       "  'effort': 1},\n",
       " '42': {'the': 4,\n",
       "  'averag': 1,\n",
       "  'student': 1,\n",
       "  'or': 1,\n",
       "  'research': 1,\n",
       "  'ha': 1,\n",
       "  'difficulti': 1,\n",
       "  'in': 1,\n",
       "  'comprehend': 1,\n",
       "  'vocabulari': 1,\n",
       "  'of': 3,\n",
       "  'inform': 2,\n",
       "  'retriev': 2,\n",
       "  'it': 2,\n",
       "  'appear': 1,\n",
       "  'import': 2,\n",
       "  'that': 1,\n",
       "  'thi': 1,\n",
       "  'new': 1,\n",
       "  'field': 1,\n",
       "  'be': 2,\n",
       "  'understood': 1,\n",
       "  'befor': 1,\n",
       "  'is': 1,\n",
       "  'to': 1,\n",
       "  'fulli': 1,\n",
       "  'accept': 1,\n",
       "  'what': 1,\n",
       "  'basic': 1,\n",
       "  'articl': 1,\n",
       "  'would': 1,\n",
       "  'provid': 1,\n",
       "  'an': 1,\n",
       "  'understand': 1,\n",
       "  'variou': 1,\n",
       "  'aspect': 1,\n",
       "  'storag': 1,\n",
       "  'and': 1},\n",
       " '43': {'the': 7,\n",
       "  'difficulti': 1,\n",
       "  'encount': 1,\n",
       "  'in': 4,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 1,\n",
       "  'are': 1,\n",
       "  'often': 1,\n",
       "  'less': 1,\n",
       "  'relat': 1,\n",
       "  'to': 4,\n",
       "  'equip': 2,\n",
       "  'use': 1,\n",
       "  'than': 1,\n",
       "  'failur': 1,\n",
       "  'plan': 1,\n",
       "  'adequ': 1,\n",
       "  'for': 1,\n",
       "  'document': 1,\n",
       "  'analysi': 1,\n",
       "  'index': 1,\n",
       "  'and': 2,\n",
       "  'machin': 1,\n",
       "  'code': 1,\n",
       "  'posit': 1,\n",
       "  'of': 2,\n",
       "  'programm': 1,\n",
       "  'is': 1,\n",
       "  'take': 1,\n",
       "  'a': 2,\n",
       "  'problem': 1,\n",
       "  'write': 1,\n",
       "  'it': 1,\n",
       "  'way': 1,\n",
       "  'which': 1,\n",
       "  'will': 1,\n",
       "  'understand': 1,\n",
       "  'what': 1,\n",
       "  'articl': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'written': 1,\n",
       "  'describ': 1,\n",
       "  'research': 1,\n",
       "  'maxim': 1,\n",
       "  'effect': 1,\n",
       "  'program': 1},\n",
       " '44': {'there': 1,\n",
       "  'are': 1,\n",
       "  'present': 1,\n",
       "  'fifti': 1,\n",
       "  'to': 3,\n",
       "  'one': 2,\n",
       "  'hundr': 1,\n",
       "  'technic': 2,\n",
       "  'journal': 3,\n",
       "  'be': 1,\n",
       "  'publish': 2,\n",
       "  'on': 1,\n",
       "  'the': 2,\n",
       "  'averag': 1,\n",
       "  'two': 2,\n",
       "  'new': 1,\n",
       "  'appear': 2,\n",
       "  'everi': 2,\n",
       "  'day': 1,\n",
       "  'in': 2,\n",
       "  'mani': 1,\n",
       "  'million': 1,\n",
       "  'articl': 1,\n",
       "  'year': 1,\n",
       "  'what': 1,\n",
       "  'attempt': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'made': 1,\n",
       "  'cope': 1,\n",
       "  'with': 1,\n",
       "  'thi': 1,\n",
       "  'amount': 1,\n",
       "  'of': 2,\n",
       "  'scientif': 1,\n",
       "  'and': 2,\n",
       "  'public': 1,\n",
       "  'term': 1,\n",
       "  'analysi': 1,\n",
       "  'control': 1,\n",
       "  'storag': 1,\n",
       "  'retriev': 1},\n",
       " '45': {'i': 1,\n",
       "  'am': 1,\n",
       "  'look': 1,\n",
       "  'for': 2,\n",
       "  'inform': 2,\n",
       "  'about': 1,\n",
       "  'the': 4,\n",
       "  'impact': 1,\n",
       "  'of': 5,\n",
       "  'autom': 5,\n",
       "  'on': 1,\n",
       "  'librari': 4,\n",
       "  'and': 3,\n",
       "  'it': 1,\n",
       "  'signific': 1,\n",
       "  'in': 2,\n",
       "  'gener': 1,\n",
       "  'thi': 2,\n",
       "  'includ': 1,\n",
       "  'increas': 1,\n",
       "  'import': 1,\n",
       "  'view': 1,\n",
       "  'prolifer': 1,\n",
       "  'today': 1,\n",
       "  'how': 3,\n",
       "  'can': 1,\n",
       "  'help': 1,\n",
       "  'cope': 1,\n",
       "  'with': 1,\n",
       "  'problem': 1,\n",
       "  'will': 1,\n",
       "  'affect': 1,\n",
       "  'should': 1,\n",
       "  'they': 1,\n",
       "  'react': 1,\n",
       "  'to': 1,\n",
       "  'idea': 1},\n",
       " '46': {'i': 2,\n",
       "  'am': 1,\n",
       "  'seek': 1,\n",
       "  'inform': 1,\n",
       "  'on': 2,\n",
       "  'the': 3,\n",
       "  'use': 1,\n",
       "  'of': 6,\n",
       "  'data': 1,\n",
       "  'process': 2,\n",
       "  'in': 4,\n",
       "  'librari': 5,\n",
       "  'and': 6,\n",
       "  'mechan': 1,\n",
       "  'routin': 1,\n",
       "  'procedur': 1,\n",
       "  'would': 1,\n",
       "  'like': 1,\n",
       "  'descript': 2,\n",
       "  'both': 2,\n",
       "  'gener': 1,\n",
       "  'specif': 1,\n",
       "  'applic': 1,\n",
       "  'autom': 1,\n",
       "  'such': 1,\n",
       "  'area': 1,\n",
       "  'as': 1,\n",
       "  'circul': 1,\n",
       "  'catalog': 1,\n",
       "  'acquisit': 1,\n",
       "  'serial': 1,\n",
       "  'record': 1,\n",
       "  'other': 1,\n",
       "  'record-keep': 1,\n",
       "  'exampl': 1,\n",
       "  'should': 1,\n",
       "  'be': 2,\n",
       "  'base': 1,\n",
       "  'oper': 2,\n",
       "  'a': 3,\n",
       "  'convent': 1,\n",
       "  'public': 2,\n",
       "  'or': 3,\n",
       "  'univers': 2,\n",
       "  'practic': 1,\n",
       "  'special': 1,\n",
       "  'which': 1,\n",
       "  'could': 1,\n",
       "  'also': 1,\n",
       "  'appli': 1,\n",
       "  'give': 1,\n",
       "  'equip': 1,\n",
       "  'present': 1,\n",
       "  'project': 1},\n",
       " '47': {'is': 4,\n",
       "  'there': 3,\n",
       "  'ani': 2,\n",
       "  'establish': 1,\n",
       "  'mean': 1,\n",
       "  'at': 1,\n",
       "  'present': 1,\n",
       "  'for': 1,\n",
       "  'an': 2,\n",
       "  'intern': 3,\n",
       "  'exchang': 2,\n",
       "  'of': 4,\n",
       "  'materi': 2,\n",
       "  'about': 1,\n",
       "  'inform': 2,\n",
       "  'retriev': 2,\n",
       "  'if': 2,\n",
       "  'doe': 1,\n",
       "  'it': 1,\n",
       "  'take': 1,\n",
       "  'the': 2,\n",
       "  'form': 1,\n",
       "  'agenc': 1,\n",
       "  'or': 1,\n",
       "  'center': 1,\n",
       "  'which': 1,\n",
       "  'regularli': 1,\n",
       "  'distribut': 1,\n",
       "  'method': 1,\n",
       "  'and': 2,\n",
       "  'research': 1,\n",
       "  'result': 1,\n",
       "  'not': 1,\n",
       "  'in': 1,\n",
       "  'what': 2,\n",
       "  'way': 1,\n",
       "  'ha': 1,\n",
       "  'thi': 1,\n",
       "  'cross': 1,\n",
       "  'nation': 1,\n",
       "  'boundari': 1,\n",
       "  'seem': 1,\n",
       "  'to': 2,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'some': 2,\n",
       "  'problem': 2,\n",
       "  'block': 1,\n",
       "  'a': 1,\n",
       "  'better': 1,\n",
       "  'effort': 1,\n",
       "  'be': 1,\n",
       "  'made': 1,\n",
       "  'solv': 1,\n",
       "  'those': 1},\n",
       " '48': {'inform': 4,\n",
       "  'retriev': 4,\n",
       "  'is': 3,\n",
       "  'still': 2,\n",
       "  'such': 2,\n",
       "  'a': 3,\n",
       "  'new': 1,\n",
       "  'and': 3,\n",
       "  'experiment': 1,\n",
       "  'field': 2,\n",
       "  'that': 1,\n",
       "  'line': 1,\n",
       "  'distinguish': 1,\n",
       "  'research': 4,\n",
       "  'practic': 1,\n",
       "  'often': 1,\n",
       "  'difficult': 1,\n",
       "  'even': 1,\n",
       "  'imposs': 1,\n",
       "  'to': 2,\n",
       "  'draw': 1,\n",
       "  'are': 2,\n",
       "  'there': 1,\n",
       "  'howev': 1,\n",
       "  'actual': 1,\n",
       "  'center': 1,\n",
       "  'of': 2,\n",
       "  'on': 1,\n",
       "  'if': 1,\n",
       "  'so': 1,\n",
       "  'in': 2,\n",
       "  'which': 1,\n",
       "  'countri': 1,\n",
       "  'they': 1,\n",
       "  'locat': 1,\n",
       "  'who': 1,\n",
       "  'support': 1,\n",
       "  'them': 1,\n",
       "  'govern': 1,\n",
       "  'busi': 1,\n",
       "  'univers': 1,\n",
       "  'or': 2,\n",
       "  'librari': 2,\n",
       "  'can': 1,\n",
       "  'as': 2,\n",
       "  'special': 1,\n",
       "  'disciplin': 1,\n",
       "  'be': 2,\n",
       "  'said': 1,\n",
       "  'emerg': 1,\n",
       "  'it': 1,\n",
       "  'an': 1,\n",
       "  'amalgam': 1,\n",
       "  'skill': 1,\n",
       "  'from': 1,\n",
       "  'other': 2,\n",
       "  'mathemat': 1,\n",
       "  'engin': 1,\n",
       "  'scienc': 1,\n",
       "  'word': 1,\n",
       "  'tell': 1,\n",
       "  'me': 1,\n",
       "  'about': 1},\n",
       " '49': {'most': 1,\n",
       "  'resourc': 1,\n",
       "  'have': 5,\n",
       "  'been': 5,\n",
       "  'spent': 1,\n",
       "  'on': 1,\n",
       "  'appli': 1,\n",
       "  'inform': 3,\n",
       "  'retriev': 3,\n",
       "  'techniqu': 2,\n",
       "  'to': 1,\n",
       "  'the': 6,\n",
       "  'physic': 1,\n",
       "  'and': 3,\n",
       "  'medic': 1,\n",
       "  'scienc': 3,\n",
       "  'but': 1,\n",
       "  'ha': 1,\n",
       "  'use': 1,\n",
       "  'at': 2,\n",
       "  'all': 2,\n",
       "  'in': 2,\n",
       "  'natur': 1,\n",
       "  'social': 1,\n",
       "  'human': 1,\n",
       "  'if': 2,\n",
       "  'so': 1,\n",
       "  'what': 2,\n",
       "  'some': 1,\n",
       "  'of': 3,\n",
       "  'problem': 1,\n",
       "  'which': 1,\n",
       "  'encount': 1,\n",
       "  'with': 1,\n",
       "  'these': 3,\n",
       "  'subject': 2,\n",
       "  'area': 3,\n",
       "  'how': 1,\n",
       "  'they': 1,\n",
       "  'solv': 1,\n",
       "  'characterist': 1,\n",
       "  'necessit': 1,\n",
       "  'develop': 1,\n",
       "  'new': 1,\n",
       "  'are': 1,\n",
       "  'prospct': 1,\n",
       "  'for': 1,\n",
       "  'futur': 1,\n",
       "  'machin': 1,\n",
       "  'control': 1},\n",
       " '50': {'is': 4,\n",
       "  'there': 3,\n",
       "  'ani': 1,\n",
       "  'use': 3,\n",
       "  'for': 1,\n",
       "  'tradit': 1,\n",
       "  'classif': 3,\n",
       "  'scheme': 4,\n",
       "  'ddc': 1,\n",
       "  'udc': 1,\n",
       "  'lc': 1,\n",
       "  'etc': 1,\n",
       "  'in': 2,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 2,\n",
       "  'if': 2,\n",
       "  'which': 2,\n",
       "  'appear': 2,\n",
       "  'most': 1,\n",
       "  'suit': 2,\n",
       "  'to': 3,\n",
       "  'machin': 3,\n",
       "  'and': 1,\n",
       "  'where': 1,\n",
       "  'ha': 2,\n",
       "  'it': 1,\n",
       "  'been': 2,\n",
       "  'appli': 1,\n",
       "  'not': 1,\n",
       "  'whi': 1,\n",
       "  'are': 1,\n",
       "  'these': 1,\n",
       "  'irrelev': 1,\n",
       "  'research': 1,\n",
       "  'shown': 1,\n",
       "  'that': 1,\n",
       "  'a': 1,\n",
       "  'subject': 1,\n",
       "  'of': 1,\n",
       "  'knowledg': 1,\n",
       "  'complet': 1,\n",
       "  'unnecessari': 1,\n",
       "  'or': 1,\n",
       "  'have': 1,\n",
       "  'new': 1,\n",
       "  'devis': 1,\n",
       "  'be': 1,\n",
       "  'more': 1},\n",
       " '51': {'coordin': 1,\n",
       "  'index': 2,\n",
       "  'util': 1,\n",
       "  'descriptor': 3,\n",
       "  'for': 2,\n",
       "  'control': 1,\n",
       "  'languag': 1,\n",
       "  'of': 2,\n",
       "  'what': 1,\n",
       "  'use': 2,\n",
       "  'are': 1,\n",
       "  'in': 2,\n",
       "  'the': 1,\n",
       "  'construct': 1,\n",
       "  'an': 2,\n",
       "  'how': 1,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'search': 1,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 1},\n",
       " '52': {'what': 3,\n",
       "  'are': 2,\n",
       "  'the': 4,\n",
       "  'characterist': 1,\n",
       "  'of': 4,\n",
       "  'medlar': 2,\n",
       "  'medic': 2,\n",
       "  'literatur': 1,\n",
       "  'analysi': 1,\n",
       "  'and': 3,\n",
       "  'retriev': 1,\n",
       "  'system': 2,\n",
       "  'project': 2,\n",
       "  'which': 1,\n",
       "  'ha': 1,\n",
       "  'been': 1,\n",
       "  'undertaken': 1,\n",
       "  'by': 1,\n",
       "  'nation': 1,\n",
       "  'librari': 1,\n",
       "  'medicin': 1,\n",
       "  'how': 1,\n",
       "  'doe': 1,\n",
       "  'it': 2,\n",
       "  'index': 3,\n",
       "  'current': 1,\n",
       "  'journal': 1,\n",
       "  'relat': 1,\n",
       "  'is': 1,\n",
       "  'thi': 1,\n",
       "  'to': 1,\n",
       "  'medicu': 1,\n",
       "  'major': 2,\n",
       "  'compon': 1,\n",
       "  'oper': 1,\n",
       "  'detail': 1},\n",
       " '53': {'how': 1,\n",
       "  'can': 2,\n",
       "  'the': 4,\n",
       "  'comput': 2,\n",
       "  'be': 2,\n",
       "  'use': 4,\n",
       "  'in': 5,\n",
       "  'medic': 1,\n",
       "  'scienc': 1,\n",
       "  'for': 2,\n",
       "  'diagnost': 1,\n",
       "  'and': 1,\n",
       "  'clinic': 2,\n",
       "  'record': 2,\n",
       "  'keep': 1,\n",
       "  'purpos': 2,\n",
       "  'have': 3,\n",
       "  'ani': 1,\n",
       "  'program': 1,\n",
       "  'of': 4,\n",
       "  'autom': 3,\n",
       "  'been': 3,\n",
       "  'tri': 1,\n",
       "  'hospit': 1,\n",
       "  'if': 1,\n",
       "  'so': 1,\n",
       "  'what': 4,\n",
       "  'result': 1,\n",
       "  'problem': 1,\n",
       "  'encount': 1,\n",
       "  'medicin': 2,\n",
       "  'an': 1,\n",
       "  'system': 1,\n",
       "  'are': 1,\n",
       "  'other': 1,\n",
       "  'possibl': 1},\n",
       " '54': {'what': 2,\n",
       "  'is': 1,\n",
       "  'the': 6,\n",
       "  'effect': 2,\n",
       "  'on': 2,\n",
       "  'librarian': 3,\n",
       "  'of': 4,\n",
       "  'autom': 2,\n",
       "  'note': 1,\n",
       "  'new': 1,\n",
       "  'type': 1,\n",
       "  'technolog': 1,\n",
       "  'to': 2,\n",
       "  'be': 2,\n",
       "  'use': 1,\n",
       "  'in': 1,\n",
       "  'librari': 1,\n",
       "  'which': 1,\n",
       "  'will': 1,\n",
       "  'have': 2,\n",
       "  'an': 1,\n",
       "  'statu': 1,\n",
       "  'posit': 1,\n",
       "  'and': 1,\n",
       "  'function': 1,\n",
       "  'chang': 1,\n",
       "  'are': 1,\n",
       "  'contempl': 1,\n",
       "  'or': 1,\n",
       "  'been': 1,\n",
       "  'initi': 1,\n",
       "  'introduc': 1,\n",
       "  'into': 1,\n",
       "  'educ': 1},\n",
       " '55': {'what': 2,\n",
       "  'are': 2,\n",
       "  'the': 3,\n",
       "  'aim': 1,\n",
       "  'and': 2,\n",
       "  'object': 1,\n",
       "  'of': 2,\n",
       "  'medic': 1,\n",
       "  'literatur': 1,\n",
       "  'analysi': 1,\n",
       "  'retriev': 2,\n",
       "  'system': 2,\n",
       "  'medlar': 3,\n",
       "  'how': 1,\n",
       "  'doe': 1,\n",
       "  'oper': 1,\n",
       "  'possibl': 1,\n",
       "  'applic': 1,\n",
       "  'to': 1,\n",
       "  'futur': 1,\n",
       "  'inform': 1},\n",
       " '56': {'the': 5,\n",
       "  'standard': 1,\n",
       "  'method': 1,\n",
       "  'of': 2,\n",
       "  'find': 1,\n",
       "  'inform': 2,\n",
       "  'in': 1,\n",
       "  'today': 1,\n",
       "  \"'s\": 1,\n",
       "  'librari': 1,\n",
       "  'is': 1,\n",
       "  'through': 1,\n",
       "  'use': 2,\n",
       "  'alphabet': 1,\n",
       "  'arrang': 1,\n",
       "  'card': 1,\n",
       "  'catalog': 2,\n",
       "  'or': 2,\n",
       "  'classifi': 1,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'a': 1,\n",
       "  'classif': 1,\n",
       "  'system': 2,\n",
       "  'such': 1,\n",
       "  'as': 1,\n",
       "  'dc': 1,\n",
       "  'lc': 1,\n",
       "  'can': 1,\n",
       "  'these': 1,\n",
       "  'be': 1,\n",
       "  'modifi': 1,\n",
       "  'for': 1,\n",
       "  'with': 1,\n",
       "  'autom': 1,\n",
       "  'retriev': 1},\n",
       " '57': {'in': 7,\n",
       "  'catalog': 1,\n",
       "  'which': 1,\n",
       "  'are': 1,\n",
       "  'either': 1,\n",
       "  'arrang': 2,\n",
       "  'alphabet': 1,\n",
       "  'or': 2,\n",
       "  'by': 1,\n",
       "  'classif': 1,\n",
       "  'number': 1,\n",
       "  'the': 3,\n",
       "  'lc': 2,\n",
       "  'entri': 2,\n",
       "  'print': 1,\n",
       "  'readabl': 1,\n",
       "  'languag': 2,\n",
       "  'is': 1,\n",
       "  'ultim': 1,\n",
       "  'import': 1,\n",
       "  'becaus': 1,\n",
       "  'individu': 1,\n",
       "  'look': 1,\n",
       "  'for': 1,\n",
       "  'inform': 1,\n",
       "  'ha': 1,\n",
       "  'a': 1,\n",
       "  'definit': 1,\n",
       "  'author': 1,\n",
       "  'titl': 1,\n",
       "  'subject': 2,\n",
       "  'phrase': 1,\n",
       "  'hi': 1,\n",
       "  'probabl': 1,\n",
       "  'english': 1,\n",
       "  'our': 1,\n",
       "  'case': 1,\n",
       "  'mind': 1,\n",
       "  'will': 1,\n",
       "  'and': 1,\n",
       "  'head': 1,\n",
       "  'be': 1,\n",
       "  'use': 1,\n",
       "  'same': 1,\n",
       "  'manner': 1,\n",
       "  'autom': 1,\n",
       "  'system': 1},\n",
       " '58': {'direct': 1,\n",
       "  'in': 4,\n",
       "  'librari': 4,\n",
       "  'network': 3,\n",
       "  'bibliograph': 1,\n",
       "  'control': 1,\n",
       "  'befor': 1,\n",
       "  'and': 4,\n",
       "  'after': 1,\n",
       "  'marc': 1,\n",
       "  'is': 2,\n",
       "  'review': 1,\n",
       "  'the': 7,\n",
       "  'capabl': 1,\n",
       "  'of': 3,\n",
       "  'key': 1,\n",
       "  'into': 1,\n",
       "  'onlin': 1,\n",
       "  'system': 1,\n",
       "  'brought': 2,\n",
       "  'an': 1,\n",
       "  'interdepend': 1,\n",
       "  'among': 2,\n",
       "  'servic': 2,\n",
       "  'center': 1,\n",
       "  'that': 3,\n",
       "  'mediat': 1,\n",
       "  'between': 1,\n",
       "  'them': 1,\n",
       "  'larg': 1,\n",
       "  'util': 1,\n",
       "  'process': 1,\n",
       "  'distribut': 1,\n",
       "  'data': 1,\n",
       "  'from': 1,\n",
       "  'thi': 2,\n",
       "  'ha': 3,\n",
       "  'develop': 3,\n",
       "  'basic': 1,\n",
       "  'structur': 1,\n",
       "  'unit': 1,\n",
       "  'state': 1,\n",
       "  'independ': 1,\n",
       "  'major': 1,\n",
       "  'problem': 1,\n",
       "  'standard': 1,\n",
       "  'coordin': 2,\n",
       "  'author': 1,\n",
       "  'point': 1,\n",
       "  'out': 1,\n",
       "  'while': 1,\n",
       "  'technolog': 1,\n",
       "  'led': 1,\n",
       "  'toward': 2,\n",
       "  'central': 1,\n",
       "  'autom': 1,\n",
       "  'new': 2,\n",
       "  'are': 1,\n",
       "  'now': 1,\n",
       "  'push': 1,\n",
       "  'decentr': 1,\n",
       "  'a': 1,\n",
       "  'requir': 1,\n",
       "  'to': 1,\n",
       "  'avoid': 1,\n",
       "  'fragment': 1,\n",
       "  'environ': 1},\n",
       " '59': {'perform': 4,\n",
       "  'test': 3,\n",
       "  'of': 7,\n",
       "  'a': 4,\n",
       "  'book': 3,\n",
       "  'and': 3,\n",
       "  'it': 3,\n",
       "  'index': 3,\n",
       "  'as': 2,\n",
       "  'inform': 1,\n",
       "  'retriev': 4,\n",
       "  'system': 2,\n",
       "  'the': 9,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'measur': 2,\n",
       "  'in': 2,\n",
       "  'term': 1,\n",
       "  'their': 2,\n",
       "  'abil': 3,\n",
       "  'to': 6,\n",
       "  'direct': 1,\n",
       "  'user': 1,\n",
       "  'select': 1,\n",
       "  'text': 1,\n",
       "  'materi': 1,\n",
       "  'whose': 1,\n",
       "  'ident': 1,\n",
       "  'but': 2,\n",
       "  'not': 2,\n",
       "  'locat': 1,\n",
       "  'is': 3,\n",
       "  'known': 1,\n",
       "  'method': 3,\n",
       "  'requir': 1,\n",
       "  'human': 1,\n",
       "  'searcher': 1,\n",
       "  'base': 1,\n",
       "  'search': 1,\n",
       "  'strategi': 1,\n",
       "  'on': 2,\n",
       "  'actual': 1,\n",
       "  'passag': 1,\n",
       "  'from': 1,\n",
       "  'rather': 1,\n",
       "  'than': 1,\n",
       "  'queri': 1,\n",
       "  'natur': 1,\n",
       "  'or': 2,\n",
       "  'contriv': 1,\n",
       "  'circumv': 1,\n",
       "  'need': 1,\n",
       "  'for': 2,\n",
       "  'relev': 1,\n",
       "  'judgement': 1,\n",
       "  'still': 1,\n",
       "  'yield': 2,\n",
       "  'indic': 1,\n",
       "  'that': 1,\n",
       "  'correspond': 1,\n",
       "  'approxim': 1,\n",
       "  'recal': 1,\n",
       "  'precis': 1,\n",
       "  'ratio': 1,\n",
       "  'larg': 1,\n",
       "  'document': 1,\n",
       "  'evalu': 1,\n",
       "  'preliminari': 1,\n",
       "  'applic': 1,\n",
       "  'subject': 1,\n",
       "  'two': 1,\n",
       "  'major': 1,\n",
       "  'encyclopedia': 2,\n",
       "  'show': 1,\n",
       "  'one': 1,\n",
       "  'appar': 1,\n",
       "  'superior': 1,\n",
       "  'both': 1,\n",
       "  'find': 1,\n",
       "  'discrimin': 1,\n",
       "  'present': 1,\n",
       "  'best': 1,\n",
       "  'suit': 1,\n",
       "  'compar': 1,\n",
       "  'sinc': 1,\n",
       "  'absolut': 1,\n",
       "  'reproduc': 1,\n",
       "  'yet': 1,\n",
       "  'establish': 1},\n",
       " '60': {'the': 12,\n",
       "  'combin': 1,\n",
       "  'use': 2,\n",
       "  'of': 8,\n",
       "  'bibliograph': 4,\n",
       "  'coupl': 4,\n",
       "  'and': 5,\n",
       "  'cocit': 4,\n",
       "  'for': 2,\n",
       "  'document': 3,\n",
       "  'retriev': 4,\n",
       "  'a': 2,\n",
       "  'linkag': 2,\n",
       "  'similar': 4,\n",
       "  'measur': 6,\n",
       "  'which': 1,\n",
       "  'take': 1,\n",
       "  'into': 1,\n",
       "  'account': 1,\n",
       "  'both': 2,\n",
       "  'their': 1,\n",
       "  'cite': 2,\n",
       "  'paper': 6,\n",
       "  'produc': 2,\n",
       "  'improv': 1,\n",
       "  'over': 1,\n",
       "  'base': 1,\n",
       "  'onli': 1,\n",
       "  'on': 1,\n",
       "  'test': 1,\n",
       "  'collect': 1,\n",
       "  'consist': 1,\n",
       "  '1712': 1,\n",
       "  'whose': 1,\n",
       "  'relev': 4,\n",
       "  'to': 4,\n",
       "  'specif': 1,\n",
       "  'queri': 2,\n",
       "  'had': 1,\n",
       "  'been': 1,\n",
       "  'judg': 1,\n",
       "  'by': 2,\n",
       "  'user': 2,\n",
       "  'evalu': 2,\n",
       "  'effect': 1,\n",
       "  'data': 2,\n",
       "  'we': 2,\n",
       "  'calcul': 1,\n",
       "  'each': 2,\n",
       "  'two': 2,\n",
       "  'between': 1,\n",
       "  'everi': 1,\n",
       "  'other': 1,\n",
       "  'were': 1,\n",
       "  'then': 2,\n",
       "  'sort': 1,\n",
       "  'order': 1,\n",
       "  'list': 1,\n",
       "  'compar': 1,\n",
       "  'result': 2,\n",
       "  'predict': 1,\n",
       "  'partial': 1,\n",
       "  'non-relev': 1,\n",
       "  \"'s\": 1,\n",
       "  'same': 1,\n",
       "  'overal': 1,\n",
       "  'chang': 1,\n",
       "  'from': 1,\n",
       "  'repres': 1,\n",
       "  'introduct': 1,\n",
       "  'in': 1,\n",
       "  'better': 1,\n",
       "  'perform': 1},\n",
       " '61': {'search': 4,\n",
       "  'bias': 4,\n",
       "  'in': 2,\n",
       "  'larg': 3,\n",
       "  'interact': 3,\n",
       "  'document': 3,\n",
       "  'retriev': 2,\n",
       "  'system': 3,\n",
       "  'the': 4,\n",
       "  'way': 1,\n",
       "  'that': 3,\n",
       "  'individu': 1,\n",
       "  'construct': 2,\n",
       "  'and': 4,\n",
       "  'modifi': 2,\n",
       "  'queri': 2,\n",
       "  'on': 3,\n",
       "  'a': 3,\n",
       "  'is': 2,\n",
       "  'subject': 2,\n",
       "  'to': 4,\n",
       "  'systemat': 1,\n",
       "  'similar': 1,\n",
       "  'those': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'demonstr': 1,\n",
       "  'experi': 1,\n",
       "  'judgement': 1,\n",
       "  'under': 1,\n",
       "  'uncertainti': 1,\n",
       "  'these': 2,\n",
       "  'are': 1,\n",
       "  'share': 1,\n",
       "  'by': 1,\n",
       "  'both': 1,\n",
       "  'naiv': 1,\n",
       "  'sophist': 1,\n",
       "  'caus': 1,\n",
       "  'inquir': 2,\n",
       "  'for': 1,\n",
       "  'ineffici': 1,\n",
       "  'algorithm': 1,\n",
       "  'suggest': 1,\n",
       "  'help': 1,\n",
       "  'avoid': 1,\n",
       "  'effect': 1,\n",
       "  'of': 1},\n",
       " '62': {'fuzzi': 4,\n",
       "  'request': 4,\n",
       "  'an': 1,\n",
       "  'approach': 1,\n",
       "  'to': 5,\n",
       "  'weight': 2,\n",
       "  'boolean': 5,\n",
       "  'search': 1,\n",
       "  'thi': 1,\n",
       "  'articl': 1,\n",
       "  'concern': 1,\n",
       "  'the': 9,\n",
       "  'problem': 1,\n",
       "  'of': 9,\n",
       "  'how': 1,\n",
       "  'permit': 1,\n",
       "  'a': 5,\n",
       "  'patron': 1,\n",
       "  'repres': 1,\n",
       "  'rel': 1,\n",
       "  'import': 1,\n",
       "  'variou': 1,\n",
       "  'index': 2,\n",
       "  'term': 2,\n",
       "  'in': 2,\n",
       "  'while': 1,\n",
       "  'retain': 2,\n",
       "  'desir': 1,\n",
       "  'properti': 2,\n",
       "  'system': 4,\n",
       "  'charact': 1,\n",
       "  'classic': 1,\n",
       "  'is': 2,\n",
       "  'review': 1,\n",
       "  'and': 2,\n",
       "  'relat': 1,\n",
       "  'notion': 1,\n",
       "  'set': 2,\n",
       "  'concept': 2,\n",
       "  'then': 1,\n",
       "  'form': 1,\n",
       "  'basi': 1,\n",
       "  'which': 1,\n",
       "  'are': 2,\n",
       "  'assign': 1,\n",
       "  'ther': 1,\n",
       "  'such': 2,\n",
       "  'discuss': 1,\n",
       "  'it': 1,\n",
       "  'shown': 1,\n",
       "  'that': 1,\n",
       "  'manipul': 1,\n",
       "  'tradit': 1},\n",
       " '63': {'featur': 3,\n",
       "  'comparison': 1,\n",
       "  'of': 5,\n",
       "  'an': 2,\n",
       "  'in-hous': 5,\n",
       "  'inform': 2,\n",
       "  'retriev': 1,\n",
       "  'system': 7,\n",
       "  'with': 1,\n",
       "  'a': 5,\n",
       "  'commerci': 4,\n",
       "  'search': 4,\n",
       "  'servic': 1,\n",
       "  'avail': 1,\n",
       "  'onlin': 2,\n",
       "  'wa': 1,\n",
       "  'use': 3,\n",
       "  'as': 3,\n",
       "  'standard': 2,\n",
       "  'for': 3,\n",
       "  'compar': 2,\n",
       "  'and': 5,\n",
       "  'evalu': 3,\n",
       "  'base': 1,\n",
       "  'on': 2,\n",
       "  'automat': 1,\n",
       "  'index': 1,\n",
       "  'were': 1,\n",
       "  'identifi': 1,\n",
       "  'the': 5,\n",
       "  'basi': 1,\n",
       "  'their': 2,\n",
       "  'in': 4,\n",
       "  'variou': 1,\n",
       "  'kind': 1,\n",
       "  'eas': 1,\n",
       "  'implement': 1,\n",
       "  'how': 1,\n",
       "  'they': 1,\n",
       "  'are': 2,\n",
       "  'influenc': 1,\n",
       "  'by': 1,\n",
       "  'differ': 1,\n",
       "  'user': 2,\n",
       "  'type': 1,\n",
       "  'or': 2,\n",
       "  'specif': 1,\n",
       "  'applic': 2,\n",
       "  'some': 1,\n",
       "  'common': 1,\n",
       "  'such': 1,\n",
       "  'instruct': 1,\n",
       "  'user-specifi': 1,\n",
       "  'print': 1,\n",
       "  'format': 1,\n",
       "  'dictionari': 1,\n",
       "  'display': 1,\n",
       "  'truncat': 1,\n",
       "  'seen': 1,\n",
       "  'to': 4,\n",
       "  'be': 3,\n",
       "  'unnecessari': 1,\n",
       "  'impract': 1,\n",
       "  'design': 1,\n",
       "  'therefor': 1,\n",
       "  'detald': 1,\n",
       "  'consider': 1,\n",
       "  'must': 2,\n",
       "  'given': 1,\n",
       "  'oper': 1,\n",
       "  'environ': 1,\n",
       "  'real': 1,\n",
       "  'need': 1,\n",
       "  'while': 1,\n",
       "  'can': 1,\n",
       "  'serv': 1,\n",
       "  'one': 1,\n",
       "  'care': 1,\n",
       "  'not': 1,\n",
       "  'attempt': 1,\n",
       "  'duplic': 1,\n",
       "  'it': 1,\n",
       "  'blindli': 1},\n",
       " '64': {'measur': 1,\n",
       "  'in': 2,\n",
       "  'inform': 4,\n",
       "  'scienc': 2,\n",
       "  'object': 2,\n",
       "  'and': 2,\n",
       "  'subject': 2,\n",
       "  'metric': 1,\n",
       "  'space': 5,\n",
       "  'it': 1,\n",
       "  'is': 2,\n",
       "  'argu': 1,\n",
       "  'that': 1,\n",
       "  'we': 2,\n",
       "  'have': 1,\n",
       "  'to': 2,\n",
       "  'distinguish': 2,\n",
       "  'physic': 2,\n",
       "  'or': 2,\n",
       "  'document': 1,\n",
       "  'from': 1,\n",
       "  'perspect': 1,\n",
       "  'these': 1,\n",
       "  'two': 2,\n",
       "  'are': 3,\n",
       "  'like': 1,\n",
       "  'map': 1,\n",
       "  'landscap': 1,\n",
       "  'each': 1,\n",
       "  'a': 1,\n",
       "  'systemat': 1,\n",
       "  'distort': 1,\n",
       "  'of': 1,\n",
       "  'the': 3,\n",
       "  'other': 1,\n",
       "  'howev': 1,\n",
       "  'transform': 2,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'easili': 1,\n",
       "  'made': 1,\n",
       "  'onc': 1,\n",
       "  'if': 1,\n",
       "  'omit': 1,\n",
       "  'onli': 1,\n",
       "  'get': 1,\n",
       "  'unhelp': 1,\n",
       "  'solut': 1,\n",
       "  'problem': 1},\n",
       " '65': {'a': 4,\n",
       "  'model': 5,\n",
       "  'of': 6,\n",
       "  'cluster': 5,\n",
       "  'search': 5,\n",
       "  'base': 3,\n",
       "  'on': 3,\n",
       "  'classif': 2,\n",
       "  'the': 8,\n",
       "  'use': 2,\n",
       "  'document': 5,\n",
       "  'ha': 1,\n",
       "  'been': 1,\n",
       "  'suggest': 1,\n",
       "  'as': 1,\n",
       "  'an': 1,\n",
       "  'effici': 2,\n",
       "  'file': 1,\n",
       "  'organ': 1,\n",
       "  'for': 1,\n",
       "  'retriev': 2,\n",
       "  'system': 2,\n",
       "  'it': 4,\n",
       "  'is': 4,\n",
       "  'possibl': 1,\n",
       "  'that': 3,\n",
       "  'by': 1,\n",
       "  'thi': 3,\n",
       "  'inform': 1,\n",
       "  'about': 1,\n",
       "  'relationship': 1,\n",
       "  'between': 1,\n",
       "  'effect': 3,\n",
       "  'i.e.': 1,\n",
       "  'abil': 1,\n",
       "  'to': 2,\n",
       "  'distinguish': 1,\n",
       "  'relev': 1,\n",
       "  'from': 1,\n",
       "  'non-relev': 1,\n",
       "  'may': 1,\n",
       "  'also': 2,\n",
       "  'be': 3,\n",
       "  'improv': 1,\n",
       "  'in': 2,\n",
       "  'paper': 1,\n",
       "  'probabilist': 1,\n",
       "  'queri': 2,\n",
       "  'describ': 1,\n",
       "  'test': 1,\n",
       "  'with': 1,\n",
       "  'experi': 1,\n",
       "  'which': 2,\n",
       "  'indic': 1,\n",
       "  'can': 2,\n",
       "  'more': 2,\n",
       "  'than': 2,\n",
       "  'heurist': 1,\n",
       "  'and': 1,\n",
       "  'other': 1,\n",
       "  'full': 1,\n",
       "  'everi': 1,\n",
       "  'compar': 1,\n",
       "  'aspect': 1,\n",
       "  'implement': 1,\n",
       "  'are': 1,\n",
       "  'discuss': 1},\n",
       " '66': {'the': 4,\n",
       "  'technolog': 3,\n",
       "  'of': 3,\n",
       "  'librari': 3,\n",
       "  'and': 3,\n",
       "  'inform': 1,\n",
       "  'network': 4,\n",
       "  'current': 1,\n",
       "  'onlin': 1,\n",
       "  'is': 2,\n",
       "  'describ': 1,\n",
       "  'includ': 1,\n",
       "  'physic': 1,\n",
       "  'function': 1,\n",
       "  'aspect': 1,\n",
       "  'three': 1,\n",
       "  'type': 1,\n",
       "  'are': 1,\n",
       "  'distinguish': 1,\n",
       "  'search': 1,\n",
       "  'servic': 4,\n",
       "  'e.g.': 3,\n",
       "  'sdc': 1,\n",
       "  'lockhe': 1,\n",
       "  'custom': 1,\n",
       "  'that': 2,\n",
       "  'provid': 2,\n",
       "  'bibliograph': 1,\n",
       "  'file': 1,\n",
       "  'oclc': 1,\n",
       "  'inc.': 1,\n",
       "  'rlin': 1,\n",
       "  'center': 1,\n",
       "  'nelinet': 1,\n",
       "  'incolsa': 1,\n",
       "  'it': 1,\n",
       "  'predict': 1,\n",
       "  'as': 1,\n",
       "  'evolv': 1,\n",
       "  'more': 1,\n",
       "  'will': 1,\n",
       "  'be': 1,\n",
       "  'outsid': 1,\n",
       "  'directli': 1,\n",
       "  'to': 1,\n",
       "  'user': 1,\n",
       "  'through': 1,\n",
       "  'hi': 1,\n",
       "  'home': 1,\n",
       "  'or': 1,\n",
       "  'offic': 1},\n",
       " '67': {'the': 23,\n",
       "  'use': 4,\n",
       "  'of': 13,\n",
       "  'titl': 2,\n",
       "  'for': 1,\n",
       "  'automat': 1,\n",
       "  'document': 9,\n",
       "  'classif': 3,\n",
       "  'an': 2,\n",
       "  'experiment': 1,\n",
       "  'comput': 2,\n",
       "  'program': 5,\n",
       "  'ha': 1,\n",
       "  'been': 2,\n",
       "  'develop': 1,\n",
       "  'to': 8,\n",
       "  'classifi': 1,\n",
       "  'accord': 1,\n",
       "  '80': 1,\n",
       "  'section': 9,\n",
       "  'and': 9,\n",
       "  'five': 1,\n",
       "  'major': 2,\n",
       "  'group': 2,\n",
       "  'chemic': 2,\n",
       "  'abstract': 1,\n",
       "  'ca': 5,\n",
       "  'pattern': 1,\n",
       "  'recognit': 1,\n",
       "  'techniqu': 3,\n",
       "  'supplement': 2,\n",
       "  'by': 4,\n",
       "  'heurist': 2,\n",
       "  'dure': 1,\n",
       "  '``': 2,\n",
       "  'train': 2,\n",
       "  \"''\": 2,\n",
       "  'phase': 4,\n",
       "  'word': 5,\n",
       "  'from': 2,\n",
       "  'pre-classifi': 1,\n",
       "  'are': 3,\n",
       "  'select': 1,\n",
       "  'probabl': 2,\n",
       "  'occurr': 1,\n",
       "  'each': 3,\n",
       "  'in': 5,\n",
       "  'is': 2,\n",
       "  'store': 1,\n",
       "  'a': 4,\n",
       "  'refer': 1,\n",
       "  'dictionari': 4,\n",
       "  'match': 1,\n",
       "  'against': 2,\n",
       "  'assign': 4,\n",
       "  'number': 1,\n",
       "  'weight': 1,\n",
       "  'deriv': 1,\n",
       "  'normal': 1,\n",
       "  'variant': 1,\n",
       "  'such': 1,\n",
       "  'as': 1,\n",
       "  'plural': 1,\n",
       "  'past': 1,\n",
       "  'tens': 1,\n",
       "  'gerund': 1,\n",
       "  'both': 1,\n",
       "  'lookup': 1,\n",
       "  'analysi': 1,\n",
       "  'nomenclatur': 1,\n",
       "  'term': 1,\n",
       "  'into': 1,\n",
       "  'their': 1,\n",
       "  'compon': 1,\n",
       "  'root': 1,\n",
       "  'influenc': 1,\n",
       "  'which': 1,\n",
       "  'perform': 1,\n",
       "  'human': 1,\n",
       "  'consist': 1,\n",
       "  'have': 1,\n",
       "  'evalu': 1,\n",
       "  'compar': 1,\n",
       "  'result': 1,\n",
       "  'publish': 1,\n",
       "  'conduct': 1,\n",
       "  'experi': 1,\n",
       "  'with': 1,\n",
       "  'peopl': 1,\n",
       "  'experienc': 1,\n",
       "  'approxim': 1,\n",
       "  '78': 1,\n",
       "  'correct': 2,\n",
       "  '67': 1,\n",
       "  'or': 1,\n",
       "  'cross-refer': 1,\n",
       "  'at': 1,\n",
       "  'rate': 1,\n",
       "  '100': 1,\n",
       "  'per': 1,\n",
       "  'second': 1},\n",
       " '68': {'brief': 1,\n",
       "  'commun': 2,\n",
       "  'some': 1,\n",
       "  'of': 10,\n",
       "  'the': 12,\n",
       "  'automat': 1,\n",
       "  'classif': 1,\n",
       "  'procedur': 1,\n",
       "  'use': 3,\n",
       "  'in': 4,\n",
       "  'inform': 1,\n",
       "  'retriev': 1,\n",
       "  'deriv': 1,\n",
       "  'cluster': 1,\n",
       "  'document': 6,\n",
       "  'from': 1,\n",
       "  'an': 2,\n",
       "  'intermedi': 1,\n",
       "  'similar': 2,\n",
       "  'matrix': 2,\n",
       "  'comput': 2,\n",
       "  'which': 1,\n",
       "  'involv': 1,\n",
       "  'compar': 2,\n",
       "  'each': 2,\n",
       "  'collect': 2,\n",
       "  'with': 1,\n",
       "  'all': 1,\n",
       "  'other': 1,\n",
       "  'it': 1,\n",
       "  'ha': 1,\n",
       "  'recent': 1,\n",
       "  'been': 1,\n",
       "  'suggest': 1,\n",
       "  'that': 2,\n",
       "  'mani': 2,\n",
       "  'these': 1,\n",
       "  'comparison': 2,\n",
       "  'specif': 1,\n",
       "  'those': 1,\n",
       "  'between': 1,\n",
       "  'have': 1,\n",
       "  'no': 1,\n",
       "  'term': 2,\n",
       "  'common': 1,\n",
       "  'may': 1,\n",
       "  'be': 3,\n",
       "  'avoid': 1,\n",
       "  'by': 2,\n",
       "  'mean': 1,\n",
       "  'uys': 1,\n",
       "  'invert': 1,\n",
       "  'file': 1,\n",
       "  'to': 2,\n",
       "  'thi': 1,\n",
       "  'show': 1,\n",
       "  'approach': 2,\n",
       "  'will': 3,\n",
       "  'effect': 1,\n",
       "  'reduct': 1,\n",
       "  'number': 2,\n",
       "  'interdocu': 1,\n",
       "  'onli': 1,\n",
       "  'if': 2,\n",
       "  'are': 2,\n",
       "  'index': 3,\n",
       "  'a': 1,\n",
       "  'limit': 1,\n",
       "  'exhaust': 1,\n",
       "  'is': 1,\n",
       "  'pair': 1,\n",
       "  'sever': 1,\n",
       "  'time': 1,\n",
       "  'over': 1,\n",
       "  'and': 1,\n",
       "  'greater': 1,\n",
       "  'than': 1,\n",
       "  'when': 1,\n",
       "  'convent': 1,\n",
       "  'gener': 1},\n",
       " '69': {'the': 12,\n",
       "  'applic': 1,\n",
       "  'of': 8,\n",
       "  'a': 2,\n",
       "  'minicomput': 5,\n",
       "  'to': 5,\n",
       "  'thesauru': 5,\n",
       "  'construct': 1,\n",
       "  'use': 5,\n",
       "  'in': 5,\n",
       "  'variou': 1,\n",
       "  'phase': 2,\n",
       "  'creat': 1,\n",
       "  'for': 2,\n",
       "  'nation': 1,\n",
       "  'inform': 1,\n",
       "  'center': 1,\n",
       "  'special': 1,\n",
       "  'educ': 1,\n",
       "  'materi': 1,\n",
       "  'nicsem': 1,\n",
       "  'databas': 1,\n",
       "  'is': 3,\n",
       "  'describ': 1,\n",
       "  'collect': 1,\n",
       "  'edit': 1,\n",
       "  'and': 5,\n",
       "  'correct': 1,\n",
       "  'candid': 1,\n",
       "  'term': 5,\n",
       "  'eas': 1,\n",
       "  'process': 2,\n",
       "  'group': 1,\n",
       "  'into': 1,\n",
       "  'file': 1,\n",
       "  'similar': 1,\n",
       "  'concept': 1,\n",
       "  'facilit': 2,\n",
       "  'gener': 1,\n",
       "  'product': 1,\n",
       "  'vocabulari': 1,\n",
       "  'review': 1,\n",
       "  'structur': 1,\n",
       "  'syndet': 1,\n",
       "  'relat': 1,\n",
       "  'indic': 1,\n",
       "  'by': 2,\n",
       "  'assign': 1,\n",
       "  'code': 1,\n",
       "  'identif': 1,\n",
       "  'number': 1,\n",
       "  'are': 2,\n",
       "  'alter': 1,\n",
       "  'easili': 1,\n",
       "  'design': 1,\n",
       "  'reflect': 1,\n",
       "  'restructur': 1,\n",
       "  'requir': 1,\n",
       "  'becaus': 1,\n",
       "  'alreadi': 1,\n",
       "  'machine-': 1,\n",
       "  'readabl': 1,\n",
       "  'form': 1,\n",
       "  'it': 1,\n",
       "  'simpl': 1,\n",
       "  'prepar': 1,\n",
       "  'print': 1,\n",
       "  'program': 1,\n",
       "  'provid': 1,\n",
       "  'permut': 1,\n",
       "  'alphabet': 1,\n",
       "  'hierarch': 1,\n",
       "  'chart': 1,\n",
       "  'format': 1,\n",
       "  'display': 1,\n",
       "  'overal': 2,\n",
       "  'initi': 1,\n",
       "  'entri': 1,\n",
       "  'develop': 1,\n",
       "  'reduc': 1,\n",
       "  'cleric': 1,\n",
       "  'effort': 1,\n",
       "  'editori': 1,\n",
       "  'staff': 1,\n",
       "  'decis': 1,\n",
       "  'time': 1},\n",
       " '70': {'adapt': 3,\n",
       "  'design': 4,\n",
       "  'for': 6,\n",
       "  'decis': 5,\n",
       "  'support': 4,\n",
       "  'system': 6,\n",
       "  'dss': 6,\n",
       "  'repres': 1,\n",
       "  'a': 5,\n",
       "  'concept': 1,\n",
       "  'of': 7,\n",
       "  'the': 12,\n",
       "  'role': 1,\n",
       "  'comput': 1,\n",
       "  'within': 1,\n",
       "  'make': 1,\n",
       "  'process': 4,\n",
       "  'term': 3,\n",
       "  'ha': 1,\n",
       "  'becom': 2,\n",
       "  'ralli': 2,\n",
       "  'cri': 2,\n",
       "  'research': 3,\n",
       "  'practition': 1,\n",
       "  'and': 10,\n",
       "  'manag': 7,\n",
       "  'concern': 1,\n",
       "  'that': 2,\n",
       "  'scienc': 3,\n",
       "  'inform': 1,\n",
       "  'field': 1,\n",
       "  'have': 1,\n",
       "  'unnecessarili': 1,\n",
       "  'narrow': 1,\n",
       "  'in': 1,\n",
       "  'focu': 3,\n",
       "  'as': 5,\n",
       "  'with': 2,\n",
       "  'mani': 1,\n",
       "  'is': 6,\n",
       "  'not': 1,\n",
       "  'well': 1,\n",
       "  'defin': 2,\n",
       "  'some': 2,\n",
       "  'writer': 1,\n",
       "  'simpli': 1,\n",
       "  'mean': 1,\n",
       "  'interact': 1,\n",
       "  'use': 2,\n",
       "  'by': 1,\n",
       "  'to': 4,\n",
       "  'other': 2,\n",
       "  'key': 2,\n",
       "  'issu': 2,\n",
       "  'rather': 1,\n",
       "  'than': 1,\n",
       "  'they': 2,\n",
       "  'on': 2,\n",
       "  'understand': 1,\n",
       "  'improv': 1,\n",
       "  'then': 2,\n",
       "  'ani': 1,\n",
       "  'avail': 1,\n",
       "  'suitabl': 1,\n",
       "  'technolog': 1,\n",
       "  'view': 1,\n",
       "  'subfield': 1,\n",
       "  'mi': 1,\n",
       "  'while': 1,\n",
       "  'regard': 1,\n",
       "  'it': 1,\n",
       "  'an': 2,\n",
       "  'extens': 1,\n",
       "  'techniqu': 1,\n",
       "  'former': 1,\n",
       "  'provid': 1,\n",
       "  'access': 2,\n",
       "  'data': 2,\n",
       "  'latter': 1,\n",
       "  'give': 1,\n",
       "  'them': 1,\n",
       "  'analyt': 1,\n",
       "  'model': 1,\n",
       "  'argument': 1,\n",
       "  'thi': 2,\n",
       "  'paper': 1,\n",
       "  'relev': 1,\n",
       "  'situat': 1,\n",
       "  'where': 1,\n",
       "  '``': 1,\n",
       "  'final': 1,\n",
       "  \"''\": 1,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'develop': 1,\n",
       "  'onli': 1,\n",
       "  'through': 1,\n",
       "  'learn': 2,\n",
       "  'evolut': 2,\n",
       "  'strategi': 2,\n",
       "  'must': 1,\n",
       "  'get': 2,\n",
       "  'finish': 1,\n",
       "  'veri': 1,\n",
       "  'differ': 1,\n",
       "  'from': 1,\n",
       "  'approach': 1,\n",
       "  'center': 1,\n",
       "  'around': 1,\n",
       "  'includ': 1,\n",
       "  'manageri': 1,\n",
       "  'represent': 1,\n",
       "  'task': 1,\n",
       "  'user': 1,\n",
       "  'behavior': 1,\n",
       "  'architectur': 1,\n",
       "  'start': 1},\n",
       " '71': {'an': 1,\n",
       "  'automat': 1,\n",
       "  'method': 4,\n",
       "  'for': 4,\n",
       "  'extract': 3,\n",
       "  'signific': 5,\n",
       "  'phrase': 5,\n",
       "  'in': 5,\n",
       "  'scienfif': 1,\n",
       "  'or': 3,\n",
       "  'technic': 2,\n",
       "  'document': 6,\n",
       "  'a': 4,\n",
       "  'new': 1,\n",
       "  'is': 4,\n",
       "  'describ': 1,\n",
       "  'to': 3,\n",
       "  'the': 19,\n",
       "  'titl': 1,\n",
       "  'and': 7,\n",
       "  'abstreact': 1,\n",
       "  'of': 9,\n",
       "  'scientif': 1,\n",
       "  'base': 2,\n",
       "  'upon': 1,\n",
       "  'text': 2,\n",
       "  'structur': 1,\n",
       "  'analysi': 1,\n",
       "  'use': 3,\n",
       "  'rel': 1,\n",
       "  'small': 1,\n",
       "  'dictionari': 2,\n",
       "  'ha': 2,\n",
       "  'been': 2,\n",
       "  'construct': 2,\n",
       "  'on': 1,\n",
       "  'knowledg': 2,\n",
       "  'about': 1,\n",
       "  'concept': 1,\n",
       "  'field': 2,\n",
       "  'scienc': 1,\n",
       "  'technolog': 1,\n",
       "  'some': 1,\n",
       "  'lexic': 1,\n",
       "  'their': 1,\n",
       "  'compon': 1,\n",
       "  'item': 1,\n",
       "  'may': 1,\n",
       "  'be': 1,\n",
       "  'differ': 1,\n",
       "  'mean': 1,\n",
       "  'among': 1,\n",
       "  'analysiu': 1,\n",
       "  'approach': 1,\n",
       "  'appli': 1,\n",
       "  'select': 1,\n",
       "  'as': 1,\n",
       "  'substanti': 1,\n",
       "  'semant': 1,\n",
       "  'inform': 3,\n",
       "  'carrier': 1,\n",
       "  'content': 1,\n",
       "  'abstract': 1,\n",
       "  'result': 1,\n",
       "  'experi': 1,\n",
       "  'five': 1,\n",
       "  'set': 1,\n",
       "  'have': 1,\n",
       "  'shown': 1,\n",
       "  'that': 1,\n",
       "  'are': 1,\n",
       "  'effect': 1,\n",
       "  'all': 1,\n",
       "  'case': 1,\n",
       "  'number': 1,\n",
       "  'them': 1,\n",
       "  'everi': 1,\n",
       "  'process': 1,\n",
       "  'time': 1,\n",
       "  'fairli': 1,\n",
       "  'satisfactori': 1,\n",
       "  'represent': 1,\n",
       "  'partli': 1,\n",
       "  'discuss': 1,\n",
       "  'with': 1,\n",
       "  'relat': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 1},\n",
       " '72': {'answer-passag': 1,\n",
       "  'retriev': 12,\n",
       "  'by': 2,\n",
       "  'text': 1,\n",
       "  'search': 3,\n",
       "  'passag': 3,\n",
       "  'alreadi': 1,\n",
       "  'oper': 1,\n",
       "  'for': 6,\n",
       "  'lawyer': 1,\n",
       "  'ha': 1,\n",
       "  'advantag': 1,\n",
       "  'in': 4,\n",
       "  'output': 1,\n",
       "  'form': 2,\n",
       "  'opver': 1,\n",
       "  'refer': 2,\n",
       "  'and': 4,\n",
       "  'is': 1,\n",
       "  'econom': 1,\n",
       "  'feasibl': 1,\n",
       "  'previou': 1,\n",
       "  'experi': 2,\n",
       "  'scientist': 1,\n",
       "  'have': 1,\n",
       "  'demonstr': 1,\n",
       "  'recal': 2,\n",
       "  'fals': 3,\n",
       "  'rate': 2,\n",
       "  'as': 1,\n",
       "  'good': 1,\n",
       "  'or': 1,\n",
       "  'better': 1,\n",
       "  'than': 1,\n",
       "  'those': 1,\n",
       "  'of': 4,\n",
       "  'present': 2,\n",
       "  'servic': 1,\n",
       "  'the': 5,\n",
       "  'involv': 1,\n",
       "  'a': 1,\n",
       "  'greater': 1,\n",
       "  'varieti': 1,\n",
       "  'question': 3,\n",
       "  'addit': 1,\n",
       "  'word': 2,\n",
       "  'were': 2,\n",
       "  'select': 2,\n",
       "  'independ': 1,\n",
       "  'two': 2,\n",
       "  'differ': 1,\n",
       "  'peopl': 1,\n",
       "  'each': 1,\n",
       "  'combin': 1,\n",
       "  'with': 1,\n",
       "  'comput': 1,\n",
       "  'procedur': 1,\n",
       "  'use': 1,\n",
       "  'produc': 1,\n",
       "  'averag': 1,\n",
       "  'ratio': 1,\n",
       "  '72': 1,\n",
       "  '67': 1,\n",
       "  'respect': 2,\n",
       "  'selector': 1,\n",
       "  'except': 1,\n",
       "  'one': 1,\n",
       "  'predict': 1,\n",
       "  'difficult': 1,\n",
       "  '13': 1,\n",
       "  '10': 1,\n",
       "  'sentenc': 1,\n",
       "  'per': 1,\n",
       "  'answer-pap': 1},\n",
       " '73': {'partial-match': 2,\n",
       "  'retriev': 3,\n",
       "  'use': 2,\n",
       "  'index': 3,\n",
       "  'descriptor': 5,\n",
       "  'file': 7,\n",
       "  'in': 5,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'we': 1,\n",
       "  'describ': 2,\n",
       "  'a': 9,\n",
       "  'practic': 1,\n",
       "  'method': 1,\n",
       "  'of': 6,\n",
       "  'veri': 1,\n",
       "  'larg': 1,\n",
       "  'data': 1,\n",
       "  'binari': 1,\n",
       "  'code': 1,\n",
       "  'word': 1,\n",
       "  'call': 1,\n",
       "  'is': 5,\n",
       "  'associ': 1,\n",
       "  'with': 1,\n",
       "  'each': 1,\n",
       "  'record': 3,\n",
       "  'the': 5,\n",
       "  'these': 2,\n",
       "  'are': 2,\n",
       "  'then': 2,\n",
       "  'to': 2,\n",
       "  'form': 1,\n",
       "  'deriv': 1,\n",
       "  'for': 2,\n",
       "  'block': 2,\n",
       "  'sever': 1,\n",
       "  'which': 2,\n",
       "  'will': 1,\n",
       "  'serv': 1,\n",
       "  'as': 2,\n",
       "  'an': 1,\n",
       "  'whole': 1,\n",
       "  'henc': 1,\n",
       "  'name': 1,\n",
       "  '``': 2,\n",
       "  \"''\": 2,\n",
       "  'first': 1,\n",
       "  'structur': 1,\n",
       "  'and': 2,\n",
       "  'simpl': 1,\n",
       "  'effici': 1,\n",
       "  'algorithm': 1,\n",
       "  'present': 1,\n",
       "  'it': 1,\n",
       "  'expect': 1,\n",
       "  'behavior': 1,\n",
       "  'term': 1,\n",
       "  'storag': 1,\n",
       "  'access': 1,\n",
       "  'analyz': 1,\n",
       "  'detail': 1,\n",
       "  'two': 1,\n",
       "  'differ': 1,\n",
       "  'creation': 1,\n",
       "  'procedur': 1,\n",
       "  'sketch': 1,\n",
       "  'number': 1,\n",
       "  'way': 1,\n",
       "  'organ': 1,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'tune': 1,\n",
       "  'particular': 1,\n",
       "  'applic': 1,\n",
       "  'suggest': 1},\n",
       " '74': {'cooper': 2,\n",
       "  'and': 7,\n",
       "  'competit': 2,\n",
       "  'among': 1,\n",
       "  'librari': 6,\n",
       "  'network': 7,\n",
       "  'recenti': 1,\n",
       "  'technolog': 2,\n",
       "  'advanc': 1,\n",
       "  'the': 11,\n",
       "  'success': 1,\n",
       "  'of': 8,\n",
       "  'oclc': 2,\n",
       "  'inc.': 2,\n",
       "  'ha': 1,\n",
       "  'led': 1,\n",
       "  'to': 1,\n",
       "  'emerg': 1,\n",
       "  'three': 1,\n",
       "  'addit': 1,\n",
       "  'nonprofit': 1,\n",
       "  'research': 2,\n",
       "  'inform': 1,\n",
       "  'rlin': 1,\n",
       "  'group': 1,\n",
       "  'univers': 1,\n",
       "  'toronto': 1,\n",
       "  'autom': 1,\n",
       "  'system': 1,\n",
       "  'utla': 1,\n",
       "  'washington': 1,\n",
       "  'wln': 1,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'examin': 1,\n",
       "  'econom': 1,\n",
       "  'factor': 1,\n",
       "  'affect': 1,\n",
       "  'evolut': 1,\n",
       "  'these': 1,\n",
       "  'also': 1,\n",
       "  'explor': 1,\n",
       "  'role': 1,\n",
       "  'those': 1,\n",
       "  'state': 1,\n",
       "  'region': 1,\n",
       "  'multist': 1,\n",
       "  'that': 1,\n",
       "  'broker': 1,\n",
       "  'servic': 1,\n",
       "  'natur': 1,\n",
       "  'relationship': 1,\n",
       "  'is': 1,\n",
       "  'a': 1,\n",
       "  'major': 1,\n",
       "  'theme': 1,\n",
       "  'discuss': 1},\n",
       " '75': {'an': 3,\n",
       "  'integr': 2,\n",
       "  'understand': 2,\n",
       "  'a': 1,\n",
       "  'new': 1,\n",
       "  'type': 1,\n",
       "  'of': 4,\n",
       "  'natur': 1,\n",
       "  'languag': 1,\n",
       "  'parser': 3,\n",
       "  'is': 5,\n",
       "  'present': 1,\n",
       "  'the': 6,\n",
       "  'idea': 1,\n",
       "  'behind': 1,\n",
       "  'thi': 1,\n",
       "  'to': 3,\n",
       "  'map': 1,\n",
       "  'input': 1,\n",
       "  'sentenc': 1,\n",
       "  'into': 1,\n",
       "  'deepest': 1,\n",
       "  'form': 1,\n",
       "  'represent': 1,\n",
       "  'their': 1,\n",
       "  'mean': 1,\n",
       "  'and': 3,\n",
       "  'infer': 2,\n",
       "  'as': 1,\n",
       "  'appropri': 1,\n",
       "  'not': 2,\n",
       "  'distinct': 1,\n",
       "  'from': 1,\n",
       "  'entir': 1,\n",
       "  'system': 1,\n",
       "  'it': 4,\n",
       "  'use': 1,\n",
       "  'concept': 1,\n",
       "  'script': 1,\n",
       "  'plan': 1,\n",
       "  'other': 1,\n",
       "  'knowledg': 1,\n",
       "  'aid': 1,\n",
       "  'in': 1,\n",
       "  'pars': 2,\n",
       "  'furthermor': 1,\n",
       "  'doe': 1,\n",
       "  'attempt': 1,\n",
       "  'everyth': 1,\n",
       "  'see': 1,\n",
       "  'rather': 1,\n",
       "  'determin': 1,\n",
       "  'what': 1,\n",
       "  'most': 1,\n",
       "  'interest': 1,\n",
       "  'concentr': 1,\n",
       "  'on': 1,\n",
       "  'that': 1,\n",
       "  'ignor': 1,\n",
       "  'rest': 1},\n",
       " '76': {'librari': 5,\n",
       "  'network': 3,\n",
       "  'and': 5,\n",
       "  'resourc': 2,\n",
       "  'share': 2,\n",
       "  'in': 5,\n",
       "  'the': 9,\n",
       "  'unit': 2,\n",
       "  'state': 2,\n",
       "  'an': 1,\n",
       "  'histor': 1,\n",
       "  'philosoph': 1,\n",
       "  'overview': 1,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'discuss': 1,\n",
       "  'origin': 1,\n",
       "  'of': 5,\n",
       "  'trace': 1,\n",
       "  'their': 1,\n",
       "  'develop': 1,\n",
       "  'late': 1,\n",
       "  '1960': 1,\n",
       "  'through': 1,\n",
       "  'present': 1,\n",
       "  'concept': 1,\n",
       "  'with': 1,\n",
       "  'particular': 2,\n",
       "  'attent': 2,\n",
       "  'to': 4,\n",
       "  'inter-': 1,\n",
       "  'loan': 1,\n",
       "  'program': 1,\n",
       "  'for': 1,\n",
       "  'cooper': 2,\n",
       "  'acquisit': 1,\n",
       "  'storag': 1,\n",
       "  'materi': 1,\n",
       "  'is': 2,\n",
       "  'examin': 1,\n",
       "  'relationship': 1,\n",
       "  'given': 1,\n",
       "  'question': 1,\n",
       "  'how': 1,\n",
       "  'these': 1,\n",
       "  'two': 1,\n",
       "  'major': 1,\n",
       "  'compon': 1,\n",
       "  'which': 1,\n",
       "  'have': 1,\n",
       "  'tend': 1,\n",
       "  'be': 1,\n",
       "  'separ': 1,\n",
       "  'might': 1,\n",
       "  'becom': 1,\n",
       "  'more': 1,\n",
       "  'close': 1,\n",
       "  'integr': 1},\n",
       " '77': {'normal': 3,\n",
       "  'of': 5,\n",
       "  'titl': 3,\n",
       "  'and': 5,\n",
       "  'their': 2,\n",
       "  'retriev': 5,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'present': 1,\n",
       "  'a': 10,\n",
       "  'method': 1,\n",
       "  'english': 1,\n",
       "  'the': 8,\n",
       "  'express': 2,\n",
       "  'by': 3,\n",
       "  'noun': 2,\n",
       "  'phrase': 1,\n",
       "  'or': 1,\n",
       "  'claus': 1,\n",
       "  'is': 3,\n",
       "  'convert': 1,\n",
       "  'to': 4,\n",
       "  'function-express': 1,\n",
       "  'pars': 1,\n",
       "  'for': 2,\n",
       "  'with': 1,\n",
       "  'reason': 2,\n",
       "  'recal': 2,\n",
       "  'rate': 3,\n",
       "  'as': 2,\n",
       "  'well': 1,\n",
       "  'high': 1,\n",
       "  'precis': 2,\n",
       "  'function-': 1,\n",
       "  'transform': 1,\n",
       "  'predicate-governor': 1,\n",
       "  'form': 2,\n",
       "  'then': 1,\n",
       "  'standard': 1,\n",
       "  'therefrom': 1,\n",
       "  'variou': 1,\n",
       "  'item': 1,\n",
       "  'are': 2,\n",
       "  'extract': 1,\n",
       "  'record': 1,\n",
       "  'in': 3,\n",
       "  'hierarch': 1,\n",
       "  'tree-lik': 1,\n",
       "  'invert': 1,\n",
       "  'file': 1,\n",
       "  'order': 1,\n",
       "  'keep': 1,\n",
       "  'valu': 1,\n",
       "  'sever': 1,\n",
       "  'stage': 1,\n",
       "  'implement': 1,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'key-term': 2,\n",
       "  'case-label': 2,\n",
       "  'match': 1,\n",
       "  'control': 1,\n",
       "  'specif': 1,\n",
       "  'each': 1},\n",
       " '78': {'cascad': 2,\n",
       "  'atn': 5,\n",
       "  'grammar': 3,\n",
       "  'a': 6,\n",
       "  'gener': 1,\n",
       "  'of': 10,\n",
       "  'the': 7,\n",
       "  'notion': 1,\n",
       "  'call': 2,\n",
       "  'catn': 2,\n",
       "  'is': 1,\n",
       "  'prescrib': 1,\n",
       "  \"'s\": 2,\n",
       "  'permit': 1,\n",
       "  'decomposit': 1,\n",
       "  'complex': 1,\n",
       "  'languag': 1,\n",
       "  'understand': 1,\n",
       "  'behavior': 1,\n",
       "  'into': 1,\n",
       "  'sequenc': 1,\n",
       "  'cooper': 1,\n",
       "  'with': 1,\n",
       "  'separ': 1,\n",
       "  'domain': 1,\n",
       "  'respons': 1,\n",
       "  'where': 1,\n",
       "  'each': 1,\n",
       "  'stage': 2,\n",
       "  'an': 2,\n",
       "  'transduc': 1,\n",
       "  'take': 1,\n",
       "  'it': 1,\n",
       "  'input': 1,\n",
       "  'from': 1,\n",
       "  'output': 1,\n",
       "  'previou': 1,\n",
       "  'paper': 1,\n",
       "  'includ': 1,\n",
       "  'extens': 1,\n",
       "  'discjuss': 1,\n",
       "  'principl': 1,\n",
       "  'factoring-conceptu': 1,\n",
       "  'factor': 2,\n",
       "  'reduc': 2,\n",
       "  'number': 2,\n",
       "  'place': 1,\n",
       "  'that': 2,\n",
       "  'given': 1,\n",
       "  'fact': 1,\n",
       "  'need': 1,\n",
       "  'to': 2,\n",
       "  'be': 2,\n",
       "  'repres': 1,\n",
       "  'in': 1,\n",
       "  'and': 1,\n",
       "  'hypothesi': 1,\n",
       "  'distinct': 1,\n",
       "  'hypothes': 1,\n",
       "  'have': 1,\n",
       "  'consid': 1,\n",
       "  'dure': 1,\n",
       "  'pars': 1},\n",
       " '79': {'algorithm': 2,\n",
       "  'for': 1,\n",
       "  'process': 2,\n",
       "  'partial': 2,\n",
       "  'match': 1,\n",
       "  'queri': 3,\n",
       "  'use': 2,\n",
       "  'word': 3,\n",
       "  'fragment': 4,\n",
       "  'are': 2,\n",
       "  'given': 1,\n",
       "  'to': 2,\n",
       "  'specifi': 1,\n",
       "  'in': 3,\n",
       "  'a': 1,\n",
       "  'compress': 1,\n",
       "  'databas': 1,\n",
       "  'system': 1,\n",
       "  'the': 8,\n",
       "  'propos': 1,\n",
       "  'method': 3,\n",
       "  'handl': 1,\n",
       "  'effect': 1,\n",
       "  'that': 2,\n",
       "  'either': 1,\n",
       "  'whole': 1,\n",
       "  'or': 1,\n",
       "  'as': 3,\n",
       "  'languag': 1,\n",
       "  'element': 1,\n",
       "  'compar': 1,\n",
       "  'and': 3,\n",
       "  'critic': 1,\n",
       "  'evalu': 1,\n",
       "  'term': 1,\n",
       "  'of': 3,\n",
       "  'design': 2,\n",
       "  'retriev': 2,\n",
       "  'cost': 3,\n",
       "  'analys': 1,\n",
       "  'show': 1,\n",
       "  'which': 1,\n",
       "  'exploit': 1,\n",
       "  'interdepend': 1,\n",
       "  'well': 1,\n",
       "  'relev': 1,\n",
       "  'record': 1,\n",
       "  'file': 1,\n",
       "  'ha': 1,\n",
       "  'maximum': 1,\n",
       "  'least': 1},\n",
       " '80': {'a': 10,\n",
       "  'gener': 3,\n",
       "  'formul': 5,\n",
       "  'of': 16,\n",
       "  'bradford': 2,\n",
       "  \"'s\": 2,\n",
       "  'distribut': 2,\n",
       "  'the': 19,\n",
       "  'graph-ori': 1,\n",
       "  'approach': 1,\n",
       "  'from': 1,\n",
       "  'detail': 1,\n",
       "  'analysi': 1,\n",
       "  'eight': 2,\n",
       "  'previous': 1,\n",
       "  'publish': 1,\n",
       "  'mathemat': 1,\n",
       "  'model': 2,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'deduc': 1,\n",
       "  'as': 1,\n",
       "  'follow': 1,\n",
       "  'y': 2,\n",
       "  'log': 2,\n",
       "  'x': 2,\n",
       "  'c': 2,\n",
       "  'b': 2,\n",
       "  'where': 1,\n",
       "  'is': 6,\n",
       "  'ratio': 2,\n",
       "  'cumul': 1,\n",
       "  'frequenc': 1,\n",
       "  'articl': 2,\n",
       "  'to': 6,\n",
       "  'total': 2,\n",
       "  'number': 2,\n",
       "  'and': 5,\n",
       "  'rank': 2,\n",
       "  'journal': 2,\n",
       "  'paramet': 4,\n",
       "  'are': 1,\n",
       "  'slope': 1,\n",
       "  'intercept': 1,\n",
       "  'shift': 1,\n",
       "  'in': 2,\n",
       "  'straight': 1,\n",
       "  'line': 1,\n",
       "  'respect': 1,\n",
       "  'each': 1,\n",
       "  'special': 1,\n",
       "  'case': 1,\n",
       "  'one': 1,\n",
       "  'five': 1,\n",
       "  'type': 2,\n",
       "  'order': 1,\n",
       "  'estim': 1,\n",
       "  'three': 2,\n",
       "  'unknown': 2,\n",
       "  'statist': 1,\n",
       "  'method': 1,\n",
       "  'use': 2,\n",
       "  'root-weight': 1,\n",
       "  'squar': 1,\n",
       "  'error': 2,\n",
       "  'propos': 1,\n",
       "  'compar': 1,\n",
       "  'experi': 2,\n",
       "  '11': 1,\n",
       "  'databas': 1,\n",
       "  'suggest': 1,\n",
       "  'that': 2,\n",
       "  'fifth': 1,\n",
       "  'with': 1,\n",
       "  'best': 1,\n",
       "  'fit': 1,\n",
       "  'observ': 1,\n",
       "  'data': 2,\n",
       "  'further': 1,\n",
       "  'show': 1,\n",
       "  'delet': 1,\n",
       "  'droop': 1,\n",
       "  'lead': 1,\n",
       "  'more': 1,\n",
       "  'accur': 1,\n",
       "  'valu': 1,\n",
       "  'less': 1},\n",
       " '81': {'lexic': 8,\n",
       "  'problem': 4,\n",
       "  'in': 6,\n",
       "  'larg': 3,\n",
       "  'distribut': 2,\n",
       "  'inform': 6,\n",
       "  'system': 6,\n",
       "  'the': 8,\n",
       "  'are': 3,\n",
       "  'creat': 1,\n",
       "  'by': 2,\n",
       "  'necess': 1,\n",
       "  'of': 7,\n",
       "  'handl': 1,\n",
       "  'a': 6,\n",
       "  'great': 1,\n",
       "  'number': 1,\n",
       "  'name': 1,\n",
       "  'and': 5,\n",
       "  'their': 1,\n",
       "  'interrel': 1,\n",
       "  'such': 1,\n",
       "  'not': 1,\n",
       "  'cover': 1,\n",
       "  'complet': 1,\n",
       "  'concept': 1,\n",
       "  'data': 1,\n",
       "  'dictionari': 1,\n",
       "  'which': 2,\n",
       "  'mostli': 1,\n",
       "  'concern': 2,\n",
       "  'with': 2,\n",
       "  'databas': 2,\n",
       "  'scheme': 1,\n",
       "  'design': 1,\n",
       "  'rather': 1,\n",
       "  'than': 1,\n",
       "  'execut': 1,\n",
       "  'oper': 1,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'we': 2,\n",
       "  'introduc': 1,\n",
       "  'our': 1,\n",
       "  'view': 1,\n",
       "  'subsystem': 2,\n",
       "  'as': 1,\n",
       "  'separ': 1,\n",
       "  'compon': 1,\n",
       "  'an': 1,\n",
       "  'architectur': 1,\n",
       "  'to': 1,\n",
       "  'deal': 1,\n",
       "  'linguist': 2,\n",
       "  'control': 1,\n",
       "  'function': 1,\n",
       "  'local': 2,\n",
       "  'network': 1,\n",
       "  'environ': 1,\n",
       "  'suybsystem': 1,\n",
       "  'is': 1,\n",
       "  'special': 1,\n",
       "  'effici': 1,\n",
       "  'organ': 1,\n",
       "  'program': 1,\n",
       "  'packag': 1,\n",
       "  'play': 1,\n",
       "  'role': 1,\n",
       "  '``': 1,\n",
       "  'filter': 1,\n",
       "  \"''\": 1,\n",
       "  'broad': 1,\n",
       "  'sens': 1,\n",
       "  'for': 2,\n",
       "  'incorrect': 1,\n",
       "  'queri': 1,\n",
       "  'promot': 1,\n",
       "  'integr': 1,\n",
       "  'retriev': 1,\n",
       "  'facilit': 1,\n",
       "  'creation': 1,\n",
       "  'hope': 1,\n",
       "  'that': 1,\n",
       "  'can': 1,\n",
       "  'becom': 1,\n",
       "  'product': 1,\n",
       "  'ani': 1,\n",
       "  'especi': 1},\n",
       " '82': {'the': 9,\n",
       "  'relat': 10,\n",
       "  'model': 3,\n",
       "  'in': 3,\n",
       "  'inform': 4,\n",
       "  'retriev': 4,\n",
       "  'ha': 1,\n",
       "  'receiv': 1,\n",
       "  'increas': 1,\n",
       "  'attent': 1,\n",
       "  'dure': 1,\n",
       "  'past': 1,\n",
       "  'decad': 1,\n",
       "  'it': 1,\n",
       "  'advantag': 2,\n",
       "  'includ': 2,\n",
       "  'simplic': 1,\n",
       "  'consist': 1,\n",
       "  'and': 5,\n",
       "  'a': 2,\n",
       "  'sound': 1,\n",
       "  'theoret': 1,\n",
       "  'basi': 1,\n",
       "  'thi': 1,\n",
       "  'articl': 1,\n",
       "  'natur': 1,\n",
       "  'of': 4,\n",
       "  'view': 1,\n",
       "  'is': 4,\n",
       "  'demonstr': 2,\n",
       "  'present': 2,\n",
       "  'organ': 1,\n",
       "  'bibliograph': 1,\n",
       "  'databas': 1,\n",
       "  'shown': 1,\n",
       "  'notion': 1,\n",
       "  'normal': 2,\n",
       "  'introduc': 1,\n",
       "  'first': 1,\n",
       "  'second': 1,\n",
       "  'third': 1,\n",
       "  'fourth': 1,\n",
       "  'form': 1,\n",
       "  'are': 4,\n",
       "  'languag': 2,\n",
       "  'discuss': 1,\n",
       "  'calculu': 1,\n",
       "  'algebra': 1,\n",
       "  'sequel': 1,\n",
       "  'numer': 1,\n",
       "  'exampl': 1,\n",
       "  'pertin': 1,\n",
       "  'to': 2,\n",
       "  'these': 1,\n",
       "  'approach': 1,\n",
       "  'note': 1},\n",
       " '83': {'electron': 1,\n",
       "  'inform': 2,\n",
       "  'interchang': 3,\n",
       "  'in': 2,\n",
       "  'an': 2,\n",
       "  'offic': 3,\n",
       "  'environ': 1,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'describ': 4,\n",
       "  'architectur': 7,\n",
       "  'approach': 1,\n",
       "  'that': 1,\n",
       "  'provid': 3,\n",
       "  'exchang': 1,\n",
       "  'across': 1,\n",
       "  'a': 4,\n",
       "  'broad': 1,\n",
       "  'spectrum': 1,\n",
       "  'of': 3,\n",
       "  'user': 2,\n",
       "  'applic': 2,\n",
       "  'and': 6,\n",
       "  'autom': 1,\n",
       "  'offer': 1,\n",
       "  'some': 1,\n",
       "  'the': 9,\n",
       "  'herein': 1,\n",
       "  'are': 2,\n",
       "  'current': 1,\n",
       "  'implement': 1,\n",
       "  'exist': 1,\n",
       "  'ibm': 4,\n",
       "  'product': 2,\n",
       "  'these': 1,\n",
       "  'other': 2,\n",
       "  'will': 1,\n",
       "  'basi': 1,\n",
       "  'for': 3,\n",
       "  'document': 3,\n",
       "  'capabl': 1,\n",
       "  'between': 2,\n",
       "  'such': 1,\n",
       "  'as': 2,\n",
       "  '5520': 1,\n",
       "  'administr': 1,\n",
       "  'system': 3,\n",
       "  'system/370': 1,\n",
       "  'distribut': 3,\n",
       "  'support': 1,\n",
       "  'disoss': 1,\n",
       "  'displaywrit': 1,\n",
       "  'specif': 2,\n",
       "  'is': 2,\n",
       "  'it': 1,\n",
       "  'associ': 1,\n",
       "  'data': 2,\n",
       "  'stream': 1,\n",
       "  'gener': 1,\n",
       "  'overview': 1,\n",
       "  'oppos': 1,\n",
       "  'to': 1,\n",
       "  'detail': 1,\n",
       "  'technic': 1,\n",
       "  'descript': 1,\n",
       "  'protocol': 1,\n",
       "  'process': 1,\n",
       "  'they': 1,\n",
       "  'do': 1,\n",
       "  'not': 1,\n",
       "  'address': 1,\n",
       "  'interfac': 1,\n",
       "  'util': 1,\n",
       "  'sna': 1,\n",
       "  'transmiss': 1,\n",
       "  'commun': 1,\n",
       "  'control': 1,\n",
       "  'facil': 1},\n",
       " '84': {'the': 6,\n",
       "  'use': 2,\n",
       "  'of': 7,\n",
       "  'automat': 2,\n",
       "  'relev': 3,\n",
       "  'feedback': 2,\n",
       "  'in': 4,\n",
       "  'boolean': 3,\n",
       "  'retriev': 4,\n",
       "  'system': 2,\n",
       "  'a': 7,\n",
       "  'techniqu': 3,\n",
       "  'is': 3,\n",
       "  'describ': 2,\n",
       "  'for': 3,\n",
       "  'reformul': 1,\n",
       "  'queri': 2,\n",
       "  'base': 2,\n",
       "  'on': 1,\n",
       "  'patron': 1,\n",
       "  'judgement': 1,\n",
       "  'an': 2,\n",
       "  'initi': 1,\n",
       "  'preval': 1,\n",
       "  'measur': 2,\n",
       "  'are': 2,\n",
       "  'deriv': 1,\n",
       "  'term': 2,\n",
       "  'appear': 1,\n",
       "  'set': 1,\n",
       "  'document': 2,\n",
       "  'that': 1,\n",
       "  'reflect': 1,\n",
       "  \"'s\": 1,\n",
       "  'distribut': 1,\n",
       "  'among': 1,\n",
       "  'and': 1,\n",
       "  'non-relev': 1,\n",
       "  'these': 1,\n",
       "  'then': 1,\n",
       "  'to': 4,\n",
       "  'guid': 1,\n",
       "  'construct': 1,\n",
       "  'subsequ': 1,\n",
       "  'illustr': 1,\n",
       "  'seri': 1,\n",
       "  'test': 2,\n",
       "  'it': 1,\n",
       "  'applic': 1,\n",
       "  'small': 1,\n",
       "  'data': 1,\n",
       "  'experiment': 1,\n",
       "  'environ': 1,\n",
       "  'result': 1,\n",
       "  'compar': 1,\n",
       "  'favour': 1,\n",
       "  'with': 1,\n",
       "  'as': 1,\n",
       "  'employ': 1,\n",
       "  'smart-typ': 1,\n",
       "  'more': 1,\n",
       "  'extens': 1,\n",
       "  'suggest': 1,\n",
       "  'valid': 1},\n",
       " '85': {'interact': 1,\n",
       "  'in': 7,\n",
       "  'natur': 3,\n",
       "  'languag': 3,\n",
       "  'with': 1,\n",
       "  'artifici': 2,\n",
       "  'system': 9,\n",
       "  'the': 22,\n",
       "  'donau': 2,\n",
       "  'project': 3,\n",
       "  'thi': 2,\n",
       "  'paper': 2,\n",
       "  'is': 4,\n",
       "  'intend': 2,\n",
       "  'to': 4,\n",
       "  'propos': 1,\n",
       "  'a': 4,\n",
       "  'new': 2,\n",
       "  'methodolog': 1,\n",
       "  'approach': 1,\n",
       "  'concept': 1,\n",
       "  'and': 13,\n",
       "  'develop': 3,\n",
       "  'of': 14,\n",
       "  'understand': 2,\n",
       "  'contribut': 1,\n",
       "  'support': 1,\n",
       "  'by': 2,\n",
       "  'design': 1,\n",
       "  'implement': 1,\n",
       "  'experiment': 1,\n",
       "  'gener': 3,\n",
       "  'purpos': 1,\n",
       "  'domain': 2,\n",
       "  'orient': 2,\n",
       "  'present': 2,\n",
       "  'run': 1,\n",
       "  'at': 1,\n",
       "  'milan': 1,\n",
       "  'polytechn': 1,\n",
       "  'intellig': 1,\n",
       "  'base': 2,\n",
       "  'on': 3,\n",
       "  'two': 1,\n",
       "  'level': 3,\n",
       "  'modular': 1,\n",
       "  'architectur': 2,\n",
       "  'overcom': 1,\n",
       "  'lack': 1,\n",
       "  'flexibl': 1,\n",
       "  'often': 1,\n",
       "  'point': 1,\n",
       "  'out': 1,\n",
       "  'mani': 1,\n",
       "  'exist': 1,\n",
       "  'facilit': 1,\n",
       "  'exchang': 1,\n",
       "  'result': 1,\n",
       "  'actual': 1,\n",
       "  'experi': 1,\n",
       "  'between': 1,\n",
       "  'differ': 1,\n",
       "  'horizont': 1,\n",
       "  'allow': 1,\n",
       "  'an': 1,\n",
       "  'independ': 1,\n",
       "  'parallel': 1,\n",
       "  'singl': 1,\n",
       "  'segment': 2,\n",
       "  'syntact': 1,\n",
       "  'analys': 1,\n",
       "  'inform': 1,\n",
       "  'extractor': 1,\n",
       "  'legal': 1,\n",
       "  'control': 1,\n",
       "  'vertic': 1,\n",
       "  'ensur': 1,\n",
       "  'possibl': 1,\n",
       "  'chang': 1,\n",
       "  'enlarg': 1,\n",
       "  'or': 1,\n",
       "  'redefin': 1,\n",
       "  'definit': 1,\n",
       "  'semant': 1,\n",
       "  'which': 1,\n",
       "  'each': 2,\n",
       "  'particular': 1,\n",
       "  'version': 2,\n",
       "  'special': 1,\n",
       "  'simpl': 1,\n",
       "  'increment': 1,\n",
       "  'user-ori': 1,\n",
       "  'way': 1,\n",
       "  'mode': 1,\n",
       "  'oper': 1,\n",
       "  'are': 4,\n",
       "  'illustr': 2,\n",
       "  'detail': 1,\n",
       "  'linguist': 1,\n",
       "  'model': 1,\n",
       "  'knowledg': 1,\n",
       "  'represent': 1,\n",
       "  'pars': 1,\n",
       "  'algorithm': 1,\n",
       "  'describ': 1,\n",
       "  'mean': 1,\n",
       "  'select': 1,\n",
       "  'exampl': 1,\n",
       "  'perform': 1,\n",
       "  'evalu': 1,\n",
       "  'applic': 1,\n",
       "  'data': 1,\n",
       "  'inquiri': 1,\n",
       "  'report': 1,\n",
       "  'discuss': 1,\n",
       "  'promis': 1,\n",
       "  'direct': 1,\n",
       "  'for': 1,\n",
       "  'futur': 1,\n",
       "  'research': 1,\n",
       "  'conclus': 1},\n",
       " '86': {'approxim': 4,\n",
       "  'string': 2,\n",
       "  'match': 4,\n",
       "  'of': 3,\n",
       "  'is': 2,\n",
       "  'review': 2,\n",
       "  'with': 2,\n",
       "  'the': 5,\n",
       "  'aim': 1,\n",
       "  'survey': 2,\n",
       "  'techniqu': 1,\n",
       "  'suitabl': 1,\n",
       "  'for': 3,\n",
       "  'find': 1,\n",
       "  'an': 2,\n",
       "  'item': 1,\n",
       "  'in': 3,\n",
       "  'a': 4,\n",
       "  'databas': 1,\n",
       "  'when': 1,\n",
       "  'there': 1,\n",
       "  'may': 1,\n",
       "  'be': 3,\n",
       "  'spell': 1,\n",
       "  'mistak': 1,\n",
       "  'or': 2,\n",
       "  'other': 1,\n",
       "  'error': 2,\n",
       "  'keyword': 1,\n",
       "  'method': 2,\n",
       "  'found': 1,\n",
       "  'are': 4,\n",
       "  'classifi': 1,\n",
       "  'as': 1,\n",
       "  'either': 1,\n",
       "  'equival': 2,\n",
       "  'similar': 2,\n",
       "  'problem': 4,\n",
       "  'seen': 2,\n",
       "  'to': 3,\n",
       "  'readili': 1,\n",
       "  'solv': 1,\n",
       "  'use': 3,\n",
       "  'canon': 1,\n",
       "  'form': 1,\n",
       "  'differ': 2,\n",
       "  'measur': 1,\n",
       "  'full': 1,\n",
       "  'descript': 1,\n",
       "  'well-establish': 1,\n",
       "  'dynam': 1,\n",
       "  'program': 1,\n",
       "  'relat': 1,\n",
       "  'thi': 1,\n",
       "  'approach': 1,\n",
       "  'probabl': 1,\n",
       "  'and': 1,\n",
       "  'likelihood': 1,\n",
       "  'search': 1,\n",
       "  'larg': 1,\n",
       "  'set': 1,\n",
       "  'function': 1,\n",
       "  'open': 1,\n",
       "  'still': 1,\n",
       "  'though': 1,\n",
       "  'sever': 1,\n",
       "  'promis': 1,\n",
       "  'idea': 1,\n",
       "  'have': 1,\n",
       "  'been': 1,\n",
       "  'suggest': 1,\n",
       "  'correct': 1,\n",
       "  'dure': 1,\n",
       "  'pars': 1,\n",
       "  'briefli': 1},\n",
       " '87': {'use': 3,\n",
       "  'an': 2,\n",
       "  'onlin': 5,\n",
       "  'microfich': 5,\n",
       "  'catalog': 5,\n",
       "  'for': 5,\n",
       "  'technic': 2,\n",
       "  'servic': 2,\n",
       "  'and': 7,\n",
       "  'retriev': 2,\n",
       "  'of': 10,\n",
       "  'bibliograph': 3,\n",
       "  'data': 4,\n",
       "  'a': 4,\n",
       "  'prototyp': 1,\n",
       "  'system': 6,\n",
       "  'is': 4,\n",
       "  'creat': 1,\n",
       "  'that': 1,\n",
       "  'integr': 1,\n",
       "  'into': 1,\n",
       "  'comput': 1,\n",
       "  'control': 1,\n",
       "  'cost': 3,\n",
       "  'oper': 3,\n",
       "  'are': 1,\n",
       "  'collect': 1,\n",
       "  'analyz': 1,\n",
       "  'the': 13,\n",
       "  'permit': 1,\n",
       "  'more': 1,\n",
       "  'econom': 1,\n",
       "  'storag': 2,\n",
       "  'record': 1,\n",
       "  'than': 1,\n",
       "  'would': 1,\n",
       "  'be': 1,\n",
       "  'feasibl': 2,\n",
       "  'compar': 1,\n",
       "  'magnet': 1,\n",
       "  'disk': 1,\n",
       "  'experiment': 2,\n",
       "  'test': 1,\n",
       "  'demonstr': 3,\n",
       "  'in': 1,\n",
       "  'librari': 1,\n",
       "  'primari': 1,\n",
       "  'result': 2,\n",
       "  'project': 1,\n",
       "  'creation': 1,\n",
       "  'complet': 1,\n",
       "  'facil': 1,\n",
       "  'includ': 1,\n",
       "  'all': 1,\n",
       "  'equip': 1,\n",
       "  'softwar': 1,\n",
       "  'procedur': 1,\n",
       "  'base': 1,\n",
       "  'necessari': 1,\n",
       "  'to': 1,\n",
       "  'second': 1,\n",
       "  'set': 1,\n",
       "  'deriv': 1,\n",
       "  'from': 1,\n",
       "  'evalu': 1,\n",
       "  'time': 1,\n",
       "  'variou': 1,\n",
       "  'effect': 1},\n",
       " '88': {'natur': 3,\n",
       "  'languag': 7,\n",
       "  'access': 1,\n",
       "  'to': 3,\n",
       "  'inform': 2,\n",
       "  'system': 4,\n",
       "  'an': 1,\n",
       "  'evalu': 3,\n",
       "  'studi': 1,\n",
       "  'of': 5,\n",
       "  'it': 2,\n",
       "  'accept': 1,\n",
       "  'by': 1,\n",
       "  'end': 1,\n",
       "  'user': 2,\n",
       "  'the': 4,\n",
       "  'question': 2,\n",
       "  'is': 2,\n",
       "  'ask': 1,\n",
       "  'whether': 1,\n",
       "  'feasibl': 1,\n",
       "  'use': 3,\n",
       "  'subset': 2,\n",
       "  'as': 2,\n",
       "  'queri': 2,\n",
       "  'for': 1,\n",
       "  'data': 1,\n",
       "  'base': 2,\n",
       "  'in': 1,\n",
       "  'actual': 1,\n",
       "  'applic': 2,\n",
       "  'answer': 1,\n",
       "  '``': 1,\n",
       "  'specialti': 1,\n",
       "  \"''\": 1,\n",
       "  'usl': 1,\n",
       "  'method': 1,\n",
       "  'a': 2,\n",
       "  'will': 1,\n",
       "  'be': 1,\n",
       "  'discuss': 1,\n",
       "  'result': 1,\n",
       "  'error': 1,\n",
       "  'and': 1,\n",
       "  'structur': 1,\n",
       "  'suggest': 1,\n",
       "  'how': 1,\n",
       "  'form': 1,\n",
       "  'gener': 1,\n",
       "  'architectur': 1,\n",
       "  'which': 1,\n",
       "  'german': 1},\n",
       " '89': {'some': 2,\n",
       "  'consider': 1,\n",
       "  'relat': 1,\n",
       "  'to': 3,\n",
       "  'the': 7,\n",
       "  'cost-effect': 2,\n",
       "  'of': 7,\n",
       "  'onlin': 5,\n",
       "  'servic': 4,\n",
       "  'in': 5,\n",
       "  'librari': 3,\n",
       "  '1978': 1,\n",
       "  'collier': 2,\n",
       "  'present': 2,\n",
       "  'hypothet': 1,\n",
       "  'data': 2,\n",
       "  'on': 1,\n",
       "  'econom': 2,\n",
       "  'aspect': 2,\n",
       "  'use': 2,\n",
       "  'as': 1,\n",
       "  'compar': 2,\n",
       "  'with': 1,\n",
       "  'subscript': 1,\n",
       "  'print': 2,\n",
       "  \"'s\": 1,\n",
       "  'view': 1,\n",
       "  'search': 2,\n",
       "  'seem': 1,\n",
       "  'misleadingli': 1,\n",
       "  'pessimist': 1,\n",
       "  'becaus': 1,\n",
       "  '1.': 1,\n",
       "  'it': 1,\n",
       "  'look': 1,\n",
       "  'onli': 1,\n",
       "  'at': 2,\n",
       "  'cost': 3,\n",
       "  'but': 1,\n",
       "  'not': 1,\n",
       "  'effect': 2,\n",
       "  'two': 1,\n",
       "  'mode': 2,\n",
       "  'access': 2,\n",
       "  'and': 4,\n",
       "  'an': 1,\n",
       "  'analysi': 2,\n",
       "  'combin': 1,\n",
       "  'i.e.': 1,\n",
       "  'a': 2,\n",
       "  'would': 1,\n",
       "  'give': 1,\n",
       "  'complet': 1,\n",
       "  'differ': 1,\n",
       "  'pictur': 1,\n",
       "  '2.': 1,\n",
       "  'way': 1,\n",
       "  'are': 1,\n",
       "  'is': 1,\n",
       "  'grossli': 1,\n",
       "  'unfair': 1,\n",
       "  'thi': 1,\n",
       "  'work': 1,\n",
       "  'contain': 1,\n",
       "  'correct': 1,\n",
       "  'inform': 1,\n",
       "  'regard': 1},\n",
       " '90': {'co-cit': 1,\n",
       "  'context': 1,\n",
       "  'analysi': 2,\n",
       "  'and': 7,\n",
       "  'the': 22,\n",
       "  'structur': 5,\n",
       "  'of': 20,\n",
       "  'paradigm': 4,\n",
       "  'mani': 1,\n",
       "  'inform': 1,\n",
       "  'scientist': 4,\n",
       "  'are': 5,\n",
       "  'concern': 1,\n",
       "  'with': 5,\n",
       "  'oper': 1,\n",
       "  'document': 1,\n",
       "  'retriev': 1,\n",
       "  'system': 2,\n",
       "  'serv': 2,\n",
       "  'in': 12,\n",
       "  'variou': 1,\n",
       "  'field': 3,\n",
       "  'by': 2,\n",
       "  'these': 1,\n",
       "  'often': 2,\n",
       "  'member': 1,\n",
       "  'what': 1,\n",
       "  'have': 2,\n",
       "  'been': 1,\n",
       "  'call': 1,\n",
       "  'invis': 1,\n",
       "  'colleg': 1,\n",
       "  'group': 2,\n",
       "  'frequent': 1,\n",
       "  'commun': 1,\n",
       "  'one': 1,\n",
       "  'anoth': 1,\n",
       "  'involv': 1,\n",
       "  'highli': 1,\n",
       "  'special': 1,\n",
       "  'subject': 2,\n",
       "  'matter': 2,\n",
       "  'such': 1,\n",
       "  'consid': 1,\n",
       "  'to': 7,\n",
       "  'share': 1,\n",
       "  'an': 1,\n",
       "  'intellectu': 1,\n",
       "  'perspect': 1,\n",
       "  'regard': 2,\n",
       "  'thi': 3,\n",
       "  'which': 4,\n",
       "  'is': 6,\n",
       "  'sometim': 1,\n",
       "  'refer': 1,\n",
       "  'as': 5,\n",
       "  'a': 17,\n",
       "  'purpos': 1,\n",
       "  'paper': 6,\n",
       "  'show': 1,\n",
       "  'how': 1,\n",
       "  'it': 1,\n",
       "  'possibl': 1,\n",
       "  'identifi': 2,\n",
       "  'use': 3,\n",
       "  'techniqu': 1,\n",
       "  'citat': 1,\n",
       "  'i': 1,\n",
       "  'will': 3,\n",
       "  'operation': 1,\n",
       "  'notion': 1,\n",
       "  \"'consensu\": 1,\n",
       "  'concept': 12,\n",
       "  'suppos': 2,\n",
       "  'we': 4,\n",
       "  'obtain': 1,\n",
       "  'set': 2,\n",
       "  'pertain': 1,\n",
       "  'some': 3,\n",
       "  'topic': 2,\n",
       "  'alreadi': 1,\n",
       "  'know': 1,\n",
       "  'someth': 1,\n",
       "  'about': 1,\n",
       "  'read': 1,\n",
       "  'each': 2,\n",
       "  'text': 1,\n",
       "  'mark': 1,\n",
       "  'passag': 1,\n",
       "  'certain': 2,\n",
       "  'specif': 1,\n",
       "  'or': 1,\n",
       "  'discuss': 1,\n",
       "  'for': 3,\n",
       "  'exampl': 1,\n",
       "  'might': 1,\n",
       "  'find': 1,\n",
       "  'that': 3,\n",
       "  'design': 1,\n",
       "  'appear': 1,\n",
       "  'sub-set': 1,\n",
       "  'further': 1,\n",
       "  'those': 1,\n",
       "  'b': 2,\n",
       "  'togeth': 1,\n",
       "  'same': 2,\n",
       "  'specifi': 1,\n",
       "  'manner': 1,\n",
       "  'clearli': 1,\n",
       "  'not': 2,\n",
       "  'all': 2,\n",
       "  'combin': 5,\n",
       "  'natur': 1,\n",
       "  'way': 2,\n",
       "  'author': 1,\n",
       "  'do': 1,\n",
       "  'so': 1,\n",
       "  'though': 1,\n",
       "  'predomin': 1,\n",
       "  'mode': 1,\n",
       "  'may': 1,\n",
       "  'emerg': 1,\n",
       "  'n': 2,\n",
       "  'their': 1,\n",
       "  'given': 2,\n",
       "  'total': 1,\n",
       "  'admiss': 1,\n",
       "  'taken': 2,\n",
       "  'from': 1,\n",
       "  'two': 2,\n",
       "  'at': 2,\n",
       "  'time': 2,\n",
       "  'frequenc': 1,\n",
       "  'occur': 1,\n",
       "  'sampl': 1,\n",
       "  'on': 1,\n",
       "  'measur': 2,\n",
       "  'degre': 1,\n",
       "  'consensu': 2,\n",
       "  'particular': 1,\n",
       "  'within': 1,\n",
       "  'corpu': 1,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'display': 1,\n",
       "  'graph': 2,\n",
       "  'node': 2,\n",
       "  'relat': 1,\n",
       "  'between': 1,\n",
       "  'them': 1,\n",
       "  'repres': 1,\n",
       "  'line': 1,\n",
       "  'arc': 2,\n",
       "  'connect': 1,\n",
       "  'definit': 1,\n",
       "  'similar': 1,\n",
       "  'semant': 1,\n",
       "  'network': 1,\n",
       "  'artifici': 1,\n",
       "  'intellig': 1,\n",
       "  'except': 1,\n",
       "  'our': 1,\n",
       "  'approach': 1,\n",
       "  'weight': 1},\n",
       " '91': {'cocit': 2,\n",
       "  'author': 5,\n",
       "  'retriev': 7,\n",
       "  'onlin': 2,\n",
       "  'an': 2,\n",
       "  'experi': 1,\n",
       "  'with': 3,\n",
       "  'the': 14,\n",
       "  'social': 5,\n",
       "  'indic': 4,\n",
       "  'literatur': 2,\n",
       "  'one': 1,\n",
       "  'mode': 1,\n",
       "  'of': 8,\n",
       "  'in': 7,\n",
       "  'scisearch': 2,\n",
       "  'or': 1,\n",
       "  'involv': 1,\n",
       "  'enter': 1,\n",
       "  'pair': 5,\n",
       "  'name': 2,\n",
       "  'believ': 1,\n",
       "  'to': 3,\n",
       "  'be': 3,\n",
       "  'jointli': 1,\n",
       "  'cite': 4,\n",
       "  'by': 4,\n",
       "  'subsequ': 1,\n",
       "  'writer': 1,\n",
       "  'and': 7,\n",
       "  'paper': 9,\n",
       "  'which': 2,\n",
       "  'occur': 1,\n",
       "  'six': 1,\n",
       "  'were': 4,\n",
       "  'form': 1,\n",
       "  'four': 2,\n",
       "  'promin': 1,\n",
       "  'movement': 3,\n",
       "  'bauer': 1,\n",
       "  'duncan': 3,\n",
       "  'land': 3,\n",
       "  'sheldon': 1,\n",
       "  'document': 3,\n",
       "  'not': 1,\n",
       "  'specifi': 1,\n",
       "  'it': 2,\n",
       "  'wa': 2,\n",
       "  'thought': 1,\n",
       "  'that': 3,\n",
       "  'would': 2,\n",
       "  'indicator-typ': 1,\n",
       "  'data': 1,\n",
       "  'integr': 1,\n",
       "  'path-analyt': 2,\n",
       "  'causal': 2,\n",
       "  'model': 2,\n",
       "  'all': 1,\n",
       "  'other': 2,\n",
       "  'seem': 1,\n",
       "  'like': 1,\n",
       "  'a': 1,\n",
       "  '``': 2,\n",
       "  'gener': 3,\n",
       "  \"''\": 2,\n",
       "  '298': 1,\n",
       "  'confirm': 1,\n",
       "  'expectatt': 1,\n",
       "  'found': 1,\n",
       "  '121': 1,\n",
       "  'si': 4,\n",
       "  'input': 3,\n",
       "  'frequent': 1,\n",
       "  'had': 1,\n",
       "  'languag': 1,\n",
       "  'their': 1,\n",
       "  'titl': 1,\n",
       "  'sign': 1,\n",
       "  'content': 1,\n",
       "  'also': 1,\n",
       "  'identifi': 1,\n",
       "  'them': 1,\n",
       "  'as': 2,\n",
       "  '177': 1,\n",
       "  'on': 1,\n",
       "  'natur': 1,\n",
       "  'expect': 1,\n",
       "  'they': 1,\n",
       "  'rel': 1,\n",
       "  'harder': 1,\n",
       "  'than': 1,\n",
       "  'first': 1,\n",
       "  'group': 2,\n",
       "  'although': 1,\n",
       "  'two': 1,\n",
       "  'are': 2,\n",
       "  'akin': 1,\n",
       "  'formal': 1,\n",
       "  'link': 1,\n",
       "  'through': 1,\n",
       "  'citat': 1,\n",
       "  'certain': 1,\n",
       "  'addit': 1,\n",
       "  'result': 1,\n",
       "  'is': 1,\n",
       "  'at': 1,\n",
       "  'least': 1,\n",
       "  'three': 1,\n",
       "  'tend': 1,\n",
       "  'overview': 1},\n",
       " '92': {'databas': 6,\n",
       "  'and': 4,\n",
       "  'onlin': 3,\n",
       "  'statist': 1,\n",
       "  'for': 2,\n",
       "  '1979': 3,\n",
       "  'the': 5,\n",
       "  'number': 1,\n",
       "  'of': 2,\n",
       "  'record': 2,\n",
       "  'contain': 2,\n",
       "  'in': 2,\n",
       "  'use': 1,\n",
       "  'ha': 1,\n",
       "  'increas': 1,\n",
       "  'dramat': 1,\n",
       "  'over': 1,\n",
       "  'past': 1,\n",
       "  'sever': 1,\n",
       "  'year': 1,\n",
       "  'bring': 1,\n",
       "  'total': 1,\n",
       "  'bibliograph': 1,\n",
       "  'bioliographic-rel': 1,\n",
       "  'natur': 1,\n",
       "  'languag': 1,\n",
       "  'to': 1,\n",
       "  '528.': 1,\n",
       "  'these': 1,\n",
       "  '528': 1,\n",
       "  '148': 1,\n",
       "  'million': 2,\n",
       "  'some': 1,\n",
       "  '4': 1,\n",
       "  'search': 1,\n",
       "  'were': 1,\n",
       "  'conduct': 1,\n",
       "  'via': 1,\n",
       "  'major': 1,\n",
       "  'u.s.': 1,\n",
       "  'canadian': 1,\n",
       "  'system': 1},\n",
       " '93': {'experi': 4,\n",
       "  'in': 5,\n",
       "  'local': 2,\n",
       "  'metric': 2,\n",
       "  'feedback': 2,\n",
       "  'full-text': 2,\n",
       "  'retriev': 1,\n",
       "  'system': 1,\n",
       "  'a': 3,\n",
       "  'method': 4,\n",
       "  'of': 11,\n",
       "  'iter': 6,\n",
       "  'search': 4,\n",
       "  'use': 3,\n",
       "  'the': 12,\n",
       "  'result': 2,\n",
       "  'one': 1,\n",
       "  'to': 10,\n",
       "  'formul': 2,\n",
       "  'next': 2,\n",
       "  'wa': 1,\n",
       "  'appli': 1,\n",
       "  'databas': 5,\n",
       "  'consist': 3,\n",
       "  'some': 1,\n",
       "  '2400': 1,\n",
       "  'document': 2,\n",
       "  'and': 6,\n",
       "  '1,3000,000': 1,\n",
       "  'text-word': 1,\n",
       "  'hebrew': 1,\n",
       "  'arama': 1,\n",
       "  'cluster': 2,\n",
       "  'return': 1,\n",
       "  'an': 3,\n",
       "  'weight': 1,\n",
       "  'by': 3,\n",
       "  'proxim': 1,\n",
       "  'frequenc': 1,\n",
       "  'simultan': 2,\n",
       "  'process': 1,\n",
       "  'produc': 1,\n",
       "  'searchonym': 2,\n",
       "  'which': 1,\n",
       "  'are': 3,\n",
       "  'term': 1,\n",
       "  'synonym': 1,\n",
       "  'keyword': 2,\n",
       "  'context': 1,\n",
       "  'singl': 1,\n",
       "  'queri': 1,\n",
       "  'augument': 1,\n",
       "  'or': 2,\n",
       "  'replac': 1,\n",
       "  'via': 1,\n",
       "  'manual': 1,\n",
       "  'automat': 1,\n",
       "  'lead': 1,\n",
       "  'with': 1,\n",
       "  'those': 1,\n",
       "  'earlier': 1,\n",
       "  'small-scal': 1,\n",
       "  'on': 2,\n",
       "  'english': 1,\n",
       "  'indic': 1,\n",
       "  'that': 1,\n",
       "  'contrast': 1,\n",
       "  'global': 1,\n",
       "  'where': 1,\n",
       "  'size': 1,\n",
       "  'matric': 1,\n",
       "  'limit': 1,\n",
       "  'applic': 1,\n",
       "  'small': 1,\n",
       "  'improv': 2,\n",
       "  'doubt': 1,\n",
       "  'appear': 1,\n",
       "  'be': 2,\n",
       "  'well': 1,\n",
       "  'suit': 1,\n",
       "  'arbitrarili': 1,\n",
       "  'larg': 1,\n",
       "  'precis': 1,\n",
       "  'recal': 1,\n",
       "  'further': 2,\n",
       "  'more': 1,\n",
       "  'test-queri': 1,\n",
       "  'run': 1,\n",
       "  'even': 1,\n",
       "  'larger': 1,\n",
       "  'should': 1,\n",
       "  'made': 1,\n",
       "  'collect': 1,\n",
       "  'evid': 1,\n",
       "  'as': 1,\n",
       "  'perform': 1,\n",
       "  'these': 1},\n",
       " '94': {'a': 6,\n",
       "  'microcomput': 1,\n",
       "  'altern': 1,\n",
       "  'for': 2,\n",
       "  'inform': 2,\n",
       "  'handl': 1,\n",
       "  'refl': 4,\n",
       "  'is': 2,\n",
       "  'microcomputer-bas': 1,\n",
       "  'system': 4,\n",
       "  'data': 3,\n",
       "  'retriev': 2,\n",
       "  'in': 4,\n",
       "  'librari': 1,\n",
       "  'environ': 2,\n",
       "  'the': 5,\n",
       "  'problem': 1,\n",
       "  'of': 8,\n",
       "  'discuss': 1,\n",
       "  'from': 1,\n",
       "  'theoret': 1,\n",
       "  'point': 1,\n",
       "  'view': 1,\n",
       "  'follow': 1,\n",
       "  'by': 1,\n",
       "  'an': 1,\n",
       "  'analysi': 1,\n",
       "  'refer': 1,\n",
       "  'process': 1,\n",
       "  'and': 4,\n",
       "  'therebi': 1,\n",
       "  'gather': 1,\n",
       "  'lead': 1,\n",
       "  'to': 1,\n",
       "  'descript': 1,\n",
       "  'term': 1,\n",
       "  'it': 2,\n",
       "  'hardwar': 1,\n",
       "  'softwar': 1,\n",
       "  'prototyp': 1,\n",
       "  'at': 1,\n",
       "  'present': 2,\n",
       "  'current': 1,\n",
       "  'function': 1,\n",
       "  'test': 1,\n",
       "  'exampl': 1,\n",
       "  'contain': 1,\n",
       "  'use': 1,\n",
       "  'are': 1,\n",
       "  'futur': 1,\n",
       "  'consider': 1,\n",
       "  'specul': 1,\n",
       "  'on': 1,\n",
       "  'other': 1,\n",
       "  'version': 1,\n",
       "  'conclud': 1,\n",
       "  'paper': 1},\n",
       " '95': {'a': 6,\n",
       "  'comparison': 1,\n",
       "  'of': 6,\n",
       "  'two': 2,\n",
       "  'system': 5,\n",
       "  'weight': 6,\n",
       "  'boolean': 5,\n",
       "  'retriev': 2,\n",
       "  'major': 1,\n",
       "  'defici': 1,\n",
       "  'tradit': 2,\n",
       "  'is': 3,\n",
       "  'their': 1,\n",
       "  'inabl': 1,\n",
       "  'to': 4,\n",
       "  'repres': 1,\n",
       "  'the': 4,\n",
       "  'vari': 1,\n",
       "  'degre': 1,\n",
       "  'which': 1,\n",
       "  'document': 1,\n",
       "  'may': 1,\n",
       "  'be': 2,\n",
       "  'written': 1,\n",
       "  'on': 1,\n",
       "  'subject': 1,\n",
       "  'in': 2,\n",
       "  'thi': 2,\n",
       "  'articl': 1,\n",
       "  'we': 1,\n",
       "  'isol': 1,\n",
       "  'number': 1,\n",
       "  'criteria': 1,\n",
       "  'that': 4,\n",
       "  'should': 1,\n",
       "  'met': 1,\n",
       "  'by': 1,\n",
       "  'ani': 1,\n",
       "  'gener': 1,\n",
       "  'have': 1,\n",
       "  'capabl': 1,\n",
       "  'it': 1,\n",
       "  'proven': 1,\n",
       "  'onli': 1,\n",
       "  'one': 1,\n",
       "  'rule': 1,\n",
       "  'satisfi': 2,\n",
       "  'these': 1,\n",
       "  'condit': 1,\n",
       "  '--': 2,\n",
       "  'associ': 2,\n",
       "  'with': 2,\n",
       "  'fuzzy-': 1,\n",
       "  'set': 1,\n",
       "  'theori': 1,\n",
       "  'and': 2,\n",
       "  'scheme': 1,\n",
       "  'most': 1,\n",
       "  'other': 1,\n",
       "  'properti': 1,\n",
       "  'algebra': 1,\n",
       "  'as': 2,\n",
       "  'well': 1,\n",
       "  'probabilist': 1,\n",
       "  'then': 1,\n",
       "  'introduc': 1,\n",
       "  'an': 1,\n",
       "  'altern': 1,\n",
       "  'approach': 1,\n",
       "  'compar': 1,\n",
       "  'limit': 1,\n",
       "  'zero/on': 1,\n",
       "  'all': 1,\n",
       "  'consid': 1,\n",
       "  'converg': 1},\n",
       " '96': {'threshold': 2,\n",
       "  'valu': 2,\n",
       "  'and': 1,\n",
       "  'boolean': 2,\n",
       "  'retriev': 3,\n",
       "  'system': 2,\n",
       "  'sever': 1,\n",
       "  'paper': 2,\n",
       "  'have': 2,\n",
       "  'appear': 1,\n",
       "  'that': 3,\n",
       "  'analyz': 1,\n",
       "  'recent': 1,\n",
       "  'develop': 1,\n",
       "  'in': 2,\n",
       "  'the': 4,\n",
       "  'problem': 2,\n",
       "  'of': 4,\n",
       "  'process': 1,\n",
       "  'a': 1,\n",
       "  'document': 2,\n",
       "  'queri': 1,\n",
       "  'express': 2,\n",
       "  'as': 1,\n",
       "  'purpos': 1,\n",
       "  'thi': 1,\n",
       "  'is': 1,\n",
       "  'to': 1,\n",
       "  'continu': 1,\n",
       "  'analysi': 1,\n",
       "  'we': 2,\n",
       "  'shall': 2,\n",
       "  'show': 1,\n",
       "  'concept': 1,\n",
       "  'resolv': 1,\n",
       "  'inher': 1,\n",
       "  'with': 1,\n",
       "  'relev': 1,\n",
       "  'weight': 1,\n",
       "  'moreov': 1,\n",
       "  'explor': 1,\n",
       "  'possibl': 1,\n",
       "  'evalu': 1,\n",
       "  'mechan': 1,\n",
       "  'for': 1,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'fuzzy-set-theoret': 1,\n",
       "  'consider': 1},\n",
       " '97': {'a': 8,\n",
       "  'model': 1,\n",
       "  'for': 2,\n",
       "  'weight': 5,\n",
       "  'retriev': 3,\n",
       "  'system': 4,\n",
       "  'there': 1,\n",
       "  'ha': 1,\n",
       "  'been': 1,\n",
       "  'good': 1,\n",
       "  'deal': 1,\n",
       "  'of': 4,\n",
       "  'work': 1,\n",
       "  'on': 2,\n",
       "  'inform': 1,\n",
       "  'that': 3,\n",
       "  'have': 3,\n",
       "  'continu': 2,\n",
       "  'assign': 1,\n",
       "  'to': 6,\n",
       "  'the': 11,\n",
       "  'index': 1,\n",
       "  'term': 3,\n",
       "  'describ': 2,\n",
       "  'record': 2,\n",
       "  'in': 1,\n",
       "  'databas': 1,\n",
       "  'and/or': 2,\n",
       "  'queri': 4,\n",
       "  'user': 2,\n",
       "  'recent': 1,\n",
       "  'articl': 1,\n",
       "  'analyz': 1,\n",
       "  'with': 2,\n",
       "  'either': 1,\n",
       "  'type': 1,\n",
       "  'boolean': 1,\n",
       "  'structur': 1,\n",
       "  'they': 1,\n",
       "  'also': 2,\n",
       "  'suggest': 1,\n",
       "  'criteria': 3,\n",
       "  'which': 3,\n",
       "  'such': 1,\n",
       "  'ought': 1,\n",
       "  'satisfi': 2,\n",
       "  'and': 2,\n",
       "  'evalu': 2,\n",
       "  'mechan': 4,\n",
       "  'partial': 1,\n",
       "  'these': 1,\n",
       "  'we': 3,\n",
       "  'offer': 1,\n",
       "  'more': 1,\n",
       "  'care': 1,\n",
       "  'analysi': 1,\n",
       "  'base': 1,\n",
       "  'gener': 2,\n",
       "  'discret': 1,\n",
       "  'look': 1,\n",
       "  'at': 1,\n",
       "  'from': 1,\n",
       "  'an': 2,\n",
       "  'entir': 1,\n",
       "  'differ': 1,\n",
       "  'approach': 1,\n",
       "  'involv': 1,\n",
       "  'threshold': 2,\n",
       "  'improv': 1,\n",
       "  'seem': 1,\n",
       "  'fulfil': 1,\n",
       "  'larger': 1,\n",
       "  'subset': 1,\n",
       "  'desir': 1,\n",
       "  'than': 1,\n",
       "  'previou': 1,\n",
       "  'thi': 1,\n",
       "  'new': 1,\n",
       "  'allow': 1,\n",
       "  'attach': 1,\n",
       "  '``': 1,\n",
       "  \"''\": 1},\n",
       " '98': {'a': 6,\n",
       "  'translat': 3,\n",
       "  'comput': 2,\n",
       "  'interfac': 7,\n",
       "  'for': 3,\n",
       "  'end-us': 1,\n",
       "  'oper': 2,\n",
       "  'of': 6,\n",
       "  'heterogen': 3,\n",
       "  'retriev': 3,\n",
       "  'system': 7,\n",
       "  'i.': 1,\n",
       "  'design': 2,\n",
       "  'onlin': 1,\n",
       "  'may': 2,\n",
       "  'be': 4,\n",
       "  'difficult': 1,\n",
       "  'to': 7,\n",
       "  'use': 1,\n",
       "  'especi': 1,\n",
       "  'by': 3,\n",
       "  'end': 1,\n",
       "  'user': 5,\n",
       "  'becaus': 1,\n",
       "  'and': 5,\n",
       "  'complex': 1,\n",
       "  'investig': 1,\n",
       "  'have': 1,\n",
       "  'concern': 1,\n",
       "  'the': 11,\n",
       "  'concept': 1,\n",
       "  'as': 1,\n",
       "  'mean': 1,\n",
       "  'simplifi': 1,\n",
       "  'access': 1,\n",
       "  'bibliograph': 1,\n",
       "  'databas': 1,\n",
       "  'allow': 1,\n",
       "  'make': 1,\n",
       "  'request': 2,\n",
       "  'in': 1,\n",
       "  'common': 2,\n",
       "  'languag': 1,\n",
       "  'these': 1,\n",
       "  'are': 2,\n",
       "  'into': 2,\n",
       "  'appropri': 1,\n",
       "  'command': 1,\n",
       "  'whatev': 1,\n",
       "  'is': 2,\n",
       "  'interrog': 1,\n",
       "  'respons': 1,\n",
       "  'also': 2,\n",
       "  'transform': 1,\n",
       "  'form': 1,\n",
       "  'befor': 1,\n",
       "  'given': 1,\n",
       "  'thu': 1,\n",
       "  'network': 1,\n",
       "  'differ': 1,\n",
       "  'made': 1,\n",
       "  'look': 1,\n",
       "  'like': 1,\n",
       "  'singl': 1,\n",
       "  '``': 1,\n",
       "  'virtual': 1,\n",
       "  \"''\": 1,\n",
       "  'provid': 1,\n",
       "  'instruct': 1,\n",
       "  'other': 1,\n",
       "  'search': 1,\n",
       "  'aid': 1,\n",
       "  'philosophi': 1,\n",
       "  'implement': 1,\n",
       "  'an': 1,\n",
       "  'experiment': 1,\n",
       "  'name': 1,\n",
       "  'conit': 1,\n",
       "  'describ': 1},\n",
       " '99': {'a': 7,\n",
       "  'translat': 2,\n",
       "  'comput': 1,\n",
       "  'interfac': 5,\n",
       "  'for': 5,\n",
       "  'end-us': 1,\n",
       "  'oper': 4,\n",
       "  'of': 8,\n",
       "  'heterogen': 2,\n",
       "  'retriev': 4,\n",
       "  'system': 4,\n",
       "  'ii': 1,\n",
       "  'evalu': 2,\n",
       "  'the': 4,\n",
       "  'concept': 1,\n",
       "  'compuyt': 1,\n",
       "  'simplifi': 2,\n",
       "  'multipl': 1,\n",
       "  'onlin': 2,\n",
       "  'bibliograph': 1,\n",
       "  'ha': 1,\n",
       "  'been': 1,\n",
       "  'undertaken': 1,\n",
       "  'an': 1,\n",
       "  'experiment': 2,\n",
       "  'name': 1,\n",
       "  'conit': 1,\n",
       "  'wa': 2,\n",
       "  'built': 1,\n",
       "  'and': 3,\n",
       "  'test': 1,\n",
       "  'under': 1,\n",
       "  'control': 1,\n",
       "  'condit': 1,\n",
       "  'with': 1,\n",
       "  'inexperienc': 1,\n",
       "  'end': 1,\n",
       "  'user': 3,\n",
       "  'detail': 1,\n",
       "  'analysi': 1,\n",
       "  'usag': 1,\n",
       "  'show': 1,\n",
       "  'that': 2,\n",
       "  'were': 1,\n",
       "  'abl': 1,\n",
       "  'to': 4,\n",
       "  'master': 1,\n",
       "  'suffici': 1,\n",
       "  'well': 1,\n",
       "  'find': 1,\n",
       "  'relev': 1,\n",
       "  'document': 1,\n",
       "  'refer': 1,\n",
       "  'success': 1,\n",
       "  'attribut': 1,\n",
       "  'in': 2,\n",
       "  'part': 1,\n",
       "  'simpl': 1,\n",
       "  'command': 1,\n",
       "  'languag': 1,\n",
       "  'adequ': 1,\n",
       "  'instruct': 2,\n",
       "  'natural-languag': 1,\n",
       "  'keyword/stem': 1,\n",
       "  'approach': 1,\n",
       "  'search': 2,\n",
       "  'it': 1,\n",
       "  'is': 1,\n",
       "  'conclud': 1,\n",
       "  'type': 1,\n",
       "  'studi': 1,\n",
       "  'can': 1,\n",
       "  'provid': 1,\n",
       "  'increas': 1,\n",
       "  'usabl': 1,\n",
       "  'exist': 1,\n",
       "  'cost': 1,\n",
       "  'effect': 2,\n",
       "  'manner': 1,\n",
       "  'especi': 1,\n",
       "  'searcher': 1,\n",
       "  'furthermor': 1,\n",
       "  'more': 1,\n",
       "  'advanc': 1,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'improv': 1,\n",
       "  'autom': 1,\n",
       "  'strategi': 1,\n",
       "  'techniqu': 1,\n",
       "  'could': 1,\n",
       "  'further': 1,\n",
       "  'enhanc': 1,\n",
       "  'wide': 1,\n",
       "  'class': 1},\n",
       " '100': {'the': 6,\n",
       "  'interfac': 1,\n",
       "  'between': 2,\n",
       "  'computer': 2,\n",
       "  'retriev': 6,\n",
       "  'system': 5,\n",
       "  'and': 4,\n",
       "  'micrograph': 4,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'note': 1,\n",
       "  'benefit': 1,\n",
       "  'accru': 1,\n",
       "  'from': 2,\n",
       "  'interact': 1,\n",
       "  'it': 1,\n",
       "  'review': 1,\n",
       "  'current': 1,\n",
       "  'state': 1,\n",
       "  'of': 4,\n",
       "  'autom': 2,\n",
       "  'technolog': 2,\n",
       "  'conclus': 1,\n",
       "  'is': 1,\n",
       "  'that': 1,\n",
       "  'with': 1,\n",
       "  'a': 1,\n",
       "  'combin': 1,\n",
       "  'advanc': 1,\n",
       "  'in': 1,\n",
       "  'commun': 1,\n",
       "  'sophist': 1,\n",
       "  'index': 1,\n",
       "  'input': 1,\n",
       "  'librari': 1,\n",
       "  'inform': 1,\n",
       "  'scientist': 1,\n",
       "  'new': 1,\n",
       "  'gener': 1,\n",
       "  'devic': 1,\n",
       "  'may': 1,\n",
       "  'constitut': 1,\n",
       "  'on-lin': 1,\n",
       "  'document': 1,\n",
       "  'futur': 1},\n",
       " '101': {'parallel': 5,\n",
       "  'comput': 3,\n",
       "  'in': 6,\n",
       "  'inform': 4,\n",
       "  'retriev': 7,\n",
       "  'convent': 2,\n",
       "  'process': 5,\n",
       "  'are': 4,\n",
       "  'larg': 1,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'data': 1,\n",
       "  'movement': 1,\n",
       "  'pointer': 1,\n",
       "  'manipul': 1,\n",
       "  'and': 4,\n",
       "  'integ': 1,\n",
       "  'arithmet': 1,\n",
       "  'more': 2,\n",
       "  'refin': 1,\n",
       "  'algorithm': 1,\n",
       "  'may': 1,\n",
       "  'addit': 1,\n",
       "  'benefit': 1,\n",
       "  'from': 1,\n",
       "  'substanti': 1,\n",
       "  'power': 1,\n",
       "  'the': 3,\n",
       "  'present': 1,\n",
       "  'studi': 1,\n",
       "  'a': 1,\n",
       "  'number': 1,\n",
       "  'of': 4,\n",
       "  'method': 1,\n",
       "  'describ': 1,\n",
       "  'that': 1,\n",
       "  'serv': 1,\n",
       "  'to': 2,\n",
       "  'enhanc': 1,\n",
       "  'servic': 1,\n",
       "  'environ': 1,\n",
       "  'list': 1,\n",
       "  'search': 1,\n",
       "  'facil': 2,\n",
       "  'greatest': 1,\n",
       "  'interest': 1,\n",
       "  'advanc': 1,\n",
       "  'system': 1,\n",
       "  'use': 2,\n",
       "  'array': 1,\n",
       "  'processor': 1,\n",
       "  'also': 1,\n",
       "  'prove': 1,\n",
       "  'benefici': 1,\n",
       "  'variou': 1,\n",
       "  'examin': 1,\n",
       "  'evid': 1,\n",
       "  'is': 1,\n",
       "  'given': 1,\n",
       "  'demonstr': 1,\n",
       "  'fast': 1},\n",
       " '102': {'the': 18,\n",
       "  'measur': 1,\n",
       "  'of': 8,\n",
       "  'term': 12,\n",
       "  'import': 2,\n",
       "  'in': 5,\n",
       "  'automat': 2,\n",
       "  'index': 3,\n",
       "  'frequenc': 2,\n",
       "  'characterist': 4,\n",
       "  'document': 2,\n",
       "  'a': 2,\n",
       "  'collect': 3,\n",
       "  'have': 2,\n",
       "  'been': 2,\n",
       "  'use': 3,\n",
       "  'as': 2,\n",
       "  'indic': 1,\n",
       "  'for': 2,\n",
       "  'content': 1,\n",
       "  'analysi': 1,\n",
       "  'and': 2,\n",
       "  'purpos': 1,\n",
       "  'particular': 1,\n",
       "  'veri': 2,\n",
       "  'rare': 1,\n",
       "  'or': 1,\n",
       "  'frequent': 1,\n",
       "  'are': 6,\n",
       "  'normal': 1,\n",
       "  'believ': 1,\n",
       "  'to': 2,\n",
       "  'be': 1,\n",
       "  'less': 1,\n",
       "  'effect': 1,\n",
       "  'than': 1,\n",
       "  'medium-frequ': 1,\n",
       "  'recent': 1,\n",
       "  'theori': 2,\n",
       "  'devis': 1,\n",
       "  'that': 2,\n",
       "  'not': 1,\n",
       "  'onli': 1,\n",
       "  'but': 1,\n",
       "  'also': 1,\n",
       "  'relev': 4,\n",
       "  'properti': 3,\n",
       "  'major': 1,\n",
       "  'term-weight': 1,\n",
       "  'first': 1,\n",
       "  'briefli': 1,\n",
       "  'review': 1,\n",
       "  'precis': 1,\n",
       "  'util': 1,\n",
       "  'weight': 2,\n",
       "  'base': 2,\n",
       "  'on': 2,\n",
       "  'occurr': 2,\n",
       "  'oppos': 1,\n",
       "  'nonrelev': 1,\n",
       "  'then': 1,\n",
       "  'introduc': 1,\n",
       "  'method': 1,\n",
       "  'suggest': 1,\n",
       "  'estim': 1,\n",
       "  'their': 1,\n",
       "  'overal': 1,\n",
       "  'final': 1,\n",
       "  'experiment': 1,\n",
       "  'evalu': 1,\n",
       "  'result': 1,\n",
       "  'shown': 1,\n",
       "  'compar': 1,\n",
       "  'system': 1,\n",
       "  'with': 1,\n",
       "  'more': 1,\n",
       "  'convent': 1,\n",
       "  'frequency-bas': 1,\n",
       "  'methodolog': 1},\n",
       " '103': {'ndx-100': 1,\n",
       "  'an': 2,\n",
       "  'electron': 2,\n",
       "  'file': 2,\n",
       "  'machin': 3,\n",
       "  'for': 1,\n",
       "  'the': 5,\n",
       "  'offic': 1,\n",
       "  'of': 6,\n",
       "  'futur': 1,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'describ': 1,\n",
       "  'design': 1,\n",
       "  'and': 3,\n",
       "  'implement': 2,\n",
       "  '``': 2,\n",
       "  \"''\": 2,\n",
       "  'a': 5,\n",
       "  'which': 1,\n",
       "  'is': 1,\n",
       "  'capabl': 1,\n",
       "  'store': 1,\n",
       "  'larg': 1,\n",
       "  'number': 1,\n",
       "  'unstructur': 1,\n",
       "  'document': 2,\n",
       "  'in': 2,\n",
       "  'such': 1,\n",
       "  'way': 1,\n",
       "  'particular': 1,\n",
       "  'may': 1,\n",
       "  'be': 1,\n",
       "  'easili': 1,\n",
       "  'quickli': 1,\n",
       "  'retriev': 1,\n",
       "  'function': 1,\n",
       "  'distribut': 1,\n",
       "  'architectur': 1,\n",
       "  'permit': 1,\n",
       "  'system': 1,\n",
       "  'mixtur': 1,\n",
       "  'hardwar': 1,\n",
       "  'softwar': 1},\n",
       " '104': {'the': 10,\n",
       "  'select': 2,\n",
       "  'of': 5,\n",
       "  'good': 1,\n",
       "  'search': 4,\n",
       "  'term': 7,\n",
       "  'thi': 1,\n",
       "  'paper': 1,\n",
       "  'tackl': 1,\n",
       "  'problem': 1,\n",
       "  'how': 1,\n",
       "  'one': 1,\n",
       "  'might': 1,\n",
       "  'further': 1,\n",
       "  'use': 1,\n",
       "  'relev': 1,\n",
       "  'feedback': 1,\n",
       "  'given': 1,\n",
       "  'in': 3,\n",
       "  'queri': 1,\n",
       "  'these': 1,\n",
       "  'are': 3,\n",
       "  'extract': 1,\n",
       "  'from': 2,\n",
       "  'a': 3,\n",
       "  'maximum': 1,\n",
       "  'span': 3,\n",
       "  'tree': 3,\n",
       "  'connect': 1,\n",
       "  'all': 1,\n",
       "  'index': 1,\n",
       "  'vocabulari': 1,\n",
       "  'number': 1,\n",
       "  'differ': 3,\n",
       "  'gener': 1,\n",
       "  'varieti': 1,\n",
       "  'associ': 1,\n",
       "  'measur': 2,\n",
       "  'retriev': 2,\n",
       "  'effect': 2,\n",
       "  'for': 1,\n",
       "  'is': 2,\n",
       "  'shown': 1,\n",
       "  'to': 1,\n",
       "  'be': 1,\n",
       "  'approxim': 1,\n",
       "  'same': 1,\n",
       "  'precis': 1,\n",
       "  'and': 2,\n",
       "  'recal': 1,\n",
       "  'test': 2,\n",
       "  'done': 1,\n",
       "  'on': 1,\n",
       "  'three': 1,\n",
       "  'collect': 1},\n",
       " '105': {'index': 6,\n",
       "  'consist': 2,\n",
       "  'qualiti': 3,\n",
       "  'and': 2,\n",
       "  'effici': 1,\n",
       "  'determin': 1,\n",
       "  'whether': 2,\n",
       "  'the': 3,\n",
       "  'inform': 1,\n",
       "  'content': 1,\n",
       "  'of': 4,\n",
       "  'an': 2,\n",
       "  'document': 2,\n",
       "  'is': 4,\n",
       "  'accur': 1,\n",
       "  'repres': 1,\n",
       "  'effect': 2,\n",
       "  'measur': 3,\n",
       "  'correctli': 1,\n",
       "  'retriev': 1,\n",
       "  'everi': 1,\n",
       "  'time': 1,\n",
       "  'it': 1,\n",
       "  'relev': 1,\n",
       "  'to': 1,\n",
       "  'a': 2,\n",
       "  'queri': 1,\n",
       "  'these': 1,\n",
       "  'criteria': 1,\n",
       "  'cumbersom': 1,\n",
       "  'costli': 1,\n",
       "  'data': 1,\n",
       "  'base': 1,\n",
       "  'produc': 1,\n",
       "  'therefor': 1,\n",
       "  'prefer': 1,\n",
       "  'inter-index': 1,\n",
       "  'as': 1,\n",
       "  'or': 1,\n",
       "  'present': 1,\n",
       "  'articl': 1,\n",
       "  'assess': 1,\n",
       "  'valid': 1,\n",
       "  'thi': 1,\n",
       "  'substitut': 1,\n",
       "  'in': 1,\n",
       "  'variou': 1,\n",
       "  'environ': 1},\n",
       " '106': {'text': 5,\n",
       "  'passag': 2,\n",
       "  'retriev': 6,\n",
       "  'base': 1,\n",
       "  'on': 1,\n",
       "  'colon': 4,\n",
       "  'classif': 3,\n",
       "  'perform': 3,\n",
       "  'a': 4,\n",
       "  'set': 1,\n",
       "  'of': 8,\n",
       "  'experi': 1,\n",
       "  'wa': 3,\n",
       "  'conduct': 1,\n",
       "  'to': 4,\n",
       "  'determin': 1,\n",
       "  'the': 12,\n",
       "  'suitabl': 1,\n",
       "  'as': 3,\n",
       "  'foundat': 1,\n",
       "  'for': 1,\n",
       "  'autom': 3,\n",
       "  'analysi': 1,\n",
       "  'represent': 1,\n",
       "  'and': 5,\n",
       "  'primari': 2,\n",
       "  'inform': 4,\n",
       "  'from': 2,\n",
       "  'full': 3,\n",
       "  'document': 2,\n",
       "  'is': 2,\n",
       "  'that': 2,\n",
       "  'embodi': 1,\n",
       "  'in': 6,\n",
       "  'oppos': 1,\n",
       "  'secondari': 1,\n",
       "  'which': 2,\n",
       "  'gener': 1,\n",
       "  'such': 1,\n",
       "  'form': 1,\n",
       "  'an': 3,\n",
       "  'abstract': 1,\n",
       "  'tabl': 1,\n",
       "  'content': 1,\n",
       "  'or': 1,\n",
       "  'index': 2,\n",
       "  'databas': 1,\n",
       "  'were': 3,\n",
       "  'creat': 3,\n",
       "  'two': 2,\n",
       "  'subject': 1,\n",
       "  'area': 2,\n",
       "  'queri': 1,\n",
       "  'solicit': 1,\n",
       "  'specialist': 1,\n",
       "  'each': 1,\n",
       "  'system': 8,\n",
       "  'along': 1,\n",
       "  'with': 1,\n",
       "  'four': 1,\n",
       "  'test': 1,\n",
       "  'variou': 1,\n",
       "  'featur': 1,\n",
       "  'boolean-bas': 1,\n",
       "  'one': 1,\n",
       "  'simpl': 1,\n",
       "  'word': 1,\n",
       "  'occurr': 1,\n",
       "  'order': 1,\n",
       "  'compar': 1,\n",
       "  'result': 1,\n",
       "  'against': 1,\n",
       "  'type': 1,\n",
       "  'are': 1,\n",
       "  'more': 1,\n",
       "  'common': 1,\n",
       "  'use': 2,\n",
       "  'measur': 1,\n",
       "  'recal': 1,\n",
       "  'precis': 1,\n",
       "  'mean': 1,\n",
       "  'expect': 1,\n",
       "  'search': 1,\n",
       "  'length': 1,\n",
       "  'reduct': 1,\n",
       "  'factor': 1,\n",
       "  'overal': 1,\n",
       "  'it': 1,\n",
       "  'found': 1,\n",
       "  'classification-bas': 1,\n",
       "  'did': 1,\n",
       "  'not': 1,\n",
       "  'significantli': 1,\n",
       "  'better': 1,\n",
       "  'than': 1,\n",
       "  'other': 1},\n",
       " '107': {'user-respons': 1,\n",
       "  'subject': 1,\n",
       "  'control': 1,\n",
       "  'in': 4,\n",
       "  'bibliograph': 1,\n",
       "  'retriev': 3,\n",
       "  'system': 2,\n",
       "  'a': 3,\n",
       "  'studi': 1,\n",
       "  'wa': 1,\n",
       "  'carri': 1,\n",
       "  'out': 1,\n",
       "  'of': 12,\n",
       "  'the': 15,\n",
       "  'relationship': 1,\n",
       "  'between': 1,\n",
       "  'vocabulari': 2,\n",
       "  'user': 3,\n",
       "  'queri': 4,\n",
       "  'and': 7,\n",
       "  'document': 4,\n",
       "  'relev': 1,\n",
       "  'to': 3,\n",
       "  'valu': 2,\n",
       "  'ad': 2,\n",
       "  'descript': 1,\n",
       "  'record': 1,\n",
       "  'keyword': 6,\n",
       "  'from': 1,\n",
       "  'previou': 1,\n",
       "  'for': 1,\n",
       "  'which': 1,\n",
       "  'had': 1,\n",
       "  'prove': 1,\n",
       "  'use': 2,\n",
       "  'two': 1,\n",
       "  'test': 2,\n",
       "  'databas': 1,\n",
       "  'incorpor': 1,\n",
       "  'were': 2,\n",
       "  'implement': 1,\n",
       "  'at': 1,\n",
       "  'school': 1,\n",
       "  'librari': 1,\n",
       "  'inform': 1,\n",
       "  'scienc': 1,\n",
       "  'univers': 1,\n",
       "  'western': 1,\n",
       "  'ontario': 1,\n",
       "  'cluster': 1,\n",
       "  'via': 1,\n",
       "  'titl': 1,\n",
       "  'statist': 1,\n",
       "  'analysi': 1,\n",
       "  'title-us': 1,\n",
       "  'co-occurr': 1,\n",
       "  'examin': 1,\n",
       "  'effect': 1,\n",
       "  'result': 1,\n",
       "  'show': 1,\n",
       "  'impract': 1,\n",
       "  'procedur': 1,\n",
       "  'an': 1,\n",
       "  'oper': 1,\n",
       "  'set': 1,\n",
       "  'but': 1,\n",
       "  'indic': 1,\n",
       "  'analys': 1,\n",
       "  'with': 1,\n",
       "  'sampl': 1,\n",
       "  'data': 1,\n",
       "  'develop': 1,\n",
       "  'mainten': 1,\n",
       "  'dictionari': 1,\n",
       "  'thesauri': 1},\n",
       " '108': {'a': 2,\n",
       "  'program': 1,\n",
       "  'for': 2,\n",
       "  'machine-medi': 1,\n",
       "  'search': 3,\n",
       "  'techniqu': 1,\n",
       "  'of': 4,\n",
       "  'onlin': 1,\n",
       "  'instruct': 2,\n",
       "  'and': 2,\n",
       "  'assist': 2,\n",
       "  'to': 3,\n",
       "  'bibliograph': 1,\n",
       "  'data': 2,\n",
       "  'base': 2,\n",
       "  'searcher': 3,\n",
       "  'call': 1,\n",
       "  'individu': 1,\n",
       "  'access': 1,\n",
       "  'iida': 2,\n",
       "  'is': 3,\n",
       "  'be': 3,\n",
       "  'develop': 2,\n",
       "  'by': 3,\n",
       "  'drexel': 1,\n",
       "  'univers': 1,\n",
       "  'provid': 1,\n",
       "  'feedback': 1,\n",
       "  'on': 2,\n",
       "  'real-tim': 1,\n",
       "  'analysi': 2,\n",
       "  'while': 1,\n",
       "  'are': 2,\n",
       "  'perform': 1,\n",
       "  'extens': 1,\n",
       "  'help': 1,\n",
       "  'facil': 1,\n",
       "  'which': 2,\n",
       "  'draw': 1,\n",
       "  'thi': 2,\n",
       "  'avail': 1,\n",
       "  'user': 1,\n",
       "  'much': 1,\n",
       "  'the': 5,\n",
       "  'project': 2,\n",
       "  \"'s\": 3,\n",
       "  'experiment': 1,\n",
       "  'work': 1,\n",
       "  'as': 1,\n",
       "  'describ': 1,\n",
       "  'elsewher': 1,\n",
       "  'concern': 1,\n",
       "  'with': 2,\n",
       "  'process': 1,\n",
       "  'behavior': 1,\n",
       "  'paper': 1,\n",
       "  'will': 1,\n",
       "  'larg': 1,\n",
       "  'address': 1,\n",
       "  'itself': 1,\n",
       "  'comput': 1,\n",
       "  'system': 1,\n",
       "  'subcontract': 1,\n",
       "  'franklin': 1,\n",
       "  'institut': 1,\n",
       "  'scienc': 1,\n",
       "  'inform': 1,\n",
       "  'servic': 1},\n",
       " '109': {'author': 11,\n",
       "  'cocit': 4,\n",
       "  'a': 3,\n",
       "  'literatur': 1,\n",
       "  'measur': 1,\n",
       "  'of': 15,\n",
       "  'intellectu': 2,\n",
       "  'structur': 2,\n",
       "  'it': 1,\n",
       "  'is': 1,\n",
       "  'shown': 1,\n",
       "  'that': 5,\n",
       "  'the': 16,\n",
       "  'map': 3,\n",
       "  'particular': 1,\n",
       "  'area': 4,\n",
       "  'scienc': 5,\n",
       "  'in': 5,\n",
       "  'thi': 1,\n",
       "  'case': 1,\n",
       "  'inform': 2,\n",
       "  'can': 1,\n",
       "  'be': 1,\n",
       "  'done': 1,\n",
       "  'use': 1,\n",
       "  'as': 5,\n",
       "  'unit': 2,\n",
       "  'analysi': 3,\n",
       "  'and': 5,\n",
       "  'pair': 1,\n",
       "  'variabl': 1,\n",
       "  'indic': 1,\n",
       "  'their': 1,\n",
       "  '``': 3,\n",
       "  'distanc': 1,\n",
       "  \"''\": 3,\n",
       "  'from': 2,\n",
       "  'each': 2,\n",
       "  'other': 3,\n",
       "  'assum': 1,\n",
       "  'more': 1,\n",
       "  'two': 1,\n",
       "  'are': 2,\n",
       "  'cite': 1,\n",
       "  'togeth': 1,\n",
       "  'closer': 1,\n",
       "  'relationship': 1,\n",
       "  'between': 1,\n",
       "  'them': 1,\n",
       "  'raw': 1,\n",
       "  'data': 1,\n",
       "  'count': 1,\n",
       "  'drawn': 1,\n",
       "  'onlin': 1,\n",
       "  'social': 2,\n",
       "  'scisearch': 1,\n",
       "  'citat': 1,\n",
       "  'index': 1,\n",
       "  'over': 1,\n",
       "  'period': 1,\n",
       "  '1972-1979.': 1,\n",
       "  'gthe': 1,\n",
       "  'result': 1,\n",
       "  'show': 1,\n",
       "  '1': 1,\n",
       "  'identifi': 1,\n",
       "  'group': 6,\n",
       "  'akin': 1,\n",
       "  'to': 7,\n",
       "  'school': 1,\n",
       "  '2': 1,\n",
       "  'locat': 1,\n",
       "  'these': 1,\n",
       "  'with': 2,\n",
       "  'respect': 2,\n",
       "  '3': 1,\n",
       "  'degre': 1,\n",
       "  'central': 1,\n",
       "  'peripher': 1,\n",
       "  'within': 2,\n",
       "  '4': 1,\n",
       "  'proxim': 1,\n",
       "  'across': 1,\n",
       "  'boundari': 1,\n",
       "  'border': 1,\n",
       "  'who': 1,\n",
       "  'seem': 1,\n",
       "  'connect': 1,\n",
       "  'variou': 1,\n",
       "  'research': 1,\n",
       "  '5': 1,\n",
       "  'posit': 1,\n",
       "  \"'s\": 1,\n",
       "  'axe': 1,\n",
       "  'which': 1,\n",
       "  'were': 1,\n",
       "  'arbitrarili': 1,\n",
       "  'set': 1,\n",
       "  'span': 1,\n",
       "  'most': 1,\n",
       "  'diverg': 1,\n",
       "  'order': 1,\n",
       "  'aid': 1,\n",
       "  'interpret': 1,\n",
       "  'offer': 1,\n",
       "  'new': 1,\n",
       "  'techniqu': 2,\n",
       "  'might': 1,\n",
       "  'contribut': 1,\n",
       "  'understand': 1,\n",
       "  'possibl': 1,\n",
       "  'extent': 1,\n",
       "  'those': 1,\n",
       "  'reli': 1,\n",
       "  'on': 1,\n",
       "  'serial': 1,\n",
       "  'public': 1,\n",
       "  'establish': 1,\n",
       "  'well': 1,\n",
       "  'document': 1,\n",
       "  'an': 1,\n",
       "  'effect': 1,\n",
       "  'analyz': 1,\n",
       "  'subject': 1,\n",
       "  'specialti': 1},\n",
       " '110': {'progress': 1,\n",
       "  'in': 9,\n",
       "  'document': 1,\n",
       "  'word': 3,\n",
       "  'process': 2,\n",
       "  'an': 1,\n",
       "  'introduct': 1,\n",
       "  'and': 7,\n",
       "  'apprais': 1,\n",
       "  'the': 13,\n",
       "  '``': 7,\n",
       "  'offic': 6,\n",
       "  'of': 3,\n",
       "  'futur': 1,\n",
       "  \"''\": 7,\n",
       "  'technolog': 2,\n",
       "  'electron': 2,\n",
       "  'mail': 1,\n",
       "  'commun': 1,\n",
       "  'converg': 1,\n",
       "  'inform': 1,\n",
       "  'manag': 1,\n",
       "  'these': 1,\n",
       "  'are': 2,\n",
       "  'all': 1,\n",
       "  'term': 1,\n",
       "  'includ': 1,\n",
       "  'current': 2,\n",
       "  'list': 1,\n",
       "  'buzz': 1,\n",
       "  'use': 1,\n",
       "  'to': 3,\n",
       "  'describ': 1,\n",
       "  'activ': 1,\n",
       "  'area': 2,\n",
       "  'high': 1,\n",
       "  'level': 1,\n",
       "  'invest': 4,\n",
       "  'factori': 2,\n",
       "  'plant': 1,\n",
       "  'ever-increas': 1,\n",
       "  'fight': 1,\n",
       "  'improv': 2,\n",
       "  'product': 1,\n",
       "  'by': 1,\n",
       "  'autom': 2,\n",
       "  'dull': 1,\n",
       "  'routin': 2,\n",
       "  'job': 2,\n",
       "  'usual': 1,\n",
       "  'quot': 2,\n",
       "  'compar': 1,\n",
       "  'with': 1,\n",
       "  'extrem': 1,\n",
       "  'low': 1,\n",
       "  'equal': 1,\n",
       "  'tediou': 1,\n",
       "  'environ': 1,\n",
       "  'is': 3,\n",
       "  'as': 2,\n",
       "  'be': 1,\n",
       "  'ten': 1,\n",
       "  'time': 1,\n",
       "  'greater': 1,\n",
       "  'per': 1,\n",
       "  'employe': 1,\n",
       "  'than': 1,\n",
       "  'thi': 1,\n",
       "  'howev': 1,\n",
       "  'chang': 1,\n",
       "  'rapidli': 1,\n",
       "  'on': 1,\n",
       "  'a': 2,\n",
       "  'larg': 1,\n",
       "  'scale': 1,\n",
       "  'alreadi': 1,\n",
       "  'take': 2,\n",
       "  'place': 1,\n",
       "  'manhi': 1,\n",
       "  'present-day': 1,\n",
       "  'inflat': 1,\n",
       "  'bite': 1,\n",
       "  'hard': 1,\n",
       "  'forc': 1,\n",
       "  'mani': 1,\n",
       "  'compani': 1,\n",
       "  'organ': 1,\n",
       "  'much': 1,\n",
       "  'closer': 1,\n",
       "  'look': 1,\n",
       "  'at': 1,\n",
       "  'their': 1,\n",
       "  'oper': 1},\n",
       " '111': {'document': 4,\n",
       "  'cluster': 5,\n",
       "  'use': 6,\n",
       "  'an': 4,\n",
       "  'invert': 1,\n",
       "  'file': 3,\n",
       "  'approach': 1,\n",
       "  'autom': 1,\n",
       "  'procedur': 2,\n",
       "  'is': 4,\n",
       "  'describ': 1,\n",
       "  'which': 4,\n",
       "  'doe': 1,\n",
       "  'not': 1,\n",
       "  'requir': 1,\n",
       "  'the': 11,\n",
       "  'of': 6,\n",
       "  'inter-docu': 1,\n",
       "  'similar': 1,\n",
       "  'matrix': 1,\n",
       "  'and': 2,\n",
       "  'independ': 1,\n",
       "  'order': 1,\n",
       "  'in': 3,\n",
       "  'are': 1,\n",
       "  'process': 1,\n",
       "  'make': 1,\n",
       "  'initi': 1,\n",
       "  'set': 1,\n",
       "  'deriv': 1,\n",
       "  'from': 3,\n",
       "  'certain': 1,\n",
       "  'term': 1,\n",
       "  'index': 1,\n",
       "  'vocabulari': 1,\n",
       "  'to': 1,\n",
       "  'characteris': 1,\n",
       "  'retriev': 1,\n",
       "  'effect': 1,\n",
       "  'obtain': 2,\n",
       "  'compar': 1,\n",
       "  'with': 1,\n",
       "  'that': 1,\n",
       "  'serial': 1,\n",
       "  'search': 1,\n",
       "  'single-linkag': 1,\n",
       "  'method': 1},\n",
       " '112': {'a': 3,\n",
       "  'fast': 2,\n",
       "  'procedur': 3,\n",
       "  'for': 3,\n",
       "  'the': 10,\n",
       "  'calcul': 1,\n",
       "  'of': 5,\n",
       "  'similar': 1,\n",
       "  'coeffici': 1,\n",
       "  'in': 4,\n",
       "  'automat': 2,\n",
       "  'classif': 2,\n",
       "  'algorithm': 2,\n",
       "  'is': 1,\n",
       "  'describ': 2,\n",
       "  'compar': 2,\n",
       "  'list': 1,\n",
       "  'term': 2,\n",
       "  'repres': 1,\n",
       "  'document': 3,\n",
       "  'experi': 1,\n",
       "  'speed': 1,\n",
       "  'aris': 1,\n",
       "  'from': 1,\n",
       "  'fact': 1,\n",
       "  'that': 1,\n",
       "  'all': 1,\n",
       "  'non-zero-valu': 1,\n",
       "  'coefficic': 1,\n",
       "  'given': 1,\n",
       "  'are': 2,\n",
       "  'identifi': 1,\n",
       "  'togeth': 1,\n",
       "  'use': 1,\n",
       "  'an': 1,\n",
       "  'invert': 1,\n",
       "  'file': 1,\n",
       "  'to': 1,\n",
       "  'collect': 1,\n",
       "  'complex': 1,\n",
       "  'and': 1,\n",
       "  'run': 1,\n",
       "  'time': 1,\n",
       "  'with': 1,\n",
       "  'previous': 1}}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'how': 1,\n",
       " 'can': 1,\n",
       " 'actual': 1,\n",
       " 'pertin': 1,\n",
       " 'data': 1,\n",
       " 'as': 1,\n",
       " 'oppos': 1,\n",
       " 'to': 2,\n",
       " 'refer': 1,\n",
       " 'or': 1,\n",
       " 'entir': 1,\n",
       " 'articl': 1,\n",
       " 'themselv': 1,\n",
       " 'be': 1,\n",
       " 'retriev': 1,\n",
       " 'automat': 1,\n",
       " 'in': 1,\n",
       " 'respons': 1,\n",
       " 'inform': 1,\n",
       " 'request': 1}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry_terms[\"2\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
